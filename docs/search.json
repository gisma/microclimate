[
  {
    "objectID": "base/impressum.html#content-responsibility",
    "href": "base/impressum.html#content-responsibility",
    "title": "Impressum",
    "section": "Content Responsibility",
    "text": "Content Responsibility\nThe responsibility for the content rests with the instructors. Statements, opinions and/or conclusions are the ones from the instructors and do not necessarily reflect the opinion of the representatives of Marburg University."
  },
  {
    "objectID": "base/impressum.html#content-license",
    "href": "base/impressum.html#content-license",
    "title": "Impressum",
    "section": "Content License",
    "text": "Content License\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\nPrivacy Policy\n\n\nAs of 21. October 2021\n\n\nIntroduction\n\n\nWith the following data protection declaration, we would like to inform you about the types of your personal data (hereinafter also referred to as “data” for short) that we process, for what purposes and to what extent. The privacy policy applies to all processing of personal data carried out by us, both in the context of the provision of our services and in particular on our websites, in mobile applications and within external online presences, such as our social media profiles (hereinafter collectively referred to as “Online Offerings”).\n\n\nThe terms used are not gender-specific.\n\n\nResponsible\n\n\nDr Christoph ReudenbachDeutschhaustr 1035037 Marburg\n\n\nEmail address: reudenbach@uni-marburg.de.\n\n\nImprint: https://www.uni-marburg.de/de/impressum.\n\n\nOverview of Processing\n\n\nThe following overview summarizes the types of data processed and the purposes of their processing, and refers to the data subjects.\n\n\nTypes of Data Processed\n\n\n\nContent data (e.g. input in online forms).\n\n\nContact data (e.g. email, phone numbers).\n\n\nMeta/communication data (e.g. device information, IP addresses).\n\n\nUse data (e.g. websites visited, interest in content, access times).\n\n\n\nCategories of data subjects\n\n\n\nCommunication partners.\n\n\nUsers (e.g.. Website visitors, users of online services).\n\n\n\nPurposes of processing\n\n\n\nDirect marketing (e.g., by email or postal mail).\n\n\nContact requests and communications.\n\n\n\nRelevant legal basis\n\n\nThe following is an overview of the legal basis of the GDPR on the basis of which we process personal data. Please note that in addition to the provisions of the GDPR, national data protection regulations may apply in your or our country of residence or domicile. Furthermore, should more specific legal bases be decisive in individual cases, we will inform you of these in the data protection declaration.\n\n \n\n\nConsent (Art. 6 para. 1 p. 1 lit. a. DSGVO) - The data subject has given his or her consent to the processing of personal data concerning him or her for a specific purpose or purposes.\n\n\nRegistered interests (Art. 6 para. 1 p. 1 lit. f. DSGVO) - Processing is necessary to protect the legitimate interests of the controller or a third party, unless such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require the protection of personal data.\n\n\n\nNational data protection regulations in Germany: In addition to the data protection regulations of the General Data Protection Regulation, national regulations on data protection apply in Germany. These include, in particular, the Act on Protection against Misuse of Personal Data in Data Processing (Federal Data Protection Act - BDSG). In particular, the BDSG contains special regulations on the right to information, the right to erasure, the right to object, the processing of special categories of personal data, processing for other purposes and transmission, as well as automated decision-making in individual cases, including profiling. Furthermore, it regulates data processing for employment purposes (Section 26 BDSG), in particular with regard to the establishment, implementation or termination of employment relationships as well as the consent of employees. Furthermore, state data protection laws of the individual federal states may apply.\n\n \n\nSecurity measures\n\n\nWe take appropriate technical and organizational measures in accordance with the legal requirements, taking into account the state of the art, the implementation costs and the nature, scope, circumstances and purposes of the processing, as well as the different probabilities of occurrence and the extent of the threat to the rights and freedoms of natural persons, in order to ensure a level of protection appropriate to the risk.\n\n.\n\nMeasures include, in particular, ensuring the confidentiality, integrity, and availability of data by controlling physical and electronic access to data as well as access to, entry into, disclosure of, assurance of availability of, and segregation of data concerning them. Furthermore, we have established procedures to ensure the exercise of data subjects’ rights, the deletion of data, and responses to data compromise. Furthermore, we take the protection of personal data into account as early as the development or selection of hardware, software as well as procedures in accordance with the principle of data protection, through technology design and through data protection-friendly default settings.\n\n \n\nDeletion of data\n\n\nThe data processed by us will be deleted in accordance with legal requirements as soon as their consents permitted for processing are revoked or other permissions cease to apply (e.g. if the purpose of processing this data has ceased to apply or it is not necessary for the purpose).\n\n \n\nIf the data are not deleted because they are required for other and legally permissible purposes, their processing will be limited to these purposes. That is, the data will be blocked and not processed for other purposes. This applies, for example, to data that must be retained for reasons of commercial or tax law or whose storage is necessary for the assertion, exercise or defense of legal claims or for the protection of the rights of another natural person or legal entity.\n\n \n\nOur privacy notices may also include further information on the retention and deletion of data that takes precedence for the processing operations in question.\n\n \n\nUse of cookies\n\n\nCookies are text files that contain data from websites or domains visited and are stored by a browser on the user’s computer. The primary purpose of a cookie is to store information about a user during or after their visit within an online site. Stored information may include, for example, language settings on a website, login status, a shopping cart, or where a video was watched. We further include in the term cookies other technologies that perform the same functions as cookies (e.g., when user details are stored using pseudonymous online identifiers, also referred to as “user IDs”)\n\n.\n\nThe following cookie types and functions are distinguished:\n\n\n\nTemporary cookies (also: session or session cookies): Temporary cookies are deleted at the latest after a user has left an online offer and closed his browser.\n\n\nPermanent cookies: Permanent cookies remain stored even after closing the browser. For example, the login status can be saved or preferred content can be displayed directly when the user revisits a website. Likewise, the interests of users used for range measurement or marketing purposes can be stored in such a cookie.\n\n\nFirst-party cookies: First-party cookies are set by ourselves.\n\n\nThird-party cookies (also: third-party cookies): Third-party cookies are mainly used by advertisers (so-called third parties) to process user information.\n\n\nNecessary (also: essential or absolutely necessary) cookies: Cookies may be absolutely necessary for the operation of a website (e.g. to store logins or other user input or for security reasons).\n\n\nStatistics, marketing and personalization cookies: Furthermore, cookies are usually also used in the context of range measurement and when the interests of a user or his behavior (e.g. viewing certain content, use of functions, etc.) on individual web pages are stored in a user profile. Such profiles are used, for example, to show users content that matches their potential interests. This process is also referred to as “tracking”, i.e., tracking the potential interests of users. Insofar as we use cookies or “tracking” technologies, we will inform you separately in our privacy policy or in the context of obtaining consent.\n\n\n\nNotes on legal bases: On which legal basis we process your personal data using cookies depends on whether we ask you for consent. If this is the case and you consent to the use of cookies, the legal basis for the processing of your data is the declared consent. Otherwise, the data processed with the help of cookies is processed on the basis of our legitimate interests (e.g. in a business operation of our online offer and its improvement) or, if the use of cookies is necessary to fulfill our contractual obligations.\n\n.\n\nDuration of storage: If we do not provide you with explicit information about the storage period of permanent cookies (e.g. in the context of a so-called cookie opt-in), please assume that the storage period can be up to two years.\n\n.\n\nGeneral information on revocation and objection (opt-out):  Depending on whether the processing is based on consent or legal permission, you have the option at any time to revoke any consent given or to object to the processing of your data by cookie technologies (collectively referred to as “opt-out”). You can initially declare your objection by means of your browser settings, e.g. by deactivating the use of cookies (whereby this may also restrict the functionality of our online offer). An objection to the use of cookies for online marketing purposes can also be declared by means of a variety of services, especially in the case of tracking, via the websites https://optout.aboutads.info and https://www.youronlinechoices.com/. In addition, you can receive further objection notices in the context of the information on the service providers and cookies used.\n\n.\n\nProcessing of cookie data on the basis of consent: We use a cookie consent management procedure, in the context of which the consent of users to the use of cookies, or the processing and providers mentioned in the cookie consent management procedure can be obtained and managed and revoked by users. Here, the declaration of consent is stored in order not to have to repeat its query and to be able to prove the consent in accordance with the legal obligation. The storage can take place on the server side and/or in a cookie (so-called opt-in cookie, or with the help of comparable technologies), in order to be able to assign the consent to a user or their device. Subject to individual information on the providers of cookie management services, the following information applies: The duration of the storage of consent can be up to two years. Here, a pseudonymous user identifier is formed and stored with the time of consent, information on the scope of consent (e.g., which categories of cookies and/or service providers) as well as the browser, system and end device used.\n\n.\n\n\nTypes of data processed: Usage data (e.g. websites visited, interest in content, access times), meta/communication data (e.g. device information, IP addresses).\n\n\nPersons concerned: Users (e.g. website visitors, users of online services).\n\n\nLegal basis: Consent (Art. 6 para. 1 p. 1 lit. a. DSGVO), Legitimate Interests (Art. 6 para. 1 p. 1 lit. f. DSGVO).\n\n\n\nSurveys and polls\n\n\nThe surveys and polls (hereinafter “surveys”) conducted by us are evaluated anonymously. Personal data is only processed insofar as this is necessary for the provision and technical implementation of the surveys (e.g. processing of the IP address to display the survey in the user’s browser or to enable a resumption of the survey with the help of a temporary cookie (session cookie)) or users have consented.\n\n.\n\nNotes on legal basis: If we ask participants for consent to process their data, this is the legal basis of the processing, otherwise the processing of participants’ data is based on our legitimate interests in conducting an objective survey.\n\n \n\n\nTypes of data processed: Contact data (e.g. email, phone numbers), content data (e.g. input in online forms), usage data (e.g. web pages visited, interest in content, access times), meta/communication data (e.g. device information, IP addresses).\n\n\nParticipants concerned: Communication partners.\n\n\nPurposes of processing: Contact requests and communication, direct marketing (e.g. by e-mail or postal mail).\n\n\nLegal basis: Consent (Art. 6 para. 1 p. 1 lit. a. DSGVO), Legitimate Interests (Art. 6 para. 1 p. 1 lit. f. DSGVO).\n\n\n\nChange and Update Privacy Policy\n\n\nWe encourage you to periodically review the contents of our Privacy Policy. We adapt the Privacy Policy as soon as the changes in the data processing activities we carry out make it necessary. We will inform you as soon as the changes require an act of cooperation on your part (e.g. consent) or other individual notification.\n\n.\n\nWhere we provide addresses and contact information for companies and organizations in this Privacy Policy, please note that addresses may change over time and please check the information before contacting us.\n\n.\n\nRights of data subjects\n\n\nAs a data subject, you are entitled to various rights under the GDPR, which arise in particular from Art. 15 to 21 DSGVO:\n\n\n\nRight to object: You have the right to object at any time, on grounds relating to your particular situation, to the processing of personal data relating to you which is carried out on the basis of Art. 6(1)(e) or (f) DSGVO; this also applies to profiling based on these provisions. If the personal data concerning you is processed for the purpose of direct marketing, you have the right to object at any time to the processing of personal data concerning you for the purpose of such marketing; this also applies to profiling, insofar as it is associated with such direct marketing.\n\n\nRight of withdrawal in the case of consent: You have the right to withdraw any consent you have given at any time.\n\n\nRight of access: You have the right to request confirmation as to whether data in question is being processed and to information about this data, as well as further information and copy of the data in accordance with the legal requirements.\n\n\nRight of rectification: You have the right, in accordance with the legal requirements, to request the completion of the data concerning you or the correction of incorrect data concerning you.\n\n\nRight to erasure and restriction of processing: You have, in accordance with the law, the right to request that data concerning you be erased without undue delay, or alternatively, in accordance with the law, to request restriction of the processing of the data.\n\n\nRight to data portability: You have the right to receive data concerning you, which you have provided to us, in a structured, common and machine-readable format in accordance with the legal requirements, or to demand its transfer to another responsible party.\n\n\nComplaint to supervisory authority: Without prejudice to any other administrative or judicial remedy, you have the right to lodge a complaint with a supervisory authority, in particular in the Member State of your habitual residence, place of work or the place of the alleged infringement, if you consider that the processing of personal data concerning you infringes the requirements of the GDPR.\n\n\n.\n\nDefinitions of Terms\n\n\nThis section provides you with an overview of the terms used in this Privacy Policy. Many of the terms are taken from the law and defined primarily in Article 4 of the GDPR. The legal definitions are binding. The following explanations, on the other hand, are primarily intended to aid understanding. The terms are sorted alphabetically.\n\n \n\n\nPersonal data: “Personal data” means any information relating to an identified or identifiable natural person (hereinafter “data subject”); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier (eg. e.g. cookie) or to one or more special characteristics that are an expression of the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.\n\n\nController: The “controller” is the natural or legal person, public authority, agency or other body which alone or jointly with others determines the purposes and means of the processing of personal data.\n\n\nProcessing: “Processing” means any operation or set of operations which is performed upon personal data, whether or not by automatic means. The term is broad and includes virtually any handling of data, whether collecting, evaluating, storing, transmitting or deleting.\n\n\n\nCreated with free Datenschutz-Generator.de by Dr. Thomas Schwenke"
  },
  {
    "objectID": "base/impressum.html#comments-suggestions",
    "href": "base/impressum.html#comments-suggestions",
    "title": "Impressum",
    "section": "Comments & Suggestions",
    "text": "Comments & Suggestions"
  },
  {
    "objectID": "base/about.html",
    "href": "base/about.html",
    "title": "About this site",
    "section": "",
    "text": "About this site\nThis page summarizes the essential workflows , basic literature and web resources from the distributed course systems , documents and field protocols into a knowledge base.\nAlthough the web space is topic-centered any keyword can be searched using the full text search.\nThe creation of new pages, the editing of existing pages can be triggered directly via the right column online.\nOffline there are several visual editors and full integration with Rstudio etc."
  },
  {
    "objectID": "doc/helper_functions.html",
    "href": "doc/helper_functions.html",
    "title": "Helper Functions for Microclimate Predictor Stack",
    "section": "",
    "text": "1 Introduction\nThis document explains the custom helper functions used in the microclimate_predictor_stack.R script for preprocessing and analyzing LiDAR data in R. The functions support pixel-level metrics computation, raster template creation, VRT mosaicking, and tree hull extraction.\n\n\n\n2 .stdmetrics()\n#' @title .stdmetrics\n#' @description Berechnet Standardmetriken für LiDAR Rasterzellen\n.stdmetrics &lt;- function(z, i, ...) {\n  return(list(\n    zmax = max(z, na.rm = TRUE),            # Maximum height\n    zmean = mean(z, na.rm = TRUE),          # Mean height\n    zsd = sd(z, na.rm = TRUE),              # Standard deviation of heights\n    zkurto = moments::kurtosis(z, na.rm = TRUE), # Kurtosis (peakedness of distribution)\n    zskew = moments::skewness(z, na.rm = TRUE),  # Skewness (asymmetry)\n    zq25 = quantile(z, 0.25, na.rm = TRUE), # 25th percentile\n    zq50 = quantile(z, 0.5, na.rm = TRUE),  # Median height\n    zq75 = quantile(z, 0.75, na.rm = TRUE), # 75th percentile\n    zpulse = length(z)                      # Number of returns (pulse count)\n  ))\n}\nUsed to derive standard height-based metrics from LiDAR returns per raster cell using pixel_metrics().\n\n\n\n3 get_vrt_img()\n#' @title get_vrt_img\n#' @description Creates a VRT from multiple GeoTIFF files in a directory\nget_vrt_img &lt;- function(name, path, pattern) {\n  tifs &lt;- list.files(path = path, pattern = paste0(pattern, \".tif$\"), full.names = TRUE)\n  vrt &lt;- file.path(path, paste0(name, \".vrt\"))\n  if (file.exists(vrt)) file.remove(vrt)\n  gdal_utils(util = \"buildvrt\", source = tifs, destination = vrt)\n  return(vrt)\n}\nUsed to dynamically generate a VRT (virtual raster stack) from multiple .tif files with a matching pattern, e.g. \"lad_metrics\".\n\n\n\n4 tree_fn()\n#' @title tree_fn\n#' @description Creates convex hulls from segmented trees in LAS catalogs\ntree_fn &lt;- function(las, ...) {\n  if (is.empty(las)) return(NULL)                   # Skip if empty\n  las &lt;- filter_poi(las, !is.na(treeID))            # Keep only trees\n  if (npoints(las) == 0) return(NULL)               # Skip if no points\n  dt &lt;- data.table::as.data.table(las@data)\n  dt &lt;- dt[, .(X = mean(X), Y = mean(Y)), by = treeID]  # Mean location per tree\n  points_sf &lt;- st_as_sf(dt, coords = c(\"X\", \"Y\"), crs = sf::st_crs(las))\n  hulls &lt;- st_convex_hull(st_union(points_sf))      # Create unified convex hull\n  return(hulls)\n}\nUsed with catalog_apply() to derive convex hull geometries from segmented tree point clouds.\n\n\n\n5 template_raster()\n#' @title template_raster\n#' @description Creates an empty raster template based on bounding box and resolution\ntemplate_raster &lt;- function(bbox, crs, res = 1.0) {\n  if (inherits(bbox, \"sf\")) bbox &lt;- st_bbox(bbox)\n  r &lt;- terra::rast(xmin = bbox[\"xmin\"], xmax = bbox[\"xmax\"],\n                   ymin = bbox[\"ymin\"], ymax = bbox[\"ymax\"],\n                   resolution = res, crs = crs)\n  return(r)\n}\nGenerates a blank terra::rast object for rasterizing vector geometries such as LAD polygons or tree hulls."
  },
  {
    "objectID": "doc/tls_v1_1.html#background-and-method",
    "href": "doc/tls_v1_1.html#background-and-method",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Background and Method",
    "text": "Background and Method\nThis section explains the theoretical principles of leaf area density (LAD) and describes how it can be determined using terrestrial laser scanning (TLS). Leaf area density is an important parameter in environmental modeling, for example for radiation balance and microclimate simulations. It indicates the leaf area per volume (m²/m³) and is therefore a decisive factor for microclimate simulations, radiation models, and energy flows in vegetation stands.\n\n\n\n\n\n\n\n\nApproach Type\nName / Description\nNature\n\n\n\n\nPulse-count based\nSimple linear normalization of return counts or voxel hits\nEmpirical, direct\n\n\nLinear normalization\nStraightforward normalization of pulse counts by voxel volume or max LAD\nEmpirical, basic\n\n\nPulse-density normalization\nAdjusts for occlusion and scan geometry\nSemi-empirical\n\n\nGap fraction models\nEstimate LAD/LAI from canopy openness statistics\nSemi-empirical\n\n\nBeer–Lambert conversion conversion\nUses exponential light attenuation to infer LAD\nPhysically-based\n\n\nVoxel-based inverse modeling\nOptimizes 3D LAD to match observed light attenuation or reflectance\nPhysically-based\n\n\nAllometric / geometric reconstruction\nReconstructs crown volume and distributes LAD using QSM or shape fitting\nGeometric, structural\n\n\n\n\nLinear normalization is a practical baseline: simple, fast, and reproducible.\nBeer–Lambert conversion introduces realism via physical light attenuation.\n\nMore advanced models (e.g. voxel inverse or QSM-based) aim for higher biophysical fidelity at the cost of complexity.\nThe present analysis is based on TLS with a medium-range RIEGL scanner (e.g., VZ-400). This captures millions of 3D points of the vegetation structure with high angular resolution. The point cloud is divided into uniform voxels, from which the leaf area density is estimated in two ways.\n\nLinear normalization (straightforwad)\n\\[\n\\text{LAD}_i = \\frac{N_i}{N_{\\max}} \\cdot \\text{LAD}_{\\max}\n\\] - \\(N_i\\): Number of laser points in voxel \\(i\\)\n- \\(N_{\\max}\\): Maximum across all voxels\n- \\(\\text{LAD}_{\\max}\\): Maximum LAD value from the literature (e.g., 5 m²/m³)\n\n\n\nBeer–Lambert conversion\n\\[\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n\\]\n\n\\(k\\): Extinction coefficient (typically 0.3–0.5)\n\\(\\Delta z\\): vertical voxel height\n\n\n\nOverall Workflow\nWhat happens in the script?\n\n\n\n\n\n\n\n\nStep\nDescription\nRelevant Code\n\n\n\n\n1. Read & Filter LAS\nLoad TLS data, optionally crop and clean it\nreadLAS() and las = filter_poi(...)\n\n\n2. Voxel Grid Setup\nSet up 3D grid at defined grain.size\npassed to pixel_metrics(..., res = grain.size)\n\n\n3. Count Pulses\nCount returns in each voxel height bin\npointsByZSlice() function\n\n\n4. Normalise Pulse Counts\nDivide by global max (relative LAD)\nin convert_to_LAD(): lad = (count / max) * LADmax\n\n\n5. Export Raster\nConvert metrics to raster stack\nterra::rast() from voxel_df\n\n\n6. Visualization\nPlot LAD profiles\nsee plotting section\n\n\n7. Export to Plant3D\nExports the LAD to ENVI-met\nsee export section"
  },
  {
    "objectID": "doc/tls_v1_1.html#implemetation",
    "href": "doc/tls_v1_1.html#implemetation",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Implemetation",
    "text": "Implemetation\nTo use this ENVI-met tree modeling workflow in R, follow these steps to load and initialize the project correctly:\nProject Setup: Loading the R Project and Environment Download the project from next.hessenbox https://gds.hessen.de/INTERSHOP/web/WFS/HLBG-Geodaten-Site/de_DE/-/EUR/ViewDownloadcenter-Start ##### Download and Unzip the Project Archive\n\n\nUnzip the folder to your desired location.\nThe folder should contain at least:\n\nAn *.Rproj file (e.g. envimet_tree_workflow.Rproj)\nA data/ folder with input files like tree_08.las\nOne or more R/ scripts\n\n\n\nOpen the Project in RStudio\n\nGo to File → Open Project\nSelect the *.Rproj file (e.g. microclimate_TLS.Rproj)\nThis ensures that the project directory is treated as the root for all file paths.\n\n\nThe use of the {here} package depends on having a valid RStudio project. Without this, file paths may not resolve correctly.\n\n\n\nData Input Parameters and Paths\n\n\n\n\n\n\nThe input data set tree_08.las is a cleaned terrestrial laser scan of a single, isolated tree. All surrounding vegetation and ground points have been removed, so the file contains only the tree’s structure—trunk, branches, and foliage. Stored in standard LAS format, it provides high-resolution 3D point data suitable for voxelization, LAD calculation, or input into microclimate and radiative models. This detailed structural data is essential for generating true 3D tree entities in ENVI-met; without it, only simplified vegetation (SimplePlants) can be used.\n\n\n\nSet global parameters for the workflow, such as file paths, voxel resolution, and maximum LAD value for normalization.\n\nlibrary(terra)\nlibrary(lidR)\nlibrary(sf)\nlibrary(here)\nlibrary(data.table)\n\nzmax &lt;- 40  \ngrain.size &lt;- 1  \nproject_root &lt;- here::here()  \n\n# Choose LAD method: \"linear\" or \"beer\"\n# Beer–Lambert conversion Notes:\n# - Avoids log(0) and 1 by clipping near-extreme values\n# - Use when cumulative light absorption or occlusion is relevant\n# - Suitable if extinction coefficient is known or estimated from prior studies\nlad_method &lt;- \"beer\"  # Set to \"linear\" or \"beer\"\n\n# Optional: extinction coefficient (used only for Beer–Lambert conversion)\nk_extinction &lt;- 0.25\n\n\nlas_file &lt;- file.path(project_root, \"data/TLS/tree_08.laz\")  \noutput_voxels &lt;- file.path(project_root, \"data/TLS/LAD_voxDF.rds\")  \noutput_array &lt;- file.path(project_root, \"data/TLS/lad_array_m2m3.rds\")  \noutput_profile_plot &lt;- file.path(project_root, \"data/TLS/lad_vertical_profile.pdf\")  \n\n\n\nVoxelization of TLS data\nVoxelisation turns a 3D TLS point cloud into a grid of cubes (voxels), where each voxel holds structural information. The number of points per voxel is used to estimate Leaf Area Density (LAD), typically normalized relative to the voxel with the most returns.\n\nEach voxel = a 1×1×1 m³ cube\nCount the laser hits per voxel\nNormalize to maximum\nMultiply by a literature-based LAD_max (e.g. 5 m²/m³)\n\nThis gives a spatially distributed LAD profile suitable for further analysis or models like ENVI-met.\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\nlibrary(terra)\n\n las &lt;- lidR::readLAS(las_file)  # Read the LAS/LAZ file (point cloud data)\n\n\n[======================================&gt;           ] 76% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[======================================&gt;           ] 77% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n                                                                                \n\n  las@data$Z &lt;- las@data$Z - min(las@data$Z, na.rm = TRUE)  \n  maxZ &lt;- min(floor(max(las@data$Z, na.rm = TRUE)), zmax)  \n  las@data$Z[las@data$Z &gt; maxZ] &lt;- maxZ  \npointsByZSlice = function(Z, maxZ){\n  heightSlices = as.integer(Z) # Round down\n  zSlice = data.table::data.table(Z=Z, heightSlices=heightSlices) # Create a data.table (Z, slices))\n  sliceCount = stats::aggregate(list(V1=Z), list(heightSlices=heightSlices), length) # Count number of returns by slice\n  \n  ##############################################\n  # Add columns to equalize number of columns\n  ##############################################\n  colRange = 0:maxZ\n  addToList = setdiff(colRange, sliceCount$heightSlices)\n  n = length(addToList)\n  if (n &gt; 0) {\n    bindDt = data.frame(heightSlices = addToList, V1=integer(n))\n    sliceCount = rbind(sliceCount, bindDt)\n    # Order by height\n    sliceCount = sliceCount[order(sliceCount$heightSlices),]\n  }\n  \n  colNames = as.character(sliceCount$heightSlices)\n  colNames[1] = \"ground_0_1m\"\n  colNames[-1] = paste0(\"pulses_\", colNames[-1], \"_\", sliceCount$heightSlices[-1]+1, \"m\")\n  metrics = list()\n  metrics[colNames] = sliceCount$V1\n  \n  return(metrics)\n  \n} #end function pointsByZSlice\n\n# --- Main function ---\npreprocess_voxels &lt;- function(normlas, grain.size = 1, maxP =zmax, normalize = TRUE, as_raster = TRUE) {  \n  las &lt;- normlas  \n  \n  # Filter height range\n  las &lt;- filter_poi(las, Z &gt;= 0 & Z &lt;= maxP)  \n  if (lidR::is.empty(las)) return(NULL)\n  # Determine Z-slices\n  maxZ &lt;- floor(max(las@data$Z))  \n  maxZ &lt;- min(maxZ, maxP)  \n  \n  \n  # Compute voxel metrics\n  func &lt;- formula(paste0(\"~pointsByZSlice(Z, \", maxZ, \")\"))  \n  voxels &lt;- pixel_metrics(las, func, res = grain.size)  # Calculate metrics in each voxel (3D grid cell)\n  \n  # Optionally normalize values by voxel volume\n  if (normalize) {\n    vvol &lt;- grain.size^3  \n    voxels &lt;- voxels / vvol  \n  }\n  \n  # Return as both terra::SpatRaster and data.frame\n  result &lt;- list()  \n  \n  if (as_raster) {\n    result$raster &lt;- voxels  \n  }\n  \n  # Convert to data.frame\n  xy &lt;- terra::xyFromCell(voxels, seq_len(ncell(voxels)))  \n  vals &lt;- terra::values(voxels)  \n  df &lt;- cbind(xy, vals)  \n  colnames(df)[1:2] &lt;- c(\"X\", \"Y\")  \n  result$df &lt;- df  \n  \n  return(result)\n}\n\n\n\n\nvox_out &lt;- preprocess_voxels(las, grain.size = 1, maxP = zmax)  \n\n\n\n\n\nConversion to LAD (m²/m³)\nThe conversion to LAD (Leaf Area Density, in m²/m³) from TLS-based voxel pulse counts is done using a relative normalization heuristic which is adopted as a practical approximation in voxel-based canopy structure analysis using TLS (Terrestrial Laser Scanning) data.:\nFor each voxel layer (e.g. pulses_2_3m), the LAD is calculated as:\n\\[\n\\text{LAD}_{\\text{voxel}} = \\left( \\frac{\\text{pulse count in voxel}}{\\text{maximum pulse count over all voxels}} \\right) \\times \\text{LAD}_{\\text{max}}\n\\]\nWhere:\n\npulse count in voxel = number of returns in this voxel layer (from TLS)\nmax_pulse = the maximum pulse count found in any voxel (used for normalization)\nLAD_max = a fixed normalization constant (e.g. 5.0 m²/m³) chosen from literature or calibration\n\n\n\n\n\n\n\nTypical LADₘₐₓ Values by Species\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies / Structure Type\nLADₘₐₓ (m²/m³)\nSource / Notes\n\n\n\n\nFagus sylvatica (European beech)\n3.5–5.5\nCalders et al. (2015), Chen et al. (2018)\n\n\nQuercus robur (English oak)\n3.0–6.0\nHosoi & Omasa (2006), field studies with TLS voxelization\n\n\nConiferous trees (e.g. pine)\n4.0–7.0\nWilkes et al. (2017), higher LAD due to needle density\n\n\nMixed broadleaf forest\n3.0–6.0\nFlynn et al. (2023), canopy averaged estimates\n\n\nShrubs / understorey\n1.5–3.0\nChen et al. (2018),lower vertical structure density\n\n\nUrban street trees\n2.0–4.0\nSimon et al. (2020), depending on pruning and species\n\n\n\nLAD values refer to maximum expected per 1 m vertical voxel. Values depend on species, seasonality, and scanning conditions.\n\n\n\nWhat this means conceptually\nYou’re not measuring absolute LAD, but instead:\n\nUsing the number of TLS returns per voxel as a proxy for leaf density\nThen normalization all voxels relatively to the most “leaf-dense” voxel\nThe LAD_max defines what value the “densest” voxel should reach in terms of LAD\n\nThis is fast, simple, and works well when:\n\nYou want relative structure across the canopy\nYou don’t have absolute calibration (e.g. with destructive sampling or hemispheric photos)\n\nCaveats and assumptions\n\nThis approach assumes the TLS beam returns are proportional to leaf area, which is a simplification\nIt’s sensitive to occlusion and TLS positioning\nThe choice of LAD_max is crucial—common values from literature range from 3–7 m²/m³ for dense canopies\n\nThe LAD conversion in the following code is a relative, normalized mapping of TLS pulse counts to LAD values, normalized by the highest voxel return and normalized using a fixed LAD_max. This gives a plausible LAD field usable for analysis, visualization, or simulation input (e.g. for ENVI-met).\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\nlibrary(terra)\nconvert_matrix_to_df &lt;- function(mat) {  \n  df &lt;- as.data.frame(mat)  \n  colnames(df) &lt;- attr(mat, \"dimnames\")[[2]]  \n  return(df)\n}\n\n# --- Preprocess LiDAR data into voxel metrics -------------------------------\nvox_out &lt;- preprocess_voxels(las, grain.size = 1, maxP = zmax)  # Calculate vertical pulse metrics\nvox_df &lt;- convert_matrix_to_df(vox_out$df)                      # Convert voxel array to data.frame\n\n#' Convert TLS voxel pulse data to LAD using Beer–Lambert conversion conversion with post-normalization\n#'\n#' @param df A data.frame with pulse columns (from TLS voxelization)\n#' @param grainsize Numeric, vertical voxel height (e.g., 1 m)\n#' @param k Extinction coefficient (default: 0.3)\n#' @param scale_factor Optional multiplicative scale factor (default: 1.2)\n#' @param lad_max Optional maximum LAD clamp (e.g. 2.5); set to NULL to disable\n#' @param lad_min Optional minimum LAD threshold (e.g. 0.05); set to NULL to disable\n#' @param keep_pulses Logical, whether to retain pulse columns (default: FALSE)\n#'\n#' @return Data.frame with LAD columns added\n#' @export\nconvert_to_LAD_beer &lt;- function(df,\n                                grainsize = 1,\n                                k = 0.3,\n                                scale_factor = 1.2,\n                                lad_max = 2.5,\n                                lad_min = 0.05,\n                                keep_pulses = FALSE) {\n  df_lad &lt;- df\n  pulse_cols &lt;- grep(\"^pulses_\", names(df_lad), value = TRUE)\n  \n  for (col in pulse_cols) {\n    lad_col &lt;- paste0(\"lad_\", sub(\"pulses_\", \"\", col))\n    p_rel &lt;- df_lad[[col]] / max(df_lad[[col]], na.rm = TRUE)\n    \n    # Avoid log(0) and 1\n    p_rel[p_rel &gt;= 1] &lt;- 0.9999\n    p_rel[p_rel &lt;= 0] &lt;- 1e-5\n    \n    # Apply Beer–Lambert conversion\n    lad_vals &lt;- -log(1 - p_rel) / (k * grainsize)\n    \n    # Apply normalization\n    lad_vals &lt;- lad_vals * scale_factor\n    \n    # Clamp LAD values if needed\n    if (!is.null(lad_max)) {\n      lad_vals &lt;- pmin(lad_vals, lad_max)\n    }\n    if (!is.null(lad_min)) {\n      lad_vals &lt;- pmax(lad_vals, lad_min)\n    }\n    \n    df_lad[[lad_col]] &lt;- lad_vals\n    \n    if (!keep_pulses) {\n      df_lad[[col]] &lt;- NULL\n    }\n  }\n  \n  return(df_lad)\n}\n\n\n#' Convert TLS Pulse Counts to Leaf Area Density (LAD)\n#'\n#' Transforms vertically binned pulse counts (from voxelized TLS data) into Leaf Area Density (LAD, m²/m³)\n#' by normalizing pulse values to a specified LAD maximum.\n#'\n#' @param df A `data.frame` containing voxelized TLS pulse data. Must include columns starting with `\"pulses_\"`, \n#'           each representing pulse returns per vertical layer (e.g. `pulses_1_2m`, `pulses_2_3m`, ...).\n#' @param grainsize Numeric. The voxel edge length in meters (assumed cubic). Default is `1`.\n#' @param LADmax Numeric. The maximum LAD value in m²/m³ for relative normalization. Common values: `4.0`–`6.0`. Default is `5.0`.\n#' @param keep_pulses Logical. If `FALSE` (default), the original pulse columns are removed from the output. If `TRUE`, they are retained alongside the LAD columns.\n#'\n#' @return A modified `data.frame` with new LAD columns (`lad_1_2m`, `lad_2_3m`, ...) in m²/m³, normalized relatively to `LADmax`.\n#'\n#' @details\n#' - Each `pulses_*` column is linearly normalized by the overall maximum value across all vertical bins and locations.\n#' - The result is a relative LAD estimate, useful for ecological modeling, input to microclimate simulations (e.g., ENVI-met), or structural analysis.\n#' - Voxel volume is implicitly considered constant due to cubic assumption (via `grainsize`) but is not explicitly used here.\n#'\n#' @examples\n#' \\dontrun{\n#'   df_vox &lt;- readRDS(\"TLS/voxel_metrics.rds\")\n#'   lad_df &lt;- convert_to_LAD(df_vox, grainsize = 1, LADmax = 5)\n#'   head(names(lad_df))  # Should show lad_* columns\n#' }\n#'\n#' @export\nconvert_to_LAD &lt;- function(df, grainsize = 1, LADmax = 5.0, keep_pulses = FALSE) {  \n  # df: Data frame mit voxelisierten TLS-Daten\n# grainsize: Voxelgröße in m (würfelförmig angenommen)\n# LADmax: maximaler LAD-Wert (Literaturbasiert, z. B. 5.0 m²/m³)\n  df_lad &lt;- df  \n  pulse_cols &lt;- grep(\"^pulses_\", names(df_lad), value = TRUE)  \n  \n  # Schichtanzahl = Anzahl Pulse-Spalten\n  n_layers &lt;- length(pulse_cols)  \n  \n  # Optional: originales Maximum zur linearen Skalierung (relativ)\n  max_pulse &lt;- max(df_lad[, pulse_cols], na.rm = TRUE)  \n  \n  # Umwandlung in LAD (m²/m³) – Skaliert auf LADmax oder absolut (siehe Kommentar)\n  for (col in pulse_cols) {\n    lad_col &lt;- paste0(\"lad_\", sub(\"pulses_\", \"\", col))  \n    \n    # Hier wird RELATIV zu max_pulse skaliert → einfache Normalisierung\n    df_lad[[lad_col]] &lt;- (df_lad[[col]] / max_pulse) * LADmax  \n    \n    # Optional: löschen der Pulse-Spalten\n    if (!keep_pulses) {\n      df_lad[[col]] &lt;- NULL  \n    }\n  }\n  \n  return(df_lad)\n}\n\n\n\n# method selection\nif (lad_method == \"beer\") {\n  message(\"✔ Using Beer–Lambert conversion LAD conversion...\")\n  df_lad &lt;- convert_to_LAD_beer(\n    vox_df,\n    grainsize = 1,\n    k = k_extinction,\n    scale_factor = 0.4,\n    lad_max = 2.5,\n    lad_min = 0.0\n  )\n} else if (lad_method == \"linear\") {\n  message(\"Using linear LAD conversion...\")\n  df_lad &lt;- convert_to_LAD(\n    vox_df,\n    grainsize = 1,\n    LADmax = 5.0\n  )\n} else {\n  stop(\"Unknown LAD conversion method: choose 'linear' or 'beer'\")\n}\n\n\n\n\n\nDT::datatable(head(df_lad, 5))\n\n\n\n\n\n\n\nRaster Stack Representation of 3D Vegetation (Voxel-Based)\nWe represent 3D vegetation using a voxel-based raster stack:\n\nSpace is divided into cubic voxels (e.g. 1 × 1 × 1 m).\nEach raster layer represents a height slice (e.g. 0–1 m, 1–2 m, …).\nVoxels store values like pulse counts or Leaf Area Density (LAD).\n\nThis 2D stack structure enables:\n\nVertical profiling of vegetation per XY column.\nLayer-wise analysis (e.g. median, entropy).\nIntegration with raster data like topography or irradiance.\nUse in raster-based ecological and microclimate models.\n\nIt supports both analysis and visualization of vertical structure with standard geospatial tools.\nENVI-met supports custom vegetation input via the SimplePlant method, which requires a vertical LAD profile per grid column. A raster stack derived from TLS data provides exactly this: each layer represents LAD in a specific height slice, and each XY cell corresponds to one vertical profile. This structure can be exported as CSV, ASCII rasters, or custom profile files.\nFor 3D vegetation parameterization in ENVI-met 5.8+, the raster stack enables preprocessing of spatially explicit LAD or LAI profiles, even if some reformatting is needed.\nThe raster stack also supports canopy clustering and prototyping. It allows classification of structural types, simplification of complex vegetation, and the creation of representative profiles for simulation.\n\nlibrary(terra)\n# In SpatRasterStack umwandeln\nxy &lt;- df_lad[, c(\"X\", \"Y\")]  \nlad_vals &lt;- df_lad[, grep(\"^lad_\", names(df_lad), value = TRUE)]  \n\nlad_raster &lt;- rast(cbind(xy, lad_vals), type = \"xyz\")  \nplot(lad_raster)\n\n\n\n\n\n\n\n\nIn a more 3D version it looks like below.\n\n# #| eval: false\n# #| include: false\n# library(terra)\n# library(rgl)\n# \n# # Threshold value for LAD\n# threshold &lt;- 0.1 # change as needed\n# \n# # Step 1: Convert raster to voxel data frame\n# rast_cube &lt;- lad_raster  # your raster stack\n# voxel_df &lt;- as.data.frame(rast_cube, xy = TRUE, na.rm = TRUE)\n# names(voxel_df) &lt;- c(\"x\", \"y\", paste0(\"z\", seq_len(nlyr(rast_cube))))\n# \n# # Step 2: Reshape to long format\n# voxel_long &lt;- reshape(\n#   voxel_df,\n#   direction = \"long\",\n#   varying = paste0(\"z\", seq_len(nlyr(rast_cube))),\n#   v.names = \"val\",\n#   timevar = \"z\",\n#   times = seq_len(nlyr(rast_cube))\n# )\n# \n# # Step 3: Clean up and filter by threshold\n# voxel_long &lt;- voxel_long[!is.na(voxel_long$val) & voxel_long$val &gt; threshold, ]\n# voxel_long$z &lt;- as.numeric(voxel_long$z)\n# \n# # Step 4: Normalize colors\n# colors &lt;- terrain.colors(100)[cut(voxel_long$val, breaks = 100)]\n# \n# # Step 5: Draw voxel cubes\n# open3d(useNULL = TRUE)\n# for (i in seq_len(nrow(voxel_long))) {\n#   shade3d(\n#     translate3d(cube3d(scale = 1), \n#                 voxel_long$x[i], \n#                 voxel_long$y[i], \n#                 voxel_long$z[i]),\n#     color = colors[i],\n#     alpha = 0.8\n#   )\n# }\n# \n# # Step 6: Render in browser\n# # Determine the bounds of your voxel space\n# xlim &lt;- range(voxel_long$x)\n# ylim &lt;- range(voxel_long$y)\n# zlim &lt;- range(voxel_long$z)\n# \n# # Draw bounding box\n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[1], zlim[1])\n# ), col = \"black\", lwd = 2)\n# \n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[1], zlim[2])\n# ), col = \"black\", lwd = 2)\n# \n# for (i in 1:4) {\n#   lines3d(\n#     rbind(\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[1]),\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[2])\n#     ), col = \"black\", lwd = 2\n#   )\n# }\n# \n# # Optional: Add coordinate axes\n# axes3d(edges = c(\"x--\", \"y--\", \"z--\"), col = \"gray40\")\n# title3d(xlab = \"X\", ylab = \"Y\", zlab = \"Z\")\n# widget &lt;- rglwidget()\n# htmlwidgets::saveWidget(widget, \"tree_voxel_viewer.html\", selfcontained = TRUE)\n\n\n\nVisualization\n\nLAD Profile Visualizations from TLS Data\nThe plot_lad_profiles() function visualizes vertical leaf area density (LAD) profiles derived from voxelized TLS (terrestrial laser scanning) data. LAD represents leaf surface area per unit volume (m²/m³). The function provides three main plot styles:\n\n\n1. XY Matrix Plot (plotstyle = \"each_median\")\n\nDisplays a grid of mini-profiles, each representing a 0.5 × 0.5 m (x/y) ground column.\nWithin each cell, a normalized vertical LAD profile is plotted:\n\nY-axis (height) is normalized from 0 to 1 per column.\nX-axis shows LAD values normalized relative to the global LAD maximum.\n\nUseful for comparing structural patterns across space.\n\n\n\n2. Overall Median Profile (plotstyle = \"all_median\")\n\nAggregates LAD values across all (x/y) locations by height bin.\nProduces a typical vertical profile using the median and smoothed with a moving average.\nHeight is shown in absolute units (e.g. meters).\nCaptures the dominant vertical canopy structure.\n\n\n\n3. Single Profile (plotstyle = \"single_profile\")\n\nExtracts and plots the LAD profile at a specific (x, y) coordinate.\nBoth LAD and height are shown in absolute units.\nPlots the true vertical structure at one location.\n\nThe matrix plot shows multiple vertical LAD profiles arranged in a grid, with each small plot corresponding to a specific spatial location. This allows the vertical vegetation structure to be viewed in relation to its position on the ground. To make the individual profiles comparable, both height and LAD values are normalized within the plot. A reference profile on the side shows the overall median LAD distribution by height, which helps interpret the scale and shape of the individual profiles.\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\n# --- Reshape LAD data to long format ----------------------------------------\n\nlad_df &lt;- as.data.frame(lad_raster, xy = TRUE, na.rm = TRUE)     # Convert raster to data.frame\n\n# 1. Extract LAD columns and XY coordinates\npulse_cols &lt;- grep(\"^lad_\", names(lad_df), value = TRUE)\nxy_cols &lt;- c(\"x\", \"y\")  # Adjust to \"X\", \"Y\" if needed\n\n# 2. Reshape to long format (one row per LAD layer)\nlad_df &lt;- reshape(\n  data = lad_df[, c(xy_cols, pulse_cols)],\n  varying = pulse_cols,\n  v.names = \"LAD\",\n  timevar = \"layer\",\n  times = pulse_cols,\n  direction = \"long\"\n)\n\n# 3. Extract z-layer information from column names\nlad_df$z_low  &lt;- as.numeric(sub(\"lad_(\\\\d+)_.*\", \"\\\\1\", lad_df$layer))  \nlad_df$z_high &lt;- as.numeric(sub(\"lad_\\\\d+_(\\\\d+)m\", \"\\\\1\", lad_df$layer))  \n\n# 4. Compute mid-point height of each voxel layer\nlad_df$Height &lt;- (lad_df$z_low + lad_df$z_high) / 2  \n\n# 5. Round to whole meters to create height classes\nlad_df$Height_bin &lt;- round(lad_df$Height)  \n\n# --- Aggregate median LAD per 0.5 × 0.5 m column ----------------------------\nsetDT(lad_df)  # Use data.table for efficient aggregation\n\nlad_by_column &lt;- lad_df[  \n  , .(LAD_median = median(LAD, na.rm = TRUE)), \n  by = .(x, y, Height_bin)\n]\n\n# Convert back to regular data.frame\nlad_df &lt;- as.data.frame(lad_by_column)\n\nplot_lad_profiles &lt;- function(lad_df, plotstyle = c(\"each_median\", \"all_median\", \"single_profile\"),  \n                              single_coords = c(NA, NA)) {\n  plotstyle &lt;- match.arg(plotstyle)  \n  \n  # Combine x and y coordinates into a unique column ID\n  lad_df$col_id &lt;- paste(lad_df$x, lad_df$y, sep = \"_\")  \n  x_levels &lt;- sort(unique(lad_df$x))  \n  y_levels &lt;- sort(unique(lad_df$y))  \n  # Convert x/y coordinates to factor variables for matrix layout\n  lad_df$x_f &lt;- factor(lad_df$x, levels = x_levels)  \n  lad_df$y_f &lt;- factor(lad_df$y, levels = y_levels)  \n  n_x &lt;- length(x_levels)  \n  n_y &lt;- length(y_levels)  \n  \n  # Determine the maximum LAD value for relative normalization\n  lad_max &lt;- max(lad_df$LAD_median, na.rm = TRUE)  \n  height_range &lt;- range(lad_df$Height_bin, na.rm = TRUE)  \n  dx &lt;- 0.8  \n  dy &lt;- 0.8  \n  \n  par(mar = c(5, 5, 4, 5), xpd = TRUE)\n  \n \n\n  \n  # Differentiate by plot type: all profiles, overall profile, or single profile\n  if (plotstyle == \"each_median\") {\n # Load PNG legend\nlegend_img &lt;- png::readPNG(\"output.png\")\n\n# Define aspect-preserving image placement\nimg_height_units &lt;- 20\nimg_width_units &lt;- img_height_units * dim(legend_img)[2] / dim(legend_img)[1]  # preserve ratio\n\n# Define position\nimg_x_left &lt;- n_x + 1.5\nimg_x_right &lt;- img_x_left + img_width_units\nimg_y_bottom &lt;- 0\nimg_y_top &lt;- img_y_bottom + img_height_units\n\n# Begin plot\nplot(NA, xlim = c(1, n_x + img_width_units + 4), ylim = c(1, n_y),\n     type = \"n\", axes = FALSE, xlab = \"\", ylab = \"\",\n     main = \"Vertical LAD Profiles in XY Matrix\", asp = 1.2)\n\n\n# Draw all LAD profiles\nfor (i in seq_along(x_levels)) {\n  for (j in seq_along(y_levels)) {\n    profile &lt;- subset(lad_df, x == x_levels[i] & y == y_levels[j])\n    if (nrow(profile) == 0) next\n    lad_scaled &lt;- profile$LAD_median / lad_max\n    height_scaled &lt;- (profile$Height_bin - min(height_range)) / diff(height_range)\n    lines(x = lad_scaled * dx + i,\n          y = height_scaled * dy + j,\n          col = \"darkgreen\", lwd = 1)\n  }\n}\n\n# Axis labels for ground position\naxis(1, at = 1:n_x, labels = round(x_levels, 1), las = 2)\naxis(2, at = 1:n_y, labels = round(y_levels, 1), las = 2)\n\n# Add the image\nrasterImage(legend_img,\n            xleft = img_x_left,\n            xright = img_x_right,\n            ybottom = img_y_bottom,\n            ytop = img_y_top)\n\n    \n  } else if (plotstyle == \"all_median\") {\n    unique_heights &lt;- sort(unique(lad_df$Height_bin))  \n    lad_median &lt;- numeric(length(unique_heights))  \n    for (i in seq_along(unique_heights)) {\n      h &lt;- unique_heights[i]  \n      lad_median[i] &lt;- median(lad_df$LAD[lad_df$Height_bin == h], na.rm = TRUE)  \n    }\n    lad_smooth &lt;- stats::filter(lad_median, rep(1/3, 3), sides = 2)  \n    \n    plot(\n      lad_smooth, unique_heights,\n      type = \"l\",\n      col = \"darkgreen\",\n      lwd = 2,\n      xlab = \"Leaf Area Density (m²/m³)\",\n      ylab = \"Height (m)\",\n      main = \"Vertical LAD Profile (smoothed)\",\n      xlim = c(0, max(lad_smooth, na.rm = TRUE)),\n      ylim = range(unique_heights)\n    )\n    \n    text(\n      x = as.numeric(lad_smooth),\n      y = unique_heights,\n      labels = round(as.numeric(lad_smooth), 1),\n      pos = 4,\n      cex = 0.7,\n      col = \"black\"\n    )\n    grid()\n    \n    \n  } else if (plotstyle == \"single_profile\") {\n    x_target &lt;- single_coords[1]  \n    y_target &lt;- single_coords[2]  \n    tol &lt;- 1e-6  \n    \n    profile &lt;- subset(lad_df, abs(x - x_target) &lt; tol & abs(y - y_target) &lt; tol)  \n    \n    if (nrow(profile) == 0) {\n      # Show warning if no profile exists for selected coordinates\n      warning(\"No data for the selected coordinates.\")\n      plot.new()\n      title(main = paste(\"No profile at\", x_target, \"/\", y_target))\n      return(invisible(NULL))\n    }\n    \n    # Normalize height and LAD\n    height_range &lt;- range(profile$Height_bin, na.rm = TRUE)  \n    # Determine the maximum LAD value for relative normalization\n    lad_max &lt;- max(profile$LAD_median, na.rm = TRUE)  \n    \n    height_scaled &lt;- (profile$Height_bin - min(height_range)) / diff(height_range)  \n    height_unscaled &lt;- profile$Height_bin\n    # Determine the maximum LAD value for relative normalization\n    lad_scaled &lt;- profile$LAD_median / lad_max  \n    \n    plot(\n      x = lad_scaled,\n      y = height_unscaled, #height_scaled,\n      type = \"l\",\n      lwd = 2,\n      col = \"darkgreen\",\n      xlab = \"LAD (normalized)\",\n      ylab = \"Height (m)\",\n      main = paste(\"Profile at\", x_target, \"/\", y_target)\n    )\n  }\n}\n# --- Visualize LAD profiles -------------------------------------------------\n\n\n\n\n\n# Option 1: Profile in each column\nplot_lad_profiles(lad_df, plotstyle = \"each_median\")\n\n\n\n\n\n\n\n# Option 2: Overall vertical LAD profile (median of all)\nplot_lad_profiles(lad_df, plotstyle = \"all_median\")\n\n\n\n\n\n\n\n# Option 3: Single profile at specified coordinates\nplot_lad_profiles(lad_df, plotstyle = \"single_profile\", single_coords = c(57.5, -94.5))"
  },
  {
    "objectID": "doc/tls_v1_1.html#envi-met-3d-tree-export",
    "href": "doc/tls_v1_1.html#envi-met-3d-tree-export",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "ENVI-met 3D Tree Export",
    "text": "ENVI-met 3D Tree Export\nThe next section describes more detailed how the key input values in the R function export_lad_to_envimet3d() are computed, derived or selected, and provides the rationale for each. The function converts a voxel-based Leaf Area Density (LAD) profile, typically obtained from Terrestrial Laser Scanning (TLS) data, into a structured XML file compatible with ENVI-met’s 3D tree model (.pld or PLANT3D).\nGiven the sensitivity of ENVI-met simulations to tree morphology and LAD distribution, the function ensures that the spatial dimensions, vertical layering and LAD intensity values are all correctly represented. Some parameters are optional, but can be derived from the data if not explicitly set.\nThe table below details each argument of the function, including its purpose, how it is determined and its necessity.\n\n\n\n\n\n\n\n\nCode Line\nMeaning\nReason\n\n\n\n\nlad_df &lt;-lad_df[!is.na(lad_df$LAD_median), ]\nRemoves entries with missing LAD values\nEnsures only valid data is used in the LAD calculation and XML export\n\n\nlad_df$i &lt;-as.integer(factor(lad_df$x))\nConverts x-coordinates to integer voxel column indices (i)\nRequired for ENVI-met LAD matrix indexing\n\n\nlad_df$j &lt;-as.integer(factor(lad_df$y))\nConverts y-coordinates to integer voxel row indices (j)\nSame as above, for the y-direction\n\n\nz_map &lt;-setNames( ...)\nMaps unique height bins to sequential vertical indices (k)\nTranslates height levels into voxel layers compatible with ENVI-met\n\n\nlad_df$k &lt;-z_map[as.character(lad_df$Height_bin)]\nApplies the vertical index to the LAD data\nAligns LAD values with ENVI-met vertical layer system\n\n\nlad_df$lad_value &lt;-round(lad_df$LAD_median * scale_factor, 5)\nScales LAD values and rounds to 5 digits\nBrings LAD values to a usable range for ENVI-met and ensures precision\n\n\ndataI &lt;-max(lad_df$i)\nGets the number of horizontal grid cells in i-direction (width)\nRequired as matrix size input for ENVI-met\n\n\ndataJ &lt;-max(lad_df$j)\nGets the number of horizontal grid cells in j-direction (depth)\nRequired as matrix size input for ENVI-met\n\n\nzlayers &lt;-max(lad_df$k)\nGets the number of vertical layers\nSets the height resolution of the LAD matrix"
  },
  {
    "objectID": "doc/tls_v1_1.html#automatic-grid-dimensions-transformation",
    "href": "doc/tls_v1_1.html#automatic-grid-dimensions-transformation",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Automatic Grid Dimensions transformation",
    "text": "Automatic Grid Dimensions transformation\nCalculates the voxel grid dimensions in X, Y, and Z from the TLS-derived LAD profile.\nThe table below outlines how the core spatial and structural parameters of the tree model are computed from the input LAD_DF data frame. These derived values define the three-dimensional structure of the tree in terms of its horizontal extent, vertical layering and canopy dimensions.\nData I and data J represent the size of the voxel grid in the i and j dimensions, respectively, based on unique horizontal (x and y) and vertical (height bin) bins in the LAD profile.\n‘Width’ and ‘Depth’ describe the physical spread of the tree crown, inferred from the voxel grid extent if not manually set.\nHeight is computed by multiplying the number of vertical layers (zlayers) by the voxel resolution (cellSize), providing the total modelled height of the canopy.\nThese computed values are essential for correctly normalization and locating the 3D LAD matrix within the ENVI-met simulation domain to ensure visual and physiological realism.\n\n\n\n\n\n\n\n\nCode Line\nMeaning\nReason\n\n\n\n\nWidth  &lt;- if (is.null(Width)) dataI else Width\nUses the number of i-cells if Width is not provided\nAutomatically estimates tree width from voxel spread in x-direction\n\n\nDepth  &lt;- if (is.null(Depth)) dataJ else Depth\nUses the number of j-cells if Depth is not provided\nAutomatically estimates tree depth from voxel spread in y-direction\n\n\nHeight &lt;- zlayers * cellsize\nConverts number of vertical layers to metric height using cellsize\nComputes physical tree height in meters for ENVI-met\n\n\n\n# 1. Remove NA values from the LAD column\nlad_df &lt;- lad_df[!is.na(lad_df$LAD_median), ]\n\n# 2. Create discrete i and j indices for the horizontal position\n# (converts x and y coordinates into consecutive index values)\nlad_df$i &lt;- as.integer(factor(lad_df$x))\nlad_df$j &lt;- as.integer(factor(lad_df$y))\n\n# 3. Assign each Height_bin (z direction) a consecutive layer ID k\n# (z_map assigns an index layer to each unique height)\nz_map &lt;- setNames(seq_along(sort(unique(lad_df$Height_bin))), sort(unique(lad_df$Height_bin)))\nlad_df$k &lt;- z_map[as.character(lad_df$Height_bin)]\n\n# 4. Scale LAD values, e.g. to get from 0.02 to more realistic values such as 0.5–1.5\nlad_df$lad_value &lt;- round(lad_df$LAD_median * scale_factor, 5)\n\n# 5. Calculate the maximum dimensions of the grid (for XML specifications)\ndataI &lt;- max(lad_df$i) # Width in cells (x-direction)\ndataJ &lt;- max(lad_df$j) # Depth in cells (y-direction)\nzlayers &lt;- max(lad_df$k) # Number of vertical layers (z-direction)"
  },
  {
    "objectID": "doc/tls_v1_1.html#transmittance-and-albedo",
    "href": "doc/tls_v1_1.html#transmittance-and-albedo",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Transmittance and Albedo",
    "text": "Transmittance and Albedo\nAlbedo = 0.18\nTransmittance = 0.3\nAlbedo = 0.18: Albedo is the fraction of incoming solar radiation reflected by the canopy surface. For deciduous trees, values usually range between 0.15 and 0.20. 0.18 is a commonly used default for broadleaved species like Fagus sylvatica or Quercus robur in many ecological models (e.g., ENVI-met, MAESPA). It affects surface energy balance and radiation reflection in ENVI-met simulations.\nTransmittance = 0.3: Transmittance represents the proportion of shortwave radiation that passes through the canopy without being absorbed or reflected. Deciduous trees in full leaf have transmittance values between 0.1 and 0.4 depending on species and LAI. 0.3 reflects moderate canopy density, consistent with empirical observations for mid-summer crowns. It controls how much light reaches the ground and sub-canopy vegetation; affects microclimate and shading.\nBoth values can be adjusted to match field measurements or literature for specific species or leaf phenology. However you can use them as robust fallback defaults when exact species traits are unavailable."
  },
  {
    "objectID": "doc/tls_v1_1.html#season-profile",
    "href": "doc/tls_v1_1.html#season-profile",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Season-Profile",
    "text": "Season-Profile\nDefines monthly LAD normalization.\nSeasonProfile = c(0.2, 0.2, 0.4, 0.7, 1.0, 1.0, 1.0, 0.8, 0.6, 0.3, 0.2, 0.2)\nThe SeasonProfile is a vector of 12 numeric values (one per month) weighting the relative Leaf Area Density (LAD) throughout the year. It models seasonal leaf development and senescence, controlling how much foliage is present in each month:\n\nValues range from 0.0 (no foliage) to 1.0 (full foliage).\nFor deciduous trees like Fagus sylvatica or Quercus robur, foliage develops in spring (April–May), peaks in summer (June–August), and declines in autumn (September–October).\n\nProfile Breakdown:\n\n\n\nMonths\nValue\nInterpretation\n\n\n\n\nJan–Feb, Nov–Dec\n0.2\nDormant / leafless\n\n\nMarch\n0.4\nBudburst begins\n\n\nApril\n0.7\nLeaf expansion\n\n\nMay–July\n1.0\nFull canopy\n\n\nAugust\n0.8\nLeaf maturity decline\n\n\nSeptember\n0.6\nSenescence onset\n\n\nOctober\n0.3\nStrong senescence\n\n\n\nThe SeasonProfile directly influences LAD in ENVI-met’s dynamic vegetation simulation — affecting transpiration, shading, and energy balance across the simulation year. Adjusting this vector allows tailoring of phenology to site-specific or species-specific data."
  },
  {
    "objectID": "doc/tls_v1_1.html#l-systembased-trees-in-envi-met-experimetal",
    "href": "doc/tls_v1_1.html#l-systembased-trees-in-envi-met-experimetal",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "L-SystemBased trees in ENVI-met (Experimetal)",
    "text": "L-SystemBased trees in ENVI-met (Experimetal)\nENVI-met optionally allows procedural generation of tree architecture using Lindenmayer Systems (L-Systems) — a formal grammar originally used to simulate plant growth patterns. When L-SystemBased = 1, the geometry of the tree is not derived from a static LAD matrix alone, but supplemented or replaced by rule-based 3D branching structures which supplement or replace the matrix. This is independent of the LAD profile but may affect shading and visualisation in the Albero interface of ENVI-met.\nL-SystemBased = 1\nAxiom = \"F(2)V\\V\\\\V/////B\"\nIterationDepth = 3\n\nExplanation of Key Parameters\n\n\n\n\n\n\n\nParameter\nMeaning\n\n\n\n\nL-SystemBased\nIf 1, enables L-system generation (uses rules to grow plant structure)\n\n\nAxiom\nStarting string (“seed”) for the L-system; defines base growth\n\n\nIterationDepth\nHow many times to apply production rules; higher means more detail\n\n\nTermLString\nOptional: Final symbol to be drawn/rendered (e.g. “L”)\n\n\nApplyTermLString\nIf 1, interprets the TermLString; otherwise, renders entire string\n\n\n\n\n\nDefault Settings\n\n\n\nL-System Branching as implemented by default\n\n\n&lt;L-SystemBased&gt;1&lt;/L-SystemBased&gt;\n&lt;Axiom&gt;F(2)V\\V\\\\V/////B&lt;/Axiom&gt;\n&lt;IterationDepth&gt;3&lt;/IterationDepth&gt;\n&lt;TermLString&gt;L&lt;/TermLString&gt;\n&lt;ApplyTermLString&gt;1&lt;/ApplyTermLString&gt;\n\nF(2): Move forward with length 2 (main trunk)\nV\\\\V/////B: Branching pattern with rotations (backslashes and slashes encode rotation commands); B may denote a terminal leaf or bud\nIterationDepth = 3: The production rules (if defined) will be applied 3 times to this axiom, generating a fractal-like tree structure.\n\n\nNote: In ENVI-met, the actual grammar rules are hard-coded and not customizable in .pld — only the axiom and iteration depth are user-defined. It is highly experimental and poorly documented\n\nUse L-SystemBased = 1 if:\n\nYou want visual structure added to otherwise sparse or low-resolution LAD matrices\nThe tree lacks realistic shape (for Albero visualization)\nUse L-SystemBased = 0 (default) if:\n\nYou already provide a dense voxel-based LAD (from TLS or similar)\nYou want strict control over the 3D structure via LAD profile only\n\n\n\n\nImport TLS-based .pld into ENVI-met via Albero Clipboard\nRequirements\n- ENVI-met 5.8+\n- .pld file (e.g. oak_tls_envimet.pld)\n- Albero editor (via Leonardo)\nSteps\n1. Open Albero\n→ Leonardo → Database → Plant Database\n2. Open Clipboard\n→ Click Clipboard (top-right)\n3. Import .pld\n→ Clipboard → Import → Load file\n4. Edit (optional)\n→ Adjust LAD, albedo, transmittance, name, etc.\n5. Send to Library\n→ Click “Send to Library”\n6. Use in ENVI-met\n→ In Leonardo/Spaces assign plant to your 3D model\nNotes\n- .pld contains LAD(z) values (m²/m³)\n- Use Advanced Settings to fine-tune visualization\n- Custom plants stored in your personal Albero library"
  },
  {
    "objectID": "doc/tls_v1_1.html#key-benefits",
    "href": "doc/tls_v1_1.html#key-benefits",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Key Benefits",
    "text": "Key Benefits\n\nEfficient and scalable: The method avoids destructive sampling by using TLS return counts as proxies for leaf density. This makes it suitable for large-scale or repeated surveys without the need for time-consuming ground calibration.\nCaptures structural patterns: Normalizing the LAD values retains the vertical and spatial structure of vegetation, enabling meaningful comparison of crown shape, canopy layering, and vegetation density across space or time.\nDirectly usable in ENVI-met: The output is structured as a raster stack with height-specific layers, aligning with the input requirements of ENVI-met’s SimplePlant or 3D vegetation modules. This enables seamless integration into microclimate simulations."
  },
  {
    "objectID": "doc/tls_v1_1.html#limitations",
    "href": "doc/tls_v1_1.html#limitations",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Limitations",
    "text": "Limitations\n\nSimplified assumptions: The linear mapping of TLS returns to LAD assumes a proportional relationship, which simplifies the complex interaction between laser pulses and vegetation surfaces.\nScan geometry dependency: Occlusion, scan angle, and varying point densities can distort the return distribution, especially in dense or multi-layered vegetation.\nGeneric LAD normalization: The maximum LAD value used for normalization is taken from literature-based estimates rather than site-specific measurements, which can introduce bias in absolute LAD magnitudes."
  },
  {
    "objectID": "doc/tls_v1_1.html#conclusion",
    "href": "doc/tls_v1_1.html#conclusion",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Conclusion",
    "text": "Conclusion\nThis workflow offers a robust and accessible approach for analyzing vegetation structure and generating model-ready LAD profiles from TLS data. It is especially useful for relative comparisons and ecological modeling, but is not intended for absolute LAD quantification without additional calibration."
  },
  {
    "objectID": "doc/tls_v1_1.html#why-als-requires-a-specific-lad-approach",
    "href": "doc/tls_v1_1.html#why-als-requires-a-specific-lad-approach",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Why ALS Requires a Specific LAD Approach",
    "text": "Why ALS Requires a Specific LAD Approach\nUnlike TLS (Terrestrial Laser Scanning), which scans from the bottom-up and suffers from occlusion in upper layers, ALS samples vegetation top-down. This means:\n\nALS oversamples upper canopy layers\nALS undersamples lower canopy due to occlusion\n\nTo correct for this sampling bias, we estimate LAD using a modified form of Beer’s Law, based on the normalized proportion of hits per voxel layer. The key difference lies in the way “gap probability” is estimated: rather than tracking cumulative occlusion, ALS uses the maximum return count per column as a proxy for full canopy closure."
  },
  {
    "objectID": "doc/tls_v1_1.html#lad-estimation-using-beers-law",
    "href": "doc/tls_v1_1.html#lad-estimation-using-beers-law",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "LAD Estimation Using Beer’s Law",
    "text": "LAD Estimation Using Beer’s Law\nWe model LAD using:\n\\[\nLAD = -\\frac{\\ln(1 - p)}{k \\cdot dz}\n\\]\nWhere: - ( p ) is the normalized proportion of hits per voxel column (( 0 &lt; p &lt; 1 )) - ( k ) is the light extinction coefficient - ( dz ) is the vertical resolution (voxel height)\nIn our script, we set: - ( k = 0.3 ) (typical value) - LAD values are scaled using a multiplicative factor (default 1.2)\n\nTLS Variant of LAD\nIn TLS-based LAD estimation, we assume that the LiDAR sensor is located near ground level and that returns are accumulated from bottom to top. In this setup, each voxel’s return count ( N_i ) is interpreted as contributing to the cumulative transmittance through the canopy.\nThe Beer–Lambert law is applied as:\n\\[\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n\\]\nHere: - ( N_i ): number of returns in voxel layer ( i ) - ( N_{} ): maximum number of returns in any voxel in the column (used to normalize return density) - ( z ): voxel height - ( k ): extinction coefficient\n\nPhysical Interpretation\nThe ratio ( ) estimates the fraction of light intercepted at layer ( i ), assuming the densest layer represents near-total occlusion. Thus, the term ( 1 - ) represents the gap fraction — i.e., the probability that a beam of light traveling from the ground upward has not yet been occluded by vegetation up to that layer.\nThis interpretation fits the TLS scanning geometry, where lower layers are sampled first and occlusion increases with height.\n\n\n\nALS Variant Used Here\nWe assume that the highest return count in the column corresponds to full canopy closure (i.e., near-zero gap fraction). This allows us to use the maximum as a local normalization factor:\n\n( p_i = )\n( LAD_i = -(1 - p_i) / (k dz) )\n\nThis does not model occlusion directly, but gives a consistent LAD profile for column-wise clustering."
  },
  {
    "objectID": "doc/tls_v1_1.html#full-workflow-voxelization-to-envi-met-3d-trees",
    "href": "doc/tls_v1_1.html#full-workflow-voxelization-to-envi-met-3d-trees",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Full Workflow: Voxelization to ENVI-met 3D Trees",
    "text": "Full Workflow: Voxelization to ENVI-met 3D Trees\n\nNormalize ALS Height and Filter Ground\nlas &lt;- readLAS(las_file)\nlas &lt;- normalize_height(las, knnidw(k = 6, p = 2))\nlas &lt;- filter_poi(las, Z &gt; 0)\n\n\nVoxelize ALS Point Cloud\nvoxels &lt;- voxel_metrics(las, ~length(Z), res = res_xy, dz = res_z)\n\n\nConvert Voxel Counts to LAD using ALS-based Beer’s Law\nlad_df &lt;- convert_voxel_lad_long(voxels, res_z = res_z, k = k, scale_factor = scale_factor)\n\n\nCluster Similar LAD Profiles\nWe reduce the number of ENVI-met profiles by grouping similar LAD profiles using k-means clustering. LAD profiles are pivoted to a wide matrix (z-layers as columns):\nlad_df$xy_key &lt;- paste(lad_df$x, lad_df$y)\nlad_matrix &lt;- lad_df %&gt;% \n  tidyr::pivot_wider(names_from = z, values_from = lad, values_fill = 0) %&gt;%\n  column_to_rownames(\"xy_key\") %&gt;%\n  as.matrix()\nclustering &lt;- kmeans(lad_matrix, centers = n_clusters, nstart = 10)\nlad_df$cluster &lt;- clustering$cluster[match(lad_df$xy_key, rownames(lad_matrix))]\n\n\nAssign 6-Character ENVIMET_IDs\nEach LAD cluster is assigned a unique identifier that begins with “S” and uses base36 encoding (0–9, A–Z):\nint_to_base36 &lt;- function(n, width = 5) {\n  chars &lt;- c(0:9, LETTERS)\n  base &lt;- length(chars)\n  result &lt;- character()\n  while (n &gt; 0) {\n    result &lt;- c(chars[(n %% base) + 1], result)\n    n &lt;- n %/% base\n  }\n  result &lt;- paste(result, collapse = \"\")\n  padded &lt;- sprintf(paste0(\"%0\", width, \"s\"), result)\n  paste0(\"S\", substr(gsub(\" \", \"0\", padded), 1, width))\n}\n\n\nExport Point Locations as GIS Layer\nEach unique LAD column becomes a point in a GeoPackage, tagged with its ENVIMET_ID.\nsf_points &lt;- st_as_sf(point_df, coords = c(\"x\", \"y\"), crs = crs_code)\nst_write(sf_points, output_gpkg, delete_layer = TRUE)\n\n\nExport Clustered LAD Profiles as ENVI-met 3DPLANT XML\nThe LAD profile per cluster is exported to a .pld file using XML.\nexport_lad_to_envimet3d(lad_df, file_out = xml_output_file)"
  },
  {
    "objectID": "doc/tls_v1_1.html#concept-of-pseudo-3d-tree-columns",
    "href": "doc/tls_v1_1.html#concept-of-pseudo-3d-tree-columns",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Concept of Pseudo-3D Tree Columns",
    "text": "Concept of Pseudo-3D Tree Columns\nEach clustered LAD profile is interpreted as a pseudo-3D vegetation column. These are not derived from segmented individual trees but represent aggregated vertical structure typical for a 2 × 2 m area.\nThis approach provides a balance between realism and simplicity:\n\nIt allows realistic vertical vegetation profiles from ALS\nReduces complexity through clustering\nProvides efficient integration into ENVI-met via both:\n\nGIS point layers with ENVIMET_ID\nXML-based 3DPLANT definitions\n\n\nPseudo-3D trees enable realistic microclimate domains with vegetation heterogeneity without requiring full 3D reconstruction."
  },
  {
    "objectID": "doc/tls_v1_1.html#tls-vs-als-lad-computation-summary",
    "href": "doc/tls_v1_1.html#tls-vs-als-lad-computation-summary",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "TLS vs ALS LAD Computation Summary",
    "text": "TLS vs ALS LAD Computation Summary\n\n\n\n\n\n\n\n\nAspect\nTLS\nALS\n\n\n\n\nView Direction\nBottom-up\nTop-down\n\n\nOcclusion Bias\nUndersamples upper canopy\nUndersamples lower canopy\n\n\nLAD Estimation\nCumulative bottom-up (Beer)\nNormalized per column (max count)\n\n\nTypical Use Case\nDetailed single tree analysis\nLarge-area structure sampling"
  },
  {
    "objectID": "doc/tls_v1_1.html#conclusion-and-limitations",
    "href": "doc/tls_v1_1.html#conclusion-and-limitations",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Conclusion and Limitations",
    "text": "Conclusion and Limitations\nThis pipeline offers an efficient method to integrate voxelized ALS data into ENVI-met’s 3DPLANT framework by:\n\nEstimating LAD profiles via a Beer–Lambert-based approximation\nClustering voxel columns into representative pseudo-3D vegetation types\nExporting both point geometries and XML-based plant profiles\n\nAdvantages: - Scalable to large ALS datasets - Preserves key structural heterogeneity - Compatible with ENVI-met simulation domains\nLimitations: - Assumes that the maximum voxel return represents full canopy cover, which may not hold in sparse stands - LAD estimation is empirical; it does not model true light attenuation or occlusion - The pseudo-3D approach does not represent individual trees or crown geometry - Clustering may smooth out fine-scale vertical variability\nFuture improvements could include stratified LAD normalization, occlusion-aware corrections, or hybrid ALS-TLS fusion for enhanced realism."
  },
  {
    "objectID": "doc/tls_v1_1.html#references",
    "href": "doc/tls_v1_1.html#references",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "References",
    "text": "References\n\nBéland, M., et al. (2014). Remote Sensing of Environment\nCalders, K., et al. (2015). Methods in Ecology and Evolution\nJupp, D. L. B., et al. (2009). Remote Sensing of Environment"
  },
  {
    "objectID": "doc/tls_v1_1.html#script-reference",
    "href": "doc/tls_v1_1.html#script-reference",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Script Reference",
    "text": "Script Reference\nsource(\"src/microclimate_ALS.R\")\nThis source contains the complete processing workflow from voxel metrics to XML generation."
  },
  {
    "objectID": "doc/tls_v1_1.html#references-1",
    "href": "doc/tls_v1_1.html#references-1",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "References",
    "text": "References\n\nCalders et al. (2015). Nondestructive biomass estimation via TLS. Methods Ecol Evol, 6:198–208.https://doi.org/10.1111/2041-210X.12301\nChen et al. (2018): Estimation of LAI in open-canopy forests using TLS and path length models. Agric. For. Meteorol. 263, 323–333. https://doi.org/10.1016/j.agrformet.2018.09.006\nENVI-met PLANT3D specification: https://www.envi-met.net/documents/papers/overview30.pdf\nENVI-met Albero overview: https://envi-met.com/tutorials/albero-overview\nENVI-met KB – Obtaining Leaf Area Density: https://envi-met.info/doku.php?id=kb:lad#obtaining_leaf_area_density_data\nENVI-met dbmanager documentation: https://envi-met.info/doku.php?id=apps:dbmanager:start\nENVI-met Vegetation Tutorial (YouTube): https://www.youtube.com/watch?v=KGRLnXAXZds\nFlynn et al. (2023) – TLS-based vegetation index estimation; compares methods and highlights complexities in Mediterranean forest. Biogeosciences, 20(13), 2769–2784. doi:10.5194/bg-20-2769-2023\nHosoi & Omasa (2006). Voxel-based 3D tree modeling. IEEE TGRS, 44(12), 3610–3618. https://doi.org/10.1109/TGRS.2006.881743\nPrusinkiewicz & Lindenmayer (1990). The Algorithmic Beauty of Plants. Springer. https://doi.org/10.1007/978-1-4613-8476-2\nOshio & Asawa (2016). Solar transmittance of urban trees. IEEE TGRS, 54(9), 5483–5492. https://doi.org/10.1109/TGRS.2016.2565699\nSimon, Sinsel & Bruse (2020). Fractal trees in ENVI-met. Forests, 11(8), 869. https://doi.org/10.3390/f11080869\nWilkes et al. (2017). TLS acquisition strategies. Remote Sens Environ, 196, 140–153. https://doi.org/10.1016/j.rse.2017.04.030\nChen et al. (2018). LAI from TLS. Agr Forest Meteorol, 263, 323–333. https://doi.org/10.1016/j.agrformet.2018.09.006\nYin et al. (2019). Shading and thermal comfort. Sustainability, 11(5), 1355. https://doi.org/10.3390/su11051355\nZhang (2024). Green layouts in ENVI-met. Informatica, 48(23). https://doi.org/10.31449/inf.v48i23.6881 Certainly. Here’s the reference adapted to match your current compact style:"
  },
  {
    "objectID": "doc/osm2envi.html",
    "href": "doc/osm2envi.html",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "",
    "text": "The OSM2Envi_met QGIS Processing tool provides a fully automated workflow for preparing spatial input data from OpenStreetMap (OSM) and elevation datasets for use in ENVI-met 3D simulations. It combines a Python-based QGIS interface with a shell script that performs a robust geospatial preprocessing pipeline via qgis_process, gdal, and ogr2ogr.\nThis document describes how to install the tool, explains the internal processing workflow, and provides a link to the complete codebase.",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#requirements",
    "href": "doc/osm2envi.html#requirements",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "Requirements",
    "text": "Requirements\nTo run this tool successfully, you need:\n\nQGIS 3.28+ with qgis_process installed and accessible from the command line\nGDAL with ogr2ogr and gdal_calc.py\nA Bash shell (macOS/Linux, or Git Bash on Windows)",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#setup-steps",
    "href": "doc/osm2envi.html#setup-steps",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "Setup Steps",
    "text": "Setup Steps\n\nDownload the tool:\n\nFrom GitHub as ZIP:\nhttps://github.com/gisma/qgis-processing-workflows/archive/refs/heads/main.zip\nOr clone via Git: git clone https://github.com/gisma/qgis-processing-workflows.git\n\nCopy the relevant scripts to your QGIS processing script directory:\n~/.local/share/QGIS/QGIS3/profiles/default/processing/scripts/ ├── osm2envi_qgis.sh # Main processing Bash script └── osm2envi_tool.py # QGIS Processing tool wrapper\nMake the Bash script executable:\nchmod +x osm2envi_qgis.sh\nRestart QGIS.\nThe tool will now appear under: Processing Toolbox → Envi_met Tools → OSM2Envi_met",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#osm-conversion",
    "href": "doc/osm2envi.html#osm-conversion",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "1. OSM Conversion",
    "text": "1. OSM Conversion\n\nConverts the .osm file into a multi-layered GeoPackage using ogr2ogr.",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#feature-extraction",
    "href": "doc/osm2envi.html#feature-extraction",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "2. Feature Extraction",
    "text": "2. Feature Extraction\n\nExtracts thematic layers from multipolygons or lines using SQL expressions:\n\nVegetation: landuse like forest, meadow, orchard, etc.\nSurfaces: roads and natural surfaces from highway and landuse\nBuildings: all OSM geometries tagged as building\n\nEach layer is:\n\nReprojected into the target CRS using qgis_process\nClipped to the specified extent",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#classification-envimet-id",
    "href": "doc/osm2envi.html#classification-envimet-id",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "3. Classification (ENVIMET ID)",
    "text": "3. Classification (ENVIMET ID)\n\nAssigns an ENVIMET_ID attribute based on feature type:\n\nForest → 0000SM\nAsphalt → 0200AK\nIndustrial landuse → 0200AK\nWetland → 0200LI\n\nClassification is done using SQL CASE statements in qgis_process:fieldcalculator.",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#height-extraction-optional",
    "href": "doc/osm2envi.html#height-extraction-optional",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "4. Height Extraction (optional)",
    "text": "4. Height Extraction (optional)\nIf both DSM and DEM are provided:\n\nCalculates a difference raster (DSM − DEM) using gdal_calc.py\nComputes mean building heights (height_mean) via zonal statistics\nAdds height attribute to the building layer\n\nIf no elevation data is provided, this step is skipped.",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#road-buffering",
    "href": "doc/osm2envi.html#road-buffering",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "5. Road Buffering",
    "text": "5. Road Buffering\n\nBuffers road geometries based on highway type:\n\nPrimary: 10 m, Secondary: 6 m, Tertiary: 4 m, Track: 1 m\n\nBuffers are classified like surfaces and merged later.",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#layer-merging",
    "href": "doc/osm2envi.html#layer-merging",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "6. Layer Merging",
    "text": "6. Layer Merging\n\nMerges:\n\nBuffered roads\nSurface landuse polygons\n\nCreates a unified surface layer for ENVIMET (*_surface_final.gpkg)",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#cleanup",
    "href": "doc/osm2envi.html#cleanup",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "7. Cleanup",
    "text": "7. Cleanup\n\nDeletes all intermediate files:\n\n_tmp.gpkg, _proj.gpkg, _clip.gpkg\n\nKeeps only the final classified and merged output layers",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/osm2envi.html#optimization-for-envi-met",
    "href": "doc/osm2envi.html#optimization-for-envi-met",
    "title": "QGIS ENVIMET Preprocessor",
    "section": "8. Optimization for ENVI-met",
    "text": "8. Optimization for ENVI-met\n\nRetains only necessary fields:\n\nGeometry\nENVIMET_ID\nheight_mean (if computed)\n\nSaves final layers as:\n\n*_surface_final_envimet.gpkg\n*_vegetation_final_envimet.gpkg\n*_buildings_final_envimet.gpkg",
    "crumbs": [
      "QGIS ENVIMET Preprocessor"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html",
    "href": "doc/fluxes_corrected.html",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "",
    "text": "This tutorial calculates surface energy balance components using micrometeorological observations from an energy balance station. We implement a simplified diagnostic approach based on physical theory and field measurements.\n\n\nUnderstanding the surface energy balance is essential for quantifying the partitioning of energy into heating, evaporation, and ground storage. This notebook follows a physically grounded approach to derive the key energy fluxes from field observations.\n\n\n\nThe fundamental balance at the land surface is:\n\\[ R_n = H + LE + G + S \\]\nWhere:\n\n\\(R_n\\): Net radiation \\(W/m²\\) — total energy input from shortwave and longwave radiation\n\n\\(H\\): Sensible heat flux \\(W/m²\\) — convective transfer of heat to the air\n\n\\(LE\\): Latent heat flux \\(W/m²\\) — energy used for evapotranspiration\n\n\\(G\\): Ground heat flux \\(W/m²\\) — conduction of heat into the soil\n\n\\(S\\): Storage term (e.g. canopy heat, biomass, or air column storage; neglected here)\n\nAssumption: For half-hourly or hourly timesteps and shallow sensors, we assume \\(S \\approx 0\\)$.\nTherefore, we estimate:\n\\[LE = R_n - G - H\\] ### Data Used in This Analysis\n\n\n\n\n\n\n\n\nVariable\nMeaning\nSource\n\n\n\n\nrad_bil\nApproximate net radiation (R_n)\nMeasured via 4-component radiometer or surrogate\n\n\nheatflux_soil\nGround heat flux (G)\nSoil heat flux plate\n\n\nTa_2m, Ta_10m\nAir temperature at 2 m and 10 m\nThermistors\n\n\nWindspeed_2m, Windspeed_10m\nWind speed at two heights\nAnemometers\n\n\n\nIn surface energy balance analysis, the bulk transfer and residual methods complement each other:\n\nThe bulk method estimates the sensible heat flux (\\(H\\)) using measured temperature and wind gradients.\nThe residual method then infers the latent heat flux (\\(LE\\)) by closing the energy balance using the measured net radiation (\\(R_n\\)), soil heat flux (\\(G\\)), and calculated \\(H\\).\n\nThis creates a simple yet effective hybrid approach: - Physically based: \\(H\\) is grounded in turbulence theory. - Energetically constrained: \\(LE\\) ensures energy conservation at the surface.\nTogether, they enable complete estimation of surface fluxes from standard meteorological data.",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#introduction",
    "href": "doc/fluxes_corrected.html#introduction",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "",
    "text": "This tutorial calculates surface energy balance components using micrometeorological observations from an energy balance station. We implement a simplified diagnostic approach based on physical theory and field measurements.\n\n\nUnderstanding the surface energy balance is essential for quantifying the partitioning of energy into heating, evaporation, and ground storage. This notebook follows a physically grounded approach to derive the key energy fluxes from field observations.\n\n\n\nThe fundamental balance at the land surface is:\n\\[ R_n = H + LE + G + S \\]\nWhere:\n\n\\(R_n\\): Net radiation \\(W/m²\\) — total energy input from shortwave and longwave radiation\n\n\\(H\\): Sensible heat flux \\(W/m²\\) — convective transfer of heat to the air\n\n\\(LE\\): Latent heat flux \\(W/m²\\) — energy used for evapotranspiration\n\n\\(G\\): Ground heat flux \\(W/m²\\) — conduction of heat into the soil\n\n\\(S\\): Storage term (e.g. canopy heat, biomass, or air column storage; neglected here)\n\nAssumption: For half-hourly or hourly timesteps and shallow sensors, we assume \\(S \\approx 0\\)$.\nTherefore, we estimate:\n\\[LE = R_n - G - H\\] ### Data Used in This Analysis\n\n\n\n\n\n\n\n\nVariable\nMeaning\nSource\n\n\n\n\nrad_bil\nApproximate net radiation (R_n)\nMeasured via 4-component radiometer or surrogate\n\n\nheatflux_soil\nGround heat flux (G)\nSoil heat flux plate\n\n\nTa_2m, Ta_10m\nAir temperature at 2 m and 10 m\nThermistors\n\n\nWindspeed_2m, Windspeed_10m\nWind speed at two heights\nAnemometers\n\n\n\nIn surface energy balance analysis, the bulk transfer and residual methods complement each other:\n\nThe bulk method estimates the sensible heat flux (\\(H\\)) using measured temperature and wind gradients.\nThe residual method then infers the latent heat flux (\\(LE\\)) by closing the energy balance using the measured net radiation (\\(R_n\\)), soil heat flux (\\(G\\)), and calculated \\(H\\).\n\nThis creates a simple yet effective hybrid approach: - Physically based: \\(H\\) is grounded in turbulence theory. - Energetically constrained: \\(LE\\) ensures energy conservation at the surface.\nTogether, they enable complete estimation of surface fluxes from standard meteorological data.",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#load-libraries-and-data",
    "href": "doc/fluxes_corrected.html#load-libraries-and-data",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Load Libraries and Data",
    "text": "Load Libraries and Data\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(units)\n\nenergy &lt;- read_csv(\"../data/energie_bil_wiese.csv\") %&gt;%\n  mutate(datetime = dmy_hm(datetime))",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#preprocessing",
    "href": "doc/fluxes_corrected.html#preprocessing",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Preprocessing",
    "text": "Preprocessing\n\n\nCode\nenergy &lt;- energy %&gt;%\n  rename(\n    Rn = rad_bil,\n    G = heatflux_soil,\n    Ta_2m = Ta_2m,\n    Ta_10m = Ta_10m,\n    WS_2m = Windspeed_2m,\n    WS_10m = Windspeed_10m\n  ) %&gt;%\n  mutate(\n    delta_T = Ta_10m - Ta_2m,\n    WS_mean = (WS_2m + WS_10m) / 2,\n    month_num = month(datetime),\n    month_label = case_when(\n      month_num == 6 ~ \"June\",\n      month_num == 11 ~ \"November\",\n      TRUE ~ as.character(month(datetime, label = TRUE))\n    )\n  )",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#sensible-heat-flux-h-bulk-transfer-method",
    "href": "doc/fluxes_corrected.html#sensible-heat-flux-h-bulk-transfer-method",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Sensible Heat Flux (H): Bulk Transfer Method",
    "text": "Sensible Heat Flux (H): Bulk Transfer Method\nSensible heat flux (H) is the rate at which thermal energy is transferred from the Earth’s surface to the atmosphere due to a temperature difference. It is a critical term in the surface energy balance and is especially important in meteorology, hydrology, and micrometeorology.\nIt describes how warm the surface is compared to the air above it — and how turbulent air motion carries that heat away. The bulk transfer formulation for (H) assumes a logarithmic wind profile and neutral atmospheric conditions short explanation adding to the scalar laws.\n\\[ H = \\rho c_p \\cdot \\frac{\\Delta T}{r_a} \\]\nWhere:\n\n\n\n\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(H\\)\nSensible heat flux \\(W/m²\\)\n\n\n\\(rho\\)\nAir density \\(kg/m³\\) (typically ≈ 1.225 at sea level)\n\n\n\\(c_p\\)\nSpecific heat of air at constant pressure \\(J/kg/K\\) \\(≈ 1005 J/kg/K\\)\n\n\n\\(Delta T\\)\nTemperature difference between two heights: \\(T\\_{z2} - T\\_{z1}\\) \\(K\\)\n\n\n\\(r_a\\)\nAerodynamic resistance to heat transfer \\(s/m\\)\n\n\n\n\nAerodynamic Resistance \\(r_a\\)\nAerodynamic resistance quantifies how turbulent air mixes heat. It depends on wind speed, measurement height, and surface roughness.\nFor a flat and open surface, and assuming a neutral atmosphere:\n\\[r_a = \\frac{\\ln(z_2/z_1)}{k \\cdot u_{mean}}\\]\nWhere:\n\n\n\n\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(z_1\\)\nLower measurement height (e.g. 2 m)\n\n\n\\(z_2\\)\nUpper measurement height (e.g. 10 m)\n\n\n\\(k\\)\nvon Kármán constant (≈ 0.41)\n\n\n\\(u\\_{mean}\\)\nMean horizontal wind speed between \\(z_1\\) and \\(z_2\\) \\(m/s\\)\n\n\n\n\nThis formula assumes: - horizontally homogeneous surface, - fully turbulent flow, - negligible atmospheric stability effects (i.e. neutral conditions).\n\n\n\n\n\n\n\nWind profile, buoyancy effects and turbulent scalar transport\n\n\n\n\n\n\nNote on logarithmic wind profile\nA logarithmic wind profile means that wind speed increases with height according to:\n\\[\n  u(z) = \\frac{u_*}{k} \\ln\\left(\\frac{z}{z_0}\\right)\n\\]\nwhere \\(u_*\\) is the friction velocity, \\(k\\) the von Kármán constant, and \\(z_0\\) the roughness length. This profile arises from surface-layer theory under turbulent, steady conditions.\n\n\nNote on Diagnosing Atmospheric Stability\nTo determine whether neutral atmospheric stratification applies, we estimate the Obukhov length \\(L\\), a key parameter from Monin–Obukhov similarity theory:\n\\[\nL = -\\frac{\\rho \\cdot c_p \\cdot T \\cdot u_*^3}{k \\cdot g \\cdot H}\n\\]\nwhere:\n\n\\(\\rho = 1.225\\,\\text{kg/m}^3\\): air density\n\n\\(c_p = 1005\\,\\text{J/kg/K}\\): specific heat of air\n\n\\(T\\): mean air temperature (in K)\n\n\\(u_*\\): friction velocity (approximated)\n\n\\(k = 0.41\\): von Kármán constant\n\n\\(g = 9.81\\,\\text{m/s}^2\\): gravitational acceleration\n\n\\(H\\): sensible heat flux (W/m²)\n\nWe estimate \\(u_*\\) from wind speed using the log-profile equation:\n\\[\nu_* = \\frac{k \\cdot \\bar{u}}{\\ln(z_2 / z_1)}\n\\]\nand compute:\n\n\\(T = (T_{2m} + T_{10m})/2 + 273.15\\)\n\\(\\bar{u} = (u_{2m} + u_{10m}) / 2\\)\n\nThe dimensionless height \\(z/L\\) is then used to classify stability:\n\n\\(|z/L| &lt; 0.1\\) → Neutral\n\\(z/L &gt; 0.1\\) → Stable\n\\(z/L &lt; -0.1\\) → Unstable\n\nThis allows us to screen the dataset and verify whether bulk formulations assuming neutral stratification are valid at given time steps.\n\n\nNote on Scalar Transport Laws\nTurbulent scalar transport refers to the movement of quantities like temperature or humidity due to turbulent eddies in the atmosphere. These fluxes follow a gradient–flux relationship:\n\\[\nF_\\phi = -K_\\phi \\cdot \\frac{\\partial \\phi}{\\partial z}\n\\]\nwhere:\n\n\\(F_\\phi\\): vertical flux of scalar \\(\\phi\\) (e.g. \\(T\\), \\(q\\)),\n\\(K_\\phi\\): eddy diffusivity [m²/s],\n\\(\\frac{\\partial \\phi}{\\partial z}\\): vertical gradient of the scalar.\n\nIn field applications, this is simplified into bulk transfer formulas like:\n\\[\nH = \\rho \\cdot c_p \\cdot \\frac{\\Delta T}{r_a}\n\\]\nwhich relate scalar differences to vertical fluxes via aerodynamic resistance \\(r_a\\).\n\n\n\n\n\n\nAssumptions and Limitations\n\n\n\n\n\n\n-   Assumes neutral stability — ignores buoyancy effects (unstable/stable conditions).\n\n-   Requires accurate wind and temperature measurements.\n\n-   Works best over homogeneous, flat terrain.\n\n-   May underestimate or overestimate fluxes under low wind or very moist/dry conditions.\n\n\n\n\n\nCode\n# Constants\nrho_air &lt;- set_units(1.225, \"kg/m^3\")\ncp_air &lt;- set_units(1005, \"J/kg/K\")\nz1 &lt;- 2\nz2 &lt;- 10\nk &lt;- 0.41\n\nenergy &lt;- energy %&gt;%\n  mutate(\n    ra = log(z2 / z1) / (k * WS_mean),\n    H = drop_units(rho_air * cp_air * delta_T / ra)\n  )",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#latent-heat-flux-le-residual-method",
    "href": "doc/fluxes_corrected.html#latent-heat-flux-le-residual-method",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Latent Heat Flux \\(LE\\): Residual Method",
    "text": "Latent Heat Flux \\(LE\\): Residual Method\nThe latent heat flux \\(LE\\) quantifies the energy used for evapotranspiration — the combined loss of water to the atmosphere by:\n\nevaporation from soil and wet surfaces,\ntranspiration through stomata in plants, and\nevaporation of intercepted rainfall from canopy surfaces.\n\n\nResidual Energy Balance Equation\nWhen direct measurement is unavailable, we estimate \\(LE\\) as the residual of the surface energy balance by subtracting all the known energy components from the total incoming energy:\n\\[\nLE = R_n - G - H\n\\]\nWhere:\n\n\\(LE\\): latent heat flux [W/m²]\n\\(R_n\\): net radiation [W/m²] (incoming − outgoing radiation)\n\\(G\\): ground heat flux [W/m²] (into or out of the soil)\n\\(H\\): sensible heat flux [W/m²] (convective heat to the air)\n\n\n\nAssumptions and Cautions\n\nAssumes energy balance closure (no significant storage (S)).\nErrors in \\(R_n\\), \\(G\\), or \\(H\\) directly affect \\(LE\\).\nNighttime or low-flux periods often show non-physical negative (LE).",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#linking-bulk-and-residual-approaches",
    "href": "doc/fluxes_corrected.html#linking-bulk-and-residual-approaches",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Linking Bulk and Residual Approaches",
    "text": "Linking Bulk and Residual Approaches\nTo estimate the surface energy balance components, we combine two complementary methods:\n\nSensible heat flux \\(H\\) is derived using the bulk transfer approach, which relies on measured temperature and wind speed differences at two heights.\nLatent heat flux \\(LE\\) is then calculated as the residual energy — the portion of net radiation not used for heating the air (\\(H\\)) or the soil (\\(G\\)).\n\n\n\n\n\n\n\n\n\nComponent\nBulk Transfer Method\nResidual Method\n\n\n\n\nWhat it estimates\nSensible heat flux (\\(H\\))\nLatent heat flux (\\(LE\\))\n\n\nRequired inputs\n\\(\\Delta T\\) (temp. difference), \\(\\bar{u}\\) (mean wind speed)\n\\(R_n\\) (net radiation), \\(G\\) (ground heat), and \\(H\\)\n\n\nPhysical principle\nTurbulent heat transport via scalar gradient\nEnergy conservation (surface energy balance)\n\n\nFormula used\n\\(H = \\rho \\cdot c_p \\cdot \\dfrac{\\Delta T}{r_a}\\)\n\\(LE = R_n - G - H\\)\n\n\nKey assumption\nLogarithmic wind profile, neutral stratification\nNegligible storage term \\(S \\approx 0\\)\n\n\nOutput in your case\n\\(H = 251\\,\\text{W/m}^2\\) (based on realistic inputs)\n\\(LE = 289\\,\\text{W/m}^2\\) (by residual)\n\n\n\n\nStep 1: Bulk Estimation of Sensible Heat Flux\nWe use the following measured or typical values from a grassland site at midday:\n\n\\(T_{10m} = 19.0^\\circ C\\)\n\\(T_{2m} = 18.5^\\circ C\\) → \\(\\Delta T = 0.5\\,\\text{K}\\)\nWind speeds: \\(u_{2m} = 1.2\\,\\text{m/s}\\), \\(u_{10m} = 2.0\\,\\text{m/s}\\) → \\(\\bar{u} = 1.6\\,\\text{m/s}\\)\nConstants:\n\n\\(\\rho = 1.225\\,\\text{kg/m}^3\\) (air density)\n\\(c_p = 1005\\,\\text{J/kg/K}\\) (specific heat of air)\n\\(k = 0.41\\) (von Kármán constant)\n\\(z_1 = 2\\,\\text{m}\\), \\(z_2 = 10\\,\\text{m}\\)\n\n\nAerodynamic resistance is estimated using the logarithmic wind profile assumption:\n\\[\nr_a = \\frac{\\ln(z_2 / z_1)}{k \\cdot \\bar{u}} = \\frac{\\ln(10 / 2)}{0.41 \\cdot 1.6} \\approx 2.453\\,\\text{s/m}\n\\]\nNow we insert this into the bulk formula for \\(H\\):\n\\[\nH = \\rho \\cdot c_p \\cdot \\frac{\\Delta T}{r_a} = 1.225 \\cdot 1005 \\cdot \\frac{0.5}{2.453} \\approx 251\\,\\text{W/m}^2\n\\]\n\n\nStep 2: Residual Estimation of Latent Heat Flux\nWe now assume the following additional energy balance terms are available:\n\n\\(R_n = 620\\,\\text{W/m}^2\\): net radiation (measured via radiometer)\n\\(G = 80\\,\\text{W/m}^2\\): ground heat flux (from soil heat flux plates)\n\nWe calculate latent heat flux \\(LE\\) as the residual:\n\\[\nLE = R_n - G - H = 620 - 80 - 251 = 289\\,\\text{W/m}^2\n\\]\nThis gives the amount of energy used for evaporation and transpiration, inferred from energy conservation.\n\n\nInterpretation\nBy first estimating \\(H\\) via physical gradients (bulk approach), and then applying the residual method, we close the energy balance without needing direct \\(LE\\) measurements. This is a standard practice in micrometeorology when eddy covariance data are not available.\nUsing the residual method:\n\\(LE = R_n - G - H\\)\n\n\nCode\nenergy &lt;- energy %&gt;% mutate(LE = Rn - G - H)",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#plot-seasonal-comparison-of-energy-fluxes",
    "href": "doc/fluxes_corrected.html#plot-seasonal-comparison-of-energy-fluxes",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Plot: Seasonal Comparison of Energy Fluxes",
    "text": "Plot: Seasonal Comparison of Energy Fluxes\n\n\nCode\nlibrary(ggplot2)\n\nenergy_long &lt;- energy %&gt;%\n  select(datetime, month_label, Rn, G, H, LE) %&gt;%\n  pivot_longer(cols = c(Rn, G, H, LE), names_to = \"flux\", values_to = \"value\")\n\nplot_fluxes &lt;- function(df, title) {\n  ggplot(df, aes(x = datetime, y = value, color = flux)) +\n    geom_line() +\n    labs(title = title, x = \"Time\", y = \"Flux (W/m²)\") +\n    theme_minimal()\n}\n\nplot_fluxes(filter(energy_long, month_label == \"June\"), \"Energy Fluxes in June\")\n\n\n\n\n\n\n\n\n\n\nEnergy Fluxes in June\n\nHigh latent heat flux (LE) dominates, indicating active evapotranspiration.\nSensible heat (H) remains moderate, as much energy is used to vaporize water.\nGround heat flux (G) is positive in early hours, storing heat in the soil.\n\nThis matches expectations for early summer (June): longer days, moist soils, and active vegetation cover.\n\n\nCode\nplot_fluxes(filter(energy_long, month_label == \"November\"), \"Energy Fluxes in November\")\n\n\n\n\n\n\n\n\n\n\n\nEnergy Fluxes in November\n\nLatent heat (LE) is minimal — vegetation is inactive and evapotranspiration drops.\nSensible heat (H) becomes dominant — energy heats the air due to lack of biological water flux.\nGround heat flux (G) may show inversion (soil losing heat), particularly in the evening.\n\nThis pattern reflects the dormant season, with minimal biological activity and colder atmospheric conditions.\nLegend for Energy Flux Components\n\n\n\nSymbol\nDescription\nSign Convention\n\n\n\n\n(R_n)\nNet radiation\nPositive downward\n\n\n(H)\nSensible heat flux\nPositive upward (to air)\n\n\n(LE)\nLatent heat flux\nPositive upward (evaporation)\n\n\n(G)\nGround heat flux\nPositive downward (into soil)",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#notes-on-interpretation",
    "href": "doc/fluxes_corrected.html#notes-on-interpretation",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Notes on Interpretation",
    "text": "Notes on Interpretation\n\nFluxes are sensitive to soil moisture, vegetation, radiation, and wind.\nDeviations in (R_n - G - H) often indicate instrument imbalance, storage terms, or closure errors.\nThe residual approach to compute (LE) assumes high accuracy of the measured and modeled terms.\n\n\n\n\n\n\n\nConvert to Evapotranspiration (mm/day)\n\n\n\n\n\nWe calculate latent heat flux \\(LE\\) as the residual:\n\\[\nLE = R_n - G - H = 620 - 80 - 251 = 289\\,\\text{W/m}^2\n\\]\nUsing latent heat of vaporization \\(lambda = 2.45 \\cdot 10^6\\,\\text{J/kg}\\):\n\\[\nET = \\frac{LE}{\\lambda} \\cdot \\frac{86400}{1000}\n\\]\nInsert values:\n\\[\nET = \\frac{330}{2.45 \\cdot 10^6} \\cdot 86.4 \\approx 11.64\\,\\text{mm/day}\n\\]\nOn this day, the land surface lost ~11.6 mm of water via evapotranspiration — a very high rate, consistent with moist soil, strong radiation, and active vegetation.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Berechne ET\nlambda &lt;- 2.45e6  # J/kg\nenergy &lt;- energy %&gt;%\n  mutate(\n    ET_mm_day = (LE / lambda) * 86400,\n    month_label = month(datetime, label = TRUE, abbr = FALSE)\n  )\n\n# Aggregiere pro Monat\nmonthly_et &lt;- energy %&gt;%\n  filter(!is.na(ET_mm_day)) %&gt;%\n  group_by(month_label) %&gt;%\n  summarise(\n    mean_ET = mean(ET_mm_day, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Plot\nggplot(monthly_et, aes(x = month_label, y = mean_ET, fill = month_label)) +\n  geom_col(show.legend = FALSE) +\n  labs(\n    title = \"Mean Daily Evapotranspiration (ET) from Residual Method\",\n    x = \"Month\",\n    y = \"Evapotranspiration (mm/day)\"\n  ) +\n  scale_fill_manual(values = c(\"June\" = \"tomato\", \"November\" = \"turquoise3\")) +\n  theme_minimal()",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#export-optional",
    "href": "doc/fluxes_corrected.html#export-optional",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Export (Optional)",
    "text": "Export (Optional)\n\n\nCode\n# write_csv(energy, \"../data/processed_energy_fluxes.csv\")",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#complete-code",
    "href": "doc/fluxes_corrected.html#complete-code",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "Complete Code",
    "text": "Complete Code\n\n\nCode\n# Setup: source external script\nsource(\"../doc/fluxes_corrected.R\")\n\n\n\n\nCode\n# Load required libraries\nlibrary(tidyverse)   # Core tidyverse packages (readr, dplyr, ggplot2, etc.)\nlibrary(lubridate)   # For working with dates and times\nlibrary(units)       # For physical units (e.g., J/kg/K)\n\n# Load energy flux data and parse datetime column\nenergy &lt;- read_csv(\"../data/energie_bil_wiese.csv\") %&gt;%\n  mutate(datetime = dmy_hm(datetime))  # Convert 'datetime' column from character to POSIXct\n\n## ----------------------------------------------------------------------\n# Rename and derive key variables from measurements\n\nenergy &lt;- energy %&gt;%\n  rename(\n    Rn = rad_bil,            # Net radiation\n    G = heatflux_soil,       # Soil heat flux\n    Ta_2m = Ta_2m,            # Air temperature at 2 m\n    Ta_10m = Ta_10m,          # Air temperature at 10 m\n    WS_2m = Windspeed_2m,     # Wind speed at 2 m\n    WS_10m = Windspeed_10m    # Wind speed at 10 m\n  ) %&gt;%\n  mutate(\n    delta_T = Ta_10m - Ta_2m,                          # Vertical temperature gradient\n    WS_mean = (WS_2m + WS_10m) / 2,                    # Mean wind speed\n    month_num = month(datetime),                      # Numeric month for logic\n    month_label = case_when(                          # Label month manually for plot filtering\n      month_num == 6 ~ \"June\",\n      month_num == 11 ~ \"November\",\n      TRUE ~ as.character(month(datetime, label = TRUE))\n    )\n  )\n\n## ----------------------------------------------------------------------\n# Define physical constants for sensible heat flux calculation\n\nrho_air &lt;- set_units(1.225, \"kg/m^3\")   # Air density\ncp_air &lt;- set_units(1005, \"J/kg/K\")     # Specific heat capacity of air\nz1 &lt;- 2                                 # Lower measurement height (2 m)\nz2 &lt;- 10                                # Upper measurement height (10 m)\nk &lt;- 0.41                               # von Kármán constant\n\n# Calculate aerodynamic resistance and sensible heat flux (H)\nenergy &lt;- energy %&gt;%\n  mutate(\n    ra = log(z2 / z1) / (k * WS_mean),                     # Aerodynamic resistance [s/m]\n    H = drop_units(rho_air * cp_air * delta_T / ra)       # Sensible heat flux [W/m²]\n  )\n\n## ----------------------------------------------------------------------\n# Estimate latent heat flux (LE) using residual method: LE = Rn - G - H\n\nenergy &lt;- energy %&gt;%\n  mutate(LE = Rn - G - H)\n\n## ----------------------------------------------------------------------\n# Reshape data for plotting: long format for energy balance components\n\nlibrary(ggplot2)\n\nenergy_long &lt;- energy %&gt;%\n  select(datetime, month_label, Rn, G, H, LE) %&gt;%\n  pivot_longer(cols = c(Rn, G, H, LE), names_to = \"flux\", values_to = \"value\")\n\n# Define plotting function for energy fluxes\nplot_fluxes &lt;- function(df, title) {\n  ggplot(df, aes(x = datetime, y = value, color = flux)) +\n    geom_line() +\n    labs(title = title, x = \"Time\", y = \"Flux (W/m²)\") +\n    theme_minimal()\n}\n\n# Plot fluxes for June\nplot_fluxes(filter(energy_long, month_label == \"June\"), \"Energy Fluxes in June\")\n\n## ----------------------------------------------------------------------\n\n# Plot fluxes for November\nplot_fluxes(filter(energy_long, month_label == \"November\"), \"Energy Fluxes in November\")\n\n## ----------------------------------------------------------------------\n# Compute evapotranspiration (ET) from latent heat flux (LE)\n\nlambda &lt;- 2.45e6  # Latent heat of vaporization [J/kg]\nenergy &lt;- energy %&gt;%\n  mutate(\n    ET_mm_day = (LE / lambda) * 86400,                            # Convert LE to mm/day\n    month_label = month(datetime, label = TRUE, abbr = FALSE)     # Full month name\n  )\n\n# Monthly average ET\nmonthly_et &lt;- energy %&gt;%\n  filter(!is.na(ET_mm_day)) %&gt;%\n  group_by(month_label) %&gt;%\n  summarise(\n    mean_ET = mean(ET_mm_day, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Bar plot: mean ET by month\nggplot(monthly_et, aes(x = month_label, y = mean_ET, fill = month_label)) +\n  geom_col(show.legend = FALSE) +\n  labs(\n    title = \"Mean Daily Evapotranspiration (ET) from Residual Method\",\n    x = \"Month\",\n    y = \"Evapotranspiration (mm/day)\"\n  ) +\n  scale_fill_manual(values = c(\"June\" = \"tomato\", \"November\" = \"turquoise3\")) +\n  theme_minimal()\n\n## ----------------------------------------------------------------------\n# Save processed data to CSV\nwrite_csv(energy, \"../data/processed_energy_fluxes.csv\")",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/fluxes_corrected.html#references",
    "href": "doc/fluxes_corrected.html#references",
    "title": "Basic Energy Flux Analysis from Energy Balance Station",
    "section": "References",
    "text": "References\n\nFoken, T. (2008). Micrometeorology. Springer.\n\nMonteith, J. L., & Unsworth, M. H. (2013). Principles of Environmental Physics. Academic Press.\n\nAllen, R. G., Pereira, L. S., Raes, D., & Smith, M. (1998). Crop evapotranspiration – FAO Irrigation and Drainage Paper 56.\n\nArya, S. P. (2001). Introduction to Micrometeorology. Academic Press.\n\nOke, T. R. (2002). Boundary Layer Climates. Routledge.",
    "crumbs": [
      "Basic Energy Flux Analysis from Energy Balance Station"
    ]
  },
  {
    "objectID": "doc/evaluation.html",
    "href": "doc/evaluation.html",
    "title": "Evaluation of Atmosphere–Vegetation Interaction Models",
    "section": "",
    "text": "Understanding microclimatic and ecological processes at high spatial resolution requires integrated modeling approaches that couple atmospheric dynamics with plant and vegetation processes. The models compared here span a wide range of capabilities, from fluid dynamics solvers to ecophysiological simulators. This document introduces the evaluation criteria, explains the scoring approach, and provides literature references for further exploration.\n\n\nThis model comparison aims to evaluate and categorize existing modeling platforms that simulate atmosphere-vegetation interactions, emphasizing realistic deployment, dimensional and structural detail, and biophysical relevance. While many models offer advanced features in isolation, such as turbulence modeling, vegetation physiology, or 3D structural input, only a few integrate these capabilities in a usable and accessible way. This evaluation considers not only modeling power but also technical complexity, scientific maturity, and practical deployability.\n\nFull 3D support with high spatial resolution\nIntegration of real-world vegetation structure from TLS, QSM, or ALS\nExplicit representation of plant–atmosphere feedback (e.g., transpiration effects on local climate)\nAvailability of user interfaces, documentation, licensing, and feasibility on common research workstations\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"theme\": \"default\", \"themeVariables\": { \"fontSize\": \"9px\", \"nodePadding\": \"20\", \"width\": \"300\" }}}%%\ngraph TD\n    A[Model Evaluation]\n\n    A --&gt; C[Flag Classification]\n    C --&gt; C1[🟩 High capability + usability&lt;br&gt;Score: 7.0–10.0&lt;br&gt;GUI, docs, user base]\n    C --&gt; C2[🟧 High capability, low usability&lt;br&gt;Score: 7.0–10.0&lt;br&gt;Expert-only, low maturity]\n    C --&gt; C3[🟦 Moderate & well-integrated&lt;br&gt;Score: 5.0–6.9&lt;br&gt;Lacks coupling, usable]\n    C --&gt; C4[🟨 Specialized + usable&lt;br&gt;Score: 4.0–6.9&lt;br&gt;Limited scope, accessible]\n    C --&gt; C5[🟥 Experimental / niche&lt;br&gt;Score: 4.0–6.9&lt;br&gt;Non-generalizable use]\n    C --&gt; C6[❌ Legacy / not usable&lt;br&gt;Any score&lt;br&gt;No dev, no workflow]\n    A --&gt; D[Microscale Applicability]\n    D --&gt; D1[✅ Fully applicable&lt;br&gt;≤10 m, 3D veg–air coupling]\n    D --&gt; D2[🟨 Conditionally applicable&lt;br&gt;Partial 3D or physics]\n    D --&gt; D3[❌ Not applicable&lt;br&gt;Too\n coarse or schematic]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style C fill:#ccf\n    style D fill:#ffc\n    style C1 fill:#cfc\n    style C2 fill:#ffebcc\n    style C3 fill:#e0f0ff\n    style C4 fill:#ffffcc\n    style C5 fill:#ffe0e0\n    style C6 fill:#ddd\n    style D1 fill:#cfc\n    style D2 fill:#ffffcc\n    style D3 fill:#eee\n\n\n\n\n\n\n\n\n\n\n\n\nWhen selecting a suitable model for simulating interactions between the atmosphere and vegetation, more aspects than just scientific completeness must be taken into account in the context of operationalization. Models differ considerably in their structure, focus, technical maturity, and accessibility. What does this mean? Some models achieve excellent physical accuracy (e.g., LES-based turbulence and complete feedback between plants and the atmosphere) but require in-depth technical knowledge or high-performance computers. Other models, on the other hand, sacrifice physical completeness in favor of practicality and easy integration into planning or monitoring processes.\nOur attempt is to enable this multi-criteria assessment and make it comprehensible by means of an evaluation framework in order to arrive at a pre-selection. This is done by combining quantitative assessments with a qualitative classification system, in particular:\n\nscientific completeness based on various categories\noperational usability\n\nThe evaluation is based on clearly defined criteria such as model physics, plant physiology, plant structure, model dimensionality and scales, and user-friendliness. However, the relative weights reflect value-based assessments – what is considered more important depends on the context (urban planning vs. ecohydrology vs. forest micrometeorology). In concrete terms, this means:\n\nIn urban planning, user-friendliness and realistic 3D air flows may be paramount.\nIn plant science, biophysics and physiology may be paramount.\nIn forestry, compatibility with TLS or QSM inputs may be required.\n\nThis is not a weakness, but a strength, as it allows adaptation to the user’s goals – as long as the weighting and criteria are transparent.\n\n\n\n\n\n\n\n\n\n\n\n\nCriterion\nWeight\nSub-Capabilities / Description\nScoring Guidelines\n\n\n\n\nAtmosphere\n3.0\nLES/RANS, radiative transfer, soil–vegetation coupling\n1.5–3.0: Full LES or RANS / radiation / soil 0.6–1.4: Partial (e.g., radiation only) &lt; 0.6: Basic or missing physics\n\n\nStructure\n1.0\nRealistic vegetation structure (e.g., QSM/LAD, voxel, TLS-derived)\n0.8–1.0: Full 3D voxel/QSM/tree geometry 0.4–0.7: Schematic trees &lt; 0.4: No or empirical structure\n\n\nFeedback\n1.0\nBiophysical feedback transpiration ↔︎ air\n0.8–1.0: Full coupling 0.4–0.7: Drag or partial interaction &lt; 0.4: One-way/static\n\n\nPhysiology\n1.0\nTranspiration, photosynthesis, stomata, water flow\n0.8–1.0: Full physiology 0.4–0.7: Simplified &lt; 0.4: None\n\n\nUsability\n2.0\nGUI/CLI, documentation, install, license, hardware\n1.5–2.0: Documented, user-friendly 0.6–1.4: CLI/complex &lt; 0.6: Legacy/unusable\n\n\n3D\n2.0\nFull 3D resolution and within-canopy gradients\n1.0–1.9: Full 3D 0.6–0.9: Pseudo-3D 0.3–0.5: Layered &lt; 0.3: None\n\n\n\n\n\n\n\nMicroscale applicable models can resolve processes on spatial scales of ≤ 10 m. At this scale, air flows, radiation, and microclimate dynamics become relevant at the tree level. These models are typically characterized by the following features:\n\nThey work with high-resolution 3D grids.\nVegetation is explicitly represented (e.g., voxel- or TLS-based).\nLocalized simulations of plots, tree groups, or urban areas are possible.\n\nMicroscale capability is essential for LiDAR-based modeling, urban forestry, and the investigation of microclimates in tree canopies.\n\n\n\n\n\n\n\n\nSymbol\nMicroscale Capability Description\n\n\n\n\n✅\nFully applicable: Designed for a resolution of ≤ 10 m with 3D vegetation–atmosphere coupling.\n\n\n🟨\nConditionally applicable: Partial support for high resolutions, but limited physics or geometry.\n\n\n❌\nNot applicable: Coarse resolution or missing spatial details.\n\n\n\n\nThe following characteristics are flagged with an ❌ for experimental or obsolete models:\n\nno longer maintained or widely used.\nthey were developed for niche applications or obsolete use cases.\nthere is a complete lack of user-friendly workflows or adequate documentation.\n\nThis leads to the following classification scheme:\n\n\n\n\n\n\n\n\n\n\nFlag\nLabel\nImplied Score\nExplanation of the Classification\n\n\n\n\n🟩\nHigh capability, high usability\n7.0–10.0\nFully featured and deployable with reasonable effort (GUI, docs, user base)\n\n\n🟧\nHigh capability, low usability\n7.0–10.0\nPowerful but difficult to use; expert-only setup, low maturity\n\n\n🟦\nModerate capability, well-integrated\n5.0–6.9\nSolid for many tasks; lacks advanced coupling but usable and balanced\n\n\n🟨\nSpecialized model, high usability\n4.0–6.9\nLimited scope (e.g. radiation only), but very accessible and documented\n\n\n🟥\nExperimental or niche\n4.0–6.9\nLimited audience or non-generalizable application\n\n\n❌\nLegacy/unmaintained/ not usable\nany\nNo active development or practical use case today\n\n\n\n\nNote: This classification does not always correspond to the ranking by score, which is intentional. For example, a model with a high score may still be marked with 🟧 or ❌ if it is technically difficult to implement, is not documented or maintained, or is simply no longer available. This helps to put the pure scoring performance into perspective, which would otherwise lead to the selection of models that prove to be unusable in practice.\n\n\n\n\nFifteen models were systematically evaluated based on the assessment framework presented above. The models were selected on an exploratory basis using Google searches, specialist literature (e.g., GMD Geoscientific Model Development, ScienceDirect), well-known model comparisons, and open-source repositories. The selection is therefore well-founded but not entirely systematic. The following tables shows the results of this evaluation. It not only shows the weighted overall score, but also differentiates between the underlying individual criteria. In addition, the applicability in the microscale range is indicated and each model is classified using a color-coded classification system. This makes the performance of a model in terms of the atmosphere-vegetation coupling transparent and shows the extent to which a model can be realistically integrated into scientific or operational processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nScore\nAtmosphere Physics\nStructure\nFeedback\nPhysiology\nUsability\n3D\nMicroscale Capabilities\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0Full LES and radiative transfer; no soil–water coupling\n0.8Static 3D vegetation model\n0.7Air–vegetation drag interaction\n0.3No explicit physiology\n0.4Complex install, Linux only; well documented\n1.0Fully resolved CFD\nLES solver at meter-scale; used in urban microclimate studies &lt;10 m; limited physiology, strong flow–structure resolution\n🟧\n🟩\n\n\n2\nMuSICA\n7.4\n0.8Soil–plant-atmosphere exchange; no LES or radiative transfer\n0.6Layered cohort model, not voxel-based\n1.0Detailed biophysical feedback\n1.0Includes transpiration, photosynthesis, stomata, water dynamics\n0.3Legacy Fortran, hard to install\n1.01D canopy model\netailed canopy and physiology; vertical 1D, not voxel; grid spacing cohort-based\n🟥 ❌\n🟨\n\n\n3\nOpenFOAM\n7.3\n2.5LES/RANS CFD; partial radiation support\n1.0Porosity/drag approach for tree structure\n0.5Customizable feedback via coding\n0.0No vegetation physiology\n0.2Expert use only, CLI\n1.9Full 3D CFD\nCFD model with &lt;1 m resolution; porosity drag; physiology via coding\n🟧\n🟩\n\n\n4\nENVI-met\n6.9\n0.8RANS turbulence and radiation; no soil coupling\n0.6Blocky trees, parametric structure\n0.4Basic one-way coupling\n0.3Simplified energy–water exchange\n0.6GUI, documented, PC-compatible\n1.0Pseudo-3D (layered)\nGrid 0.5–2 m; urban canopy focus; simplified structure\n🟩\n🟩\n\n\n5\nWRF-Urban\n6.5\n0.9Urban-scale RANS + radiation; coarse resolution\n0.7Urban and vegetation layering\n0.6Bulk vegetation–atmosphere interactions\n0.2No individual physiology model\n0.3HPC-heavy, complex setup\n1.0Grid-based, some canopy effects\nUrban RANS, VEGE3D coupling; no true &lt;10 m flow+veg\n🟧\n🟨\n\n\n6\nForestED\n6.1\n0.9Radiation balance only\n0.8TLS-derived trees, but limited structural detail\n0.5Weak air interaction\n0.3No detailed physiology\n0.4Prototype, no GUI\n1.0Real 3D from TLS\nFull 3D via TLS; radiation only, no flow coupling\n🟥 ❌\n🟩\n\n\n7\nDART\n5.7\n0.6Radiative transfer simulation, no air dynamics\n1.0Voxel-based structural import\n0.0No air–plant feedback\n0.2No physiology\n0.3Complex setup, technical barrier\n1.0Radiative 3D\nRadiative voxel model &lt;1 m; no airflow or feedback\n🟥 ❌\n🟩\n\n\n8\nED2\n5.6\n0.7Surface energy and hydrology; no LES\n0.5Functional cohort-based\n0.6Partial feedback, not dynamic\n1.0Rich physiology, plant hydraulics\n0.4Command-line only, heavy model\n0.5Vertical layers, no 3D\nCohort-based; no individual trees or microclimate\n🟦\n❌\n\n\n9\nMAESPA\n5.3\n0.4No LES or full RANS\n0.5Elliptic crown geometries\n0.5Simple coupling (transpiration ↔︎ air temp)\n1.0Includes water and stomatal response\n0.4CLI, old Fortran\n0.8Layered or semi-3D\nTree-level radiation, no fluid; stand-scale design\n🟦\n❌\n\n\n10\nPyDOM\n5.0\n0.5Solar irradiance modeling using discrete ordinates method; no fluid dynamics\n0.6Uses simplified canopy layers or volumes; structure inferred\n0.0No biophysical feedback\n0.3No physiology model\n0.5Script-based usage; moderately usable\n1.0Volumetric but low-resolution\nVoxelized solar DOM; no air coupling\n🟨 ❌\n🟨\n\n\n11\nCOMOKIT\n4.9\n0.4No atmosphere simulation; only agent-level heat/energy accounting\n0.3Simplified static vegetation\n0.5Agent-based feedback loops via scenario definition\n0.5No continuous transpiration or photosynthesis, only thermal behavior\n0.7Accessible GUI, easy scenario logic, extensive documentation\n0.5Visual pseudo-3D, no physical gradients\nAgent-based; no physical coupling; coarse graphics\n🟨\n❌\n\n\n12\nLPJ-GUESS\n4.4\n0.7Energy and gas exchange with climate integration; no internal 3D resolution or LES\n0.4Functional PFTs with vertical profiles, no explicit geometry\n0.4Climate–vegetation coupling, but coarse\n0.9Complex physiology model with stomatal control, photosynthesis\n0.3CLI-based ecosystem model, config-heavy\n0.0No 3D, grid-cell aggregated PFT composition\nDGVM, no 3D, coarse PFT representation\n🟦 ❌\n❌\n\n\n13\nMicroclimc\n4.2\n0.6Radiative energy balance and temperature with simple terrain effects; no CFD or LES\n0.3Schematic trees only, no voxel or lidar structure\n0.4One-way: vegetation affects energy balance, no feedback from air\n0.4Simple transpiration and energy fluxes only\n0.8R-based, documented, GUI-like interface\n0.5Layered canopy modules, semi-3D\n1–5 m radiation/temp; schematic trees; no LES\n🟨\n🟨\n\n\n14\niTREETools\n3.1\n0.3No atmosphere model; static inventory system\n0.2Tree inventory tables only; no geometry\n0.2None; no feedback, no fluxes\n0.0No physiology modeling\n0.9Very accessible GUI, well supported\n0.0No 3D; inventory only\nEmpirical inventory; no spatial simulation\n🟨 ❌\n❌\n\n\n15\nFluspect\n1.9\n0.1Leaf-scale radiative simulation; no atmosphere\n0.0No spatial structure\n0.0None\n1.0Detailed leaf spectral and biochemical simulation\n0.3Niche tool, standalone use; requires integration\n0.0No 3D; single-leaf model\nLeaf-level only; no domain or airflow\n🟥 ❌\n❌\n\n\n\n\nBased on the upper table, the below graph helps visualize the trade-off between model capability and usability, making the multi-dimensional classification system intuitively accessible at a glance.\n\n\n\nModel usability vs. total score across classified microclimate models. The inverse relationship reflects a common trade-off: high-performing models (right) often require expert-level setup (low usability, bottom), while user-friendly models (top) tend to be simplified. Colored points reflect model classification: 🟩 usable and capable, 🟧 powerful but complex, 🟦 balanced, 🟨 specialized, and 🟥 experimental. Models above the trend line (e.g., ENVI-met) offer better usability than expected for their score; those below (e.g., MuSICA) require disproportionately high effort.\n\n\n\n\n\nIf we narrow the selection by removing models that are either classified as legacy systems (❌ ) or that lack both microscale applicability (❌) and fully resolved 3D spatial representation (&lt;1.0), the set of viable modeling platforms is drastically reduced. This filtering excludes tools that are either outdated, lack dimensional realism, or are designed for coarse-scale applications incompatible with high-resolution vegetation–atmosphere modeling. What remains is a focused set of platforms that combine scientific robustness with operational feasibility for modeling processes at the tree or plot level. These remaining models offer realistic support for implementation in urban microclimate design, LiDAR-informed ecological studies, and vegetation-based climate adaptation strategies where 3D feedbacks and spatial structure matter.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nModel\nScore\nAtmosphere\nStructure\nFeedback\nPhysiology\nUsability\n3D\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0 – Full LES, radiation, no soil\n0.8 – Static vegetation models\n0.7 – Basic interaction\n0.3 – No physiology\n0.4 – Complex setup, Linux only, docs\n1.0 – True 3D\n🟧\n🟩\n\n\n2\nOpenFOAM\n7.3\n2.5 – Full LES/RANS, partial radiation\n1.0 – Porosity/drag approach\n0.5 – Feedback via coding\n0.0 – None\n0.2 – CLI, expert only\n1.9 – Full CFD\n🟧\n🟩\n\n\n3\nENVI-met\n6.9\n0.8 – RANS, radiation\n0.6 – Block trees only\n0.4 – Weak one-way coupling\n0.3 – Simplified transpiration\n0.6 – GUI, docs, runs on PC\n1.0 – Pseudo-3D layering\n🟩\n🟩\n\n\n4\nWRF-Urban\n6.5\n0.9 – RANS, radiation\n0.7 – Layered urban/vegetation\n0.6 – Bulk interaction\n0.2 – None\n0.3 – HPC, not easily usable\n1.0 – Grid-based\n🟧\n🟨\n\n\n5\nMicroclimc\n4.2\n0.6 – Radiation and temp model, no LES\n0.3 – Schematic trees\n0.4 – Indirect surface coupling\n0.4 – Empirical transpiration\n0.8 – GUI, documentation, R integration\n0.5 – Semi-3D canopy layer\n🟨\n🟨\n\n\n\nSorting applied:\nPrimary: Microscale applicability (✅ &gt; 🟨 &gt; ❌)\nSecondary: Total Score (descending)\n\n\n\n\n\nto be completed\nENVI-met\n\nBruse, M., & Fleer, H. (1998). Simulating surface–plant–air interactions inside urban environments with a three-dimensional numerical model. Environmental Modelling & Software, 13(3–4), 373–384.\nENVI-met Documentation: https://envi-met.info/\n\nPALM-4U\n\nMaronga, B., et al. (2020). Overview of the PALM model system 6.0. Geoscientific Model Development, 13, 1335–1372. https://doi.org/10.5194/gmd-13-1335-2020\nhttps://palm-model.org/\n\nMuSICA\n\nOgée, J., et al. (2003). MuSICA, a CO2, water and energy multilayer, multileaf model for the analysis of function of vegetation at the canopy scale. Ecological Modelling, 156(2–3), 181–204.\n\nOpenFOAM (custom vegetation)\n\nGromke, C., & Blocken, B. (2015). CFD simulation of near-field pollutant dispersion including vegetation effects. Atmospheric Environment, 100, 238–249.\nThe OpenFOAM Foundation Hom\n\nWRF-Urban\n\nChen, F., Yu, B., Wu, M., Yang, X., et al. (2021). Improved urban finescale forecasting during a heat wave by using high-resolution urban canopy parameters. Frontiers in Climate, 3, 771441. https://doi.org/10.3389/fclim.2021.771441\nMartilli, A., Nazarian, N., Krayenhoff, E. S., Lachapelle, J., Lu, J., Rivas, E., Rodriguez‑Sanchez, A., Sanchez, B., & Santiago, J. L. (2024). WRF‑Comfort: Simulating microscale variability in outdoor heat stress at the city scale with a mesoscale model. Geoscientific Model Development, 17, 5023–5039. https://doi.org/10.5194/gmd-17-5023-2024",
    "crumbs": [
      "Evaluation of Atmosphere–Vegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#objective-of-the-evaluation",
    "href": "doc/evaluation.html#objective-of-the-evaluation",
    "title": "Evaluation of Atmosphere–Vegetation Interaction Models",
    "section": "",
    "text": "This model comparison aims to evaluate and categorize existing modeling platforms that simulate atmosphere-vegetation interactions, emphasizing realistic deployment, dimensional and structural detail, and biophysical relevance. While many models offer advanced features in isolation, such as turbulence modeling, vegetation physiology, or 3D structural input, only a few integrate these capabilities in a usable and accessible way. This evaluation considers not only modeling power but also technical complexity, scientific maturity, and practical deployability.\n\nFull 3D support with high spatial resolution\nIntegration of real-world vegetation structure from TLS, QSM, or ALS\nExplicit representation of plant–atmosphere feedback (e.g., transpiration effects on local climate)\nAvailability of user interfaces, documentation, licensing, and feasibility on common research workstations",
    "crumbs": [
      "Evaluation of Atmosphere–Vegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#model-evaluation-structure",
    "href": "doc/evaluation.html#model-evaluation-structure",
    "title": "Evaluation of Atmosphere–Vegetation Interaction Models",
    "section": "",
    "text": "%%{init: {\"theme\": \"default\", \"themeVariables\": { \"fontSize\": \"9px\", \"nodePadding\": \"20\", \"width\": \"300\" }}}%%\ngraph TD\n    A[Model Evaluation]\n\n    A --&gt; C[Flag Classification]\n    C --&gt; C1[🟩 High capability + usability&lt;br&gt;Score: 7.0–10.0&lt;br&gt;GUI, docs, user base]\n    C --&gt; C2[🟧 High capability, low usability&lt;br&gt;Score: 7.0–10.0&lt;br&gt;Expert-only, low maturity]\n    C --&gt; C3[🟦 Moderate & well-integrated&lt;br&gt;Score: 5.0–6.9&lt;br&gt;Lacks coupling, usable]\n    C --&gt; C4[🟨 Specialized + usable&lt;br&gt;Score: 4.0–6.9&lt;br&gt;Limited scope, accessible]\n    C --&gt; C5[🟥 Experimental / niche&lt;br&gt;Score: 4.0–6.9&lt;br&gt;Non-generalizable use]\n    C --&gt; C6[❌ Legacy / not usable&lt;br&gt;Any score&lt;br&gt;No dev, no workflow]\n    A --&gt; D[Microscale Applicability]\n    D --&gt; D1[✅ Fully applicable&lt;br&gt;≤10 m, 3D veg–air coupling]\n    D --&gt; D2[🟨 Conditionally applicable&lt;br&gt;Partial 3D or physics]\n    D --&gt; D3[❌ Not applicable&lt;br&gt;Too\n coarse or schematic]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style C fill:#ccf\n    style D fill:#ffc\n    style C1 fill:#cfc\n    style C2 fill:#ffebcc\n    style C3 fill:#e0f0ff\n    style C4 fill:#ffffcc\n    style C5 fill:#ffe0e0\n    style C6 fill:#ddd\n    style D1 fill:#cfc\n    style D2 fill:#ffffcc\n    style D3 fill:#eee",
    "crumbs": [
      "Evaluation of Atmosphere–Vegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#the-evaluation-framework",
    "href": "doc/evaluation.html#the-evaluation-framework",
    "title": "Evaluation of Atmosphere–Vegetation Interaction Models",
    "section": "",
    "text": "When selecting a suitable model for simulating interactions between the atmosphere and vegetation, more aspects than just scientific completeness must be taken into account in the context of operationalization. Models differ considerably in their structure, focus, technical maturity, and accessibility. What does this mean? Some models achieve excellent physical accuracy (e.g., LES-based turbulence and complete feedback between plants and the atmosphere) but require in-depth technical knowledge or high-performance computers. Other models, on the other hand, sacrifice physical completeness in favor of practicality and easy integration into planning or monitoring processes.\nOur attempt is to enable this multi-criteria assessment and make it comprehensible by means of an evaluation framework in order to arrive at a pre-selection. This is done by combining quantitative assessments with a qualitative classification system, in particular:\n\nscientific completeness based on various categories\noperational usability\n\nThe evaluation is based on clearly defined criteria such as model physics, plant physiology, plant structure, model dimensionality and scales, and user-friendliness. However, the relative weights reflect value-based assessments – what is considered more important depends on the context (urban planning vs. ecohydrology vs. forest micrometeorology). In concrete terms, this means:\n\nIn urban planning, user-friendliness and realistic 3D air flows may be paramount.\nIn plant science, biophysics and physiology may be paramount.\nIn forestry, compatibility with TLS or QSM inputs may be required.\n\nThis is not a weakness, but a strength, as it allows adaptation to the user’s goals – as long as the weighting and criteria are transparent.\n\n\n\n\n\n\n\n\n\n\n\n\nCriterion\nWeight\nSub-Capabilities / Description\nScoring Guidelines\n\n\n\n\nAtmosphere\n3.0\nLES/RANS, radiative transfer, soil–vegetation coupling\n1.5–3.0: Full LES or RANS / radiation / soil 0.6–1.4: Partial (e.g., radiation only) &lt; 0.6: Basic or missing physics\n\n\nStructure\n1.0\nRealistic vegetation structure (e.g., QSM/LAD, voxel, TLS-derived)\n0.8–1.0: Full 3D voxel/QSM/tree geometry 0.4–0.7: Schematic trees &lt; 0.4: No or empirical structure\n\n\nFeedback\n1.0\nBiophysical feedback transpiration ↔︎ air\n0.8–1.0: Full coupling 0.4–0.7: Drag or partial interaction &lt; 0.4: One-way/static\n\n\nPhysiology\n1.0\nTranspiration, photosynthesis, stomata, water flow\n0.8–1.0: Full physiology 0.4–0.7: Simplified &lt; 0.4: None\n\n\nUsability\n2.0\nGUI/CLI, documentation, install, license, hardware\n1.5–2.0: Documented, user-friendly 0.6–1.4: CLI/complex &lt; 0.6: Legacy/unusable\n\n\n3D\n2.0\nFull 3D resolution and within-canopy gradients\n1.0–1.9: Full 3D 0.6–0.9: Pseudo-3D 0.3–0.5: Layered &lt; 0.3: None\n\n\n\n\n\n\n\nMicroscale applicable models can resolve processes on spatial scales of ≤ 10 m. At this scale, air flows, radiation, and microclimate dynamics become relevant at the tree level. These models are typically characterized by the following features:\n\nThey work with high-resolution 3D grids.\nVegetation is explicitly represented (e.g., voxel- or TLS-based).\nLocalized simulations of plots, tree groups, or urban areas are possible.\n\nMicroscale capability is essential for LiDAR-based modeling, urban forestry, and the investigation of microclimates in tree canopies.\n\n\n\n\n\n\n\n\nSymbol\nMicroscale Capability Description\n\n\n\n\n✅\nFully applicable: Designed for a resolution of ≤ 10 m with 3D vegetation–atmosphere coupling.\n\n\n🟨\nConditionally applicable: Partial support for high resolutions, but limited physics or geometry.\n\n\n❌\nNot applicable: Coarse resolution or missing spatial details.\n\n\n\n\nThe following characteristics are flagged with an ❌ for experimental or obsolete models:\n\nno longer maintained or widely used.\nthey were developed for niche applications or obsolete use cases.\nthere is a complete lack of user-friendly workflows or adequate documentation.\n\nThis leads to the following classification scheme:\n\n\n\n\n\n\n\n\n\n\nFlag\nLabel\nImplied Score\nExplanation of the Classification\n\n\n\n\n🟩\nHigh capability, high usability\n7.0–10.0\nFully featured and deployable with reasonable effort (GUI, docs, user base)\n\n\n🟧\nHigh capability, low usability\n7.0–10.0\nPowerful but difficult to use; expert-only setup, low maturity\n\n\n🟦\nModerate capability, well-integrated\n5.0–6.9\nSolid for many tasks; lacks advanced coupling but usable and balanced\n\n\n🟨\nSpecialized model, high usability\n4.0–6.9\nLimited scope (e.g. radiation only), but very accessible and documented\n\n\n🟥\nExperimental or niche\n4.0–6.9\nLimited audience or non-generalizable application\n\n\n❌\nLegacy/unmaintained/ not usable\nany\nNo active development or practical use case today\n\n\n\n\nNote: This classification does not always correspond to the ranking by score, which is intentional. For example, a model with a high score may still be marked with 🟧 or ❌ if it is technically difficult to implement, is not documented or maintained, or is simply no longer available. This helps to put the pure scoring performance into perspective, which would otherwise lead to the selection of models that prove to be unusable in practice.",
    "crumbs": [
      "Evaluation of Atmosphere–Vegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#atmospherevegetation-model-comparison-of-models",
    "href": "doc/evaluation.html#atmospherevegetation-model-comparison-of-models",
    "title": "Evaluation of Atmosphere–Vegetation Interaction Models",
    "section": "",
    "text": "Fifteen models were systematically evaluated based on the assessment framework presented above. The models were selected on an exploratory basis using Google searches, specialist literature (e.g., GMD Geoscientific Model Development, ScienceDirect), well-known model comparisons, and open-source repositories. The selection is therefore well-founded but not entirely systematic. The following tables shows the results of this evaluation. It not only shows the weighted overall score, but also differentiates between the underlying individual criteria. In addition, the applicability in the microscale range is indicated and each model is classified using a color-coded classification system. This makes the performance of a model in terms of the atmosphere-vegetation coupling transparent and shows the extent to which a model can be realistically integrated into scientific or operational processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nScore\nAtmosphere Physics\nStructure\nFeedback\nPhysiology\nUsability\n3D\nMicroscale Capabilities\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0Full LES and radiative transfer; no soil–water coupling\n0.8Static 3D vegetation model\n0.7Air–vegetation drag interaction\n0.3No explicit physiology\n0.4Complex install, Linux only; well documented\n1.0Fully resolved CFD\nLES solver at meter-scale; used in urban microclimate studies &lt;10 m; limited physiology, strong flow–structure resolution\n🟧\n🟩\n\n\n2\nMuSICA\n7.4\n0.8Soil–plant-atmosphere exchange; no LES or radiative transfer\n0.6Layered cohort model, not voxel-based\n1.0Detailed biophysical feedback\n1.0Includes transpiration, photosynthesis, stomata, water dynamics\n0.3Legacy Fortran, hard to install\n1.01D canopy model\netailed canopy and physiology; vertical 1D, not voxel; grid spacing cohort-based\n🟥 ❌\n🟨\n\n\n3\nOpenFOAM\n7.3\n2.5LES/RANS CFD; partial radiation support\n1.0Porosity/drag approach for tree structure\n0.5Customizable feedback via coding\n0.0No vegetation physiology\n0.2Expert use only, CLI\n1.9Full 3D CFD\nCFD model with &lt;1 m resolution; porosity drag; physiology via coding\n🟧\n🟩\n\n\n4\nENVI-met\n6.9\n0.8RANS turbulence and radiation; no soil coupling\n0.6Blocky trees, parametric structure\n0.4Basic one-way coupling\n0.3Simplified energy–water exchange\n0.6GUI, documented, PC-compatible\n1.0Pseudo-3D (layered)\nGrid 0.5–2 m; urban canopy focus; simplified structure\n🟩\n🟩\n\n\n5\nWRF-Urban\n6.5\n0.9Urban-scale RANS + radiation; coarse resolution\n0.7Urban and vegetation layering\n0.6Bulk vegetation–atmosphere interactions\n0.2No individual physiology model\n0.3HPC-heavy, complex setup\n1.0Grid-based, some canopy effects\nUrban RANS, VEGE3D coupling; no true &lt;10 m flow+veg\n🟧\n🟨\n\n\n6\nForestED\n6.1\n0.9Radiation balance only\n0.8TLS-derived trees, but limited structural detail\n0.5Weak air interaction\n0.3No detailed physiology\n0.4Prototype, no GUI\n1.0Real 3D from TLS\nFull 3D via TLS; radiation only, no flow coupling\n🟥 ❌\n🟩\n\n\n7\nDART\n5.7\n0.6Radiative transfer simulation, no air dynamics\n1.0Voxel-based structural import\n0.0No air–plant feedback\n0.2No physiology\n0.3Complex setup, technical barrier\n1.0Radiative 3D\nRadiative voxel model &lt;1 m; no airflow or feedback\n🟥 ❌\n🟩\n\n\n8\nED2\n5.6\n0.7Surface energy and hydrology; no LES\n0.5Functional cohort-based\n0.6Partial feedback, not dynamic\n1.0Rich physiology, plant hydraulics\n0.4Command-line only, heavy model\n0.5Vertical layers, no 3D\nCohort-based; no individual trees or microclimate\n🟦\n❌\n\n\n9\nMAESPA\n5.3\n0.4No LES or full RANS\n0.5Elliptic crown geometries\n0.5Simple coupling (transpiration ↔︎ air temp)\n1.0Includes water and stomatal response\n0.4CLI, old Fortran\n0.8Layered or semi-3D\nTree-level radiation, no fluid; stand-scale design\n🟦\n❌\n\n\n10\nPyDOM\n5.0\n0.5Solar irradiance modeling using discrete ordinates method; no fluid dynamics\n0.6Uses simplified canopy layers or volumes; structure inferred\n0.0No biophysical feedback\n0.3No physiology model\n0.5Script-based usage; moderately usable\n1.0Volumetric but low-resolution\nVoxelized solar DOM; no air coupling\n🟨 ❌\n🟨\n\n\n11\nCOMOKIT\n4.9\n0.4No atmosphere simulation; only agent-level heat/energy accounting\n0.3Simplified static vegetation\n0.5Agent-based feedback loops via scenario definition\n0.5No continuous transpiration or photosynthesis, only thermal behavior\n0.7Accessible GUI, easy scenario logic, extensive documentation\n0.5Visual pseudo-3D, no physical gradients\nAgent-based; no physical coupling; coarse graphics\n🟨\n❌\n\n\n12\nLPJ-GUESS\n4.4\n0.7Energy and gas exchange with climate integration; no internal 3D resolution or LES\n0.4Functional PFTs with vertical profiles, no explicit geometry\n0.4Climate–vegetation coupling, but coarse\n0.9Complex physiology model with stomatal control, photosynthesis\n0.3CLI-based ecosystem model, config-heavy\n0.0No 3D, grid-cell aggregated PFT composition\nDGVM, no 3D, coarse PFT representation\n🟦 ❌\n❌\n\n\n13\nMicroclimc\n4.2\n0.6Radiative energy balance and temperature with simple terrain effects; no CFD or LES\n0.3Schematic trees only, no voxel or lidar structure\n0.4One-way: vegetation affects energy balance, no feedback from air\n0.4Simple transpiration and energy fluxes only\n0.8R-based, documented, GUI-like interface\n0.5Layered canopy modules, semi-3D\n1–5 m radiation/temp; schematic trees; no LES\n🟨\n🟨\n\n\n14\niTREETools\n3.1\n0.3No atmosphere model; static inventory system\n0.2Tree inventory tables only; no geometry\n0.2None; no feedback, no fluxes\n0.0No physiology modeling\n0.9Very accessible GUI, well supported\n0.0No 3D; inventory only\nEmpirical inventory; no spatial simulation\n🟨 ❌\n❌\n\n\n15\nFluspect\n1.9\n0.1Leaf-scale radiative simulation; no atmosphere\n0.0No spatial structure\n0.0None\n1.0Detailed leaf spectral and biochemical simulation\n0.3Niche tool, standalone use; requires integration\n0.0No 3D; single-leaf model\nLeaf-level only; no domain or airflow\n🟥 ❌\n❌\n\n\n\n\nBased on the upper table, the below graph helps visualize the trade-off between model capability and usability, making the multi-dimensional classification system intuitively accessible at a glance.\n\n\n\nModel usability vs. total score across classified microclimate models. The inverse relationship reflects a common trade-off: high-performing models (right) often require expert-level setup (low usability, bottom), while user-friendly models (top) tend to be simplified. Colored points reflect model classification: 🟩 usable and capable, 🟧 powerful but complex, 🟦 balanced, 🟨 specialized, and 🟥 experimental. Models above the trend line (e.g., ENVI-met) offer better usability than expected for their score; those below (e.g., MuSICA) require disproportionately high effort.\n\n\n\n\n\nIf we narrow the selection by removing models that are either classified as legacy systems (❌ ) or that lack both microscale applicability (❌) and fully resolved 3D spatial representation (&lt;1.0), the set of viable modeling platforms is drastically reduced. This filtering excludes tools that are either outdated, lack dimensional realism, or are designed for coarse-scale applications incompatible with high-resolution vegetation–atmosphere modeling. What remains is a focused set of platforms that combine scientific robustness with operational feasibility for modeling processes at the tree or plot level. These remaining models offer realistic support for implementation in urban microclimate design, LiDAR-informed ecological studies, and vegetation-based climate adaptation strategies where 3D feedbacks and spatial structure matter.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nModel\nScore\nAtmosphere\nStructure\nFeedback\nPhysiology\nUsability\n3D\nAll\nMicroScale\n\n\n\n\n1\nPALM-4U\n7.6\n1.0 – Full LES, radiation, no soil\n0.8 – Static vegetation models\n0.7 – Basic interaction\n0.3 – No physiology\n0.4 – Complex setup, Linux only, docs\n1.0 – True 3D\n🟧\n🟩\n\n\n2\nOpenFOAM\n7.3\n2.5 – Full LES/RANS, partial radiation\n1.0 – Porosity/drag approach\n0.5 – Feedback via coding\n0.0 – None\n0.2 – CLI, expert only\n1.9 – Full CFD\n🟧\n🟩\n\n\n3\nENVI-met\n6.9\n0.8 – RANS, radiation\n0.6 – Block trees only\n0.4 – Weak one-way coupling\n0.3 – Simplified transpiration\n0.6 – GUI, docs, runs on PC\n1.0 – Pseudo-3D layering\n🟩\n🟩\n\n\n4\nWRF-Urban\n6.5\n0.9 – RANS, radiation\n0.7 – Layered urban/vegetation\n0.6 – Bulk interaction\n0.2 – None\n0.3 – HPC, not easily usable\n1.0 – Grid-based\n🟧\n🟨\n\n\n5\nMicroclimc\n4.2\n0.6 – Radiation and temp model, no LES\n0.3 – Schematic trees\n0.4 – Indirect surface coupling\n0.4 – Empirical transpiration\n0.8 – GUI, documentation, R integration\n0.5 – Semi-3D canopy layer\n🟨\n🟨\n\n\n\nSorting applied:\nPrimary: Microscale applicability (✅ &gt; 🟨 &gt; ❌)\nSecondary: Total Score (descending)",
    "crumbs": [
      "Evaluation of Atmosphere–Vegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/evaluation.html#literature-and-sources-by-model",
    "href": "doc/evaluation.html#literature-and-sources-by-model",
    "title": "Evaluation of Atmosphere–Vegetation Interaction Models",
    "section": "",
    "text": "to be completed\nENVI-met\n\nBruse, M., & Fleer, H. (1998). Simulating surface–plant–air interactions inside urban environments with a three-dimensional numerical model. Environmental Modelling & Software, 13(3–4), 373–384.\nENVI-met Documentation: https://envi-met.info/\n\nPALM-4U\n\nMaronga, B., et al. (2020). Overview of the PALM model system 6.0. Geoscientific Model Development, 13, 1335–1372. https://doi.org/10.5194/gmd-13-1335-2020\nhttps://palm-model.org/\n\nMuSICA\n\nOgée, J., et al. (2003). MuSICA, a CO2, water and energy multilayer, multileaf model for the analysis of function of vegetation at the canopy scale. Ecological Modelling, 156(2–3), 181–204.\n\nOpenFOAM (custom vegetation)\n\nGromke, C., & Blocken, B. (2015). CFD simulation of near-field pollutant dispersion including vegetation effects. Atmospheric Environment, 100, 238–249.\nThe OpenFOAM Foundation Hom\n\nWRF-Urban\n\nChen, F., Yu, B., Wu, M., Yang, X., et al. (2021). Improved urban finescale forecasting during a heat wave by using high-resolution urban canopy parameters. Frontiers in Climate, 3, 771441. https://doi.org/10.3389/fclim.2021.771441\nMartilli, A., Nazarian, N., Krayenhoff, E. S., Lachapelle, J., Lu, J., Rivas, E., Rodriguez‑Sanchez, A., Sanchez, B., & Santiago, J. L. (2024). WRF‑Comfort: Simulating microscale variability in outdoor heat stress at the city scale with a mesoscale model. Geoscientific Model Development, 17, 5023–5039. https://doi.org/10.5194/gmd-17-5023-2024",
    "crumbs": [
      "Evaluation of Atmosphere–Vegetation Interaction Models"
    ]
  },
  {
    "objectID": "doc/treespecies.html",
    "href": "doc/treespecies.html",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "",
    "text": "Purpose of Tree Data for ENVI-met Modeling This workflow prepares classified tree species data as a basis for generating individual tree objects for use in ENVI-met’s 3DPLANT module. Each tree location is linked to a simplified vertical LAD profile and assigned to a species class (e.g. Fagus sylvatica, Quercus robur, Pseudotsuga menziesii), which defines its interaction with ENVI-met’s radiation and vegetation modules.\nThe underlying classification raster originates from official, state-level aerial RGB orthophotos with a spatial resolution of 0.3 m. These orthophotos provide sufficient detail to allow object-based species classification at the level of individual tree crowns.\nSpecies prediction was performed using a leave-location-out forward feature selection approach implemented via the CAST package in R. This ensures that classification results generalize across spatially distinct regions by avoiding overfitting to local spectral conditions.\nBefore assigning vegetation objects to the ENVI-met model domain, species maps are despeckled, aggregated, and contextually corrected to remove isolated or misclassified tree crowns (e.g. Douglas-fir pixels in beech-dominated stands). This ensures that each synthetic ENVI-met tree is placed in a semantically and structurally consistent vegetation context.",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#setup-and-environment",
    "href": "doc/treespecies.html#setup-and-environment",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "1. Setup and Environment",
    "text": "1. Setup and Environment\nManual Setup of OTB Environment for use with link2GI\nThe R package link2GI provides wrapper functions to connect R with external geospatial software like Orfeo Toolbox (OTB), GRASS GIS, and QGIS. The function linkOTB() is used to locate OTB binaries and configure the R session to allow calling OTB applications via command-line interface (CLI) from R.\nHowever, in many modern setups—especially on Linux or in manually installed environments (e.g., extracted zip files)—the required environment variables are not set globally, and linkOTB() alone is not sufficient. This typically leads to errors like:\n\n“Application not found”\n“No XML application descriptors”\n“Could not find CLI tools”\n\nTo fix this, two critical environment variables need to be explicitly set after calling linkOTB():\n\nOTB_APPLICATION_PATH: This must point to the directory lib/otb/applications, where all XML definitions of the OTB applications are stored. These XML files describe how to call each OTB tool from the command line.\nPATH: This must include the directory where OTB binaries like otbcli_BandMath are stored (typically bin/). Without this, system calls from R to OTB will fail.\n\nExample for Linux:\notb &lt;- link2GI::linkOTB(searchLocation = \"~/apps/OTB-9.1.0-Linux/\")\nSys.setenv(OTB_APPLICATION_PATH = file.path(dirname(as.character(otb$pathOTB)), \"lib/otb/applications\"))\nSys.setenv(PATH = paste(otb$pathOTB, Sys.getenv(\"PATH\"), sep = \":\"))\nExample for Windows:\notb &lt;- link2GI::linkOTB(searchLocation = \"C:/OTB-9.1.0-Win64/\")\nSys.setenv(OTB_APPLICATION_PATH = \"C:/OTB-9.1.0-Win64/lib/otb/applications\")\nSys.setenv(PATH = paste(\"C:/OTB-9.1.0-Win64/bin\", Sys.getenv(\"PATH\"), sep = \";\"))\nNote:\n\nOn Windows, use forward slashes / in the path.\nThe PATH separator is ; on Windows and : on Unix-based systems.\n\nThis workaround is often necessary in portable, containerized, or research setups where full system integration (e.g., PATH exports, registry entries) is not available or not desired. It ensures that link2GI can still function as intended by emulating the expected environment internally within R.\n\n# Load libraries\nlibrary(terra)\nlibrary(RColorBrewer)\nlibrary(link2GI)\nlibrary(envimaR)\nlibrary(tools)\nlibrary(mapview)\nlibrary(dplyr)\n\n# Project root and OTB environment\nroot_folder &lt;- rprojroot::find_rstudio_root_file()\notb &lt;- link2GI::linkOTB(searchLocation = \"~/apps/OTB-9.1.0-Linux/\")\nSys.setenv(OTB_APPLICATION_PATH = file.path(dirname(as.character(otb$pathOTB)), \"lib/otb/applications\"))\nSys.setenv(PATH = paste(otb$pathOTB, Sys.getenv(\"PATH\"), sep = \":\"))",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#parameters-and-class-legend",
    "href": "doc/treespecies.html#parameters-and-class-legend",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "2. Parameters and Class Legend",
    "text": "2. Parameters and Class Legend\n\ntarget_res &lt;- 1\nfn &lt;- \"5-25_MOF_rgb\"\nepsg &lt;- 25832\nsapflow_ext &lt;- raster::extent(477500, 478218, 5631730, 5632500)\n\nts &lt;- data.frame(\n  ID = 1:12,\n  value = c(\"agriculture\", \"alder\", \"ash\", \"beech\", \"douglas_fir\", \"larch\",\n            \"oak\", \"pastures\", \"roads\", \"settlements\", \"spruce\", \"water\")\n)",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#rationale-why-despeckle-first",
    "href": "doc/treespecies.html#rationale-why-despeckle-first",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "3. Rationale: Why Despeckle First?",
    "text": "3. Rationale: Why Despeckle First?\n\n🔍 Why do we despeckle at original resolution before aggregation and contextual filtering?\n\nPreserve spatial detail: High-frequency noise (e.g., misclassified single pixels) must be removed before they get averaged into larger grid cells.\nAvoid error propagation: Aggregating first would carry speckle artifacts into the coarser grid.\nEnable ecologically meaningful correction: Focal filtering (e.g., Douglas-fir to Oak) should be applied on ~1 m resolution where “dominance” of classes has meaning.\nStep order summary:\n\nClassificationMapRegularization: Clean noise at 0.2 m\naggregate(): Smooth to 1 m (e.g., crown scale)\nfocal(): Replace ecologically implausible patches",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#load-and-preprocess-species-classification",
    "href": "doc/treespecies.html#load-and-preprocess-species-classification",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "4. Load and Preprocess Species Classification",
    "text": "4. Load and Preprocess Species Classification\n\nsapflow_species &lt;- readRDS(\"data/aerial/sfprediction_ffs_5-25_MOF_rgb.rds\")\nraster::writeRaster(sapflow_species, \"data/aerial/prediction_ffs.tif\", overwrite = TRUE)\nsapflow_species &lt;- raster::crop(sapflow_species, sapflow_ext)\nraster::writeRaster(sapflow_species, \"data/aerial/prediction_ffs_cut.tif\", overwrite = TRUE)",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#majority-filtering-otb-despeckle",
    "href": "doc/treespecies.html#majority-filtering-otb-despeckle",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "5. Majority Filtering (OTB Despeckle)",
    "text": "5. Majority Filtering (OTB Despeckle)\n\ncmr &lt;- parseOTBFunction(\"ClassificationMapRegularization\", otb)\ncmr$io.in &lt;- \"data/aerial/prediction_ffs.tif\"\ncmr$io.out &lt;- \"data/aerial/majority_out.tif\"\ncmr$ip.radius &lt;- \"1\"\ncmr$progress &lt;- \"true\"\nfilter_treespecies &lt;- runOTB(cmr, gili = otb$pathOTB, quiet = FALSE, retRaster = TRUE)",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#aggregate-to-1-m-resolution",
    "href": "doc/treespecies.html#aggregate-to-1-m-resolution",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "6. Aggregate to 1 m Resolution",
    "text": "6. Aggregate to 1 m Resolution\n\nr &lt;- rast(\"data/aerial/majority_out.tif\")\ncur_res &lt;- res(r)[1]\nfact &lt;- round(target_res / cur_res)\nif (target_res &lt;= cur_res) stop(\"Target resolution is lower than input resolution.\")\nr_agg &lt;- aggregate(r, fact = fact, fun = median, na.rm = TRUE)\noutfile &lt;- sprintf(\"data/aerial/%s_%sm.tif\", tools::file_path_sans_ext(basename(\"data/aerial/aggregate.tif\")), target_res)\nwriteRaster(r_agg, outfile, overwrite = TRUE)",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#contextual-correction-douglas-beechoak",
    "href": "doc/treespecies.html#contextual-correction-douglas-beechoak",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "7. Contextual Correction (Douglas → Beech/Oak)",
    "text": "7. Contextual Correction (Douglas → Beech/Oak)\n\nreplace_douglas_in_buche_eiche &lt;- function(rast_input,\n                                           window_size = 5,\n                                           douglas_value = 5,\n                                           target_values = c(4, 7),\n                                           target_res = 1.0) {\n  if (!inherits(rast_input, \"SpatRaster\")) stop(\"Input must be SpatRaster\")\n  if (window_size %% 2 == 0) stop(\"window_size must be odd\")\n  w &lt;- matrix(1, nrow = window_size, ncol = window_size)\n  r_mode &lt;- focal(rast_input, w = w, fun = modal, na.policy = \"omit\", na.rm = TRUE, progress = \"text\")\n  is_douglas &lt;- rast_input == douglas_value\n  is_oak_beech_mode &lt;- r_mode %in% target_values\n  replace_mask &lt;- is_douglas & is_oak_beech_mode\n  r_new &lt;- rast_input\n  r_new[replace_mask] &lt;- r_mode[replace_mask]\n  writeRaster(r_new, sprintf(\"data/aerial/%s_%sm.tif\", \"agg_cleand\", target_res), overwrite = TRUE)\n  return(r_new)\n}\nspecies_cleaned &lt;- replace_douglas_in_buche_eiche(r_agg, window_size = 5)",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/treespecies.html#visualize-results",
    "href": "doc/treespecies.html#visualize-results",
    "title": "Tree Species Classification Cleaning with OTB and Terra",
    "section": "8. Visualize Results",
    "text": "8. Visualize Results\nmapviewOptions(fgb = FALSE) m1 &lt;- mapview(filter_treespecies, col.regions = brewer.pal(12, “Paired”), at = ts\\(ID)\nm2 &lt;- mapview(species_cleaned, col.regions = brewer.pal(12, \"Paired\"), at = ts\\)ID) m1 + m2",
    "crumbs": [
      "Tree Species Classification Cleaning with OTB and Terra"
    ]
  },
  {
    "objectID": "doc/microclimate_predictor_stack_commented.html",
    "href": "doc/microclimate_predictor_stack_commented.html",
    "title": "Microclimate Predictor Stack Tutorial",
    "section": "",
    "text": "1 Introduction\nThis tutorial documents the modular processing chain for deriving microclimate-relevant predictors from ALS (Airborne Laser Scanning) data.\nIt is based on the script 20_microclimate_predictor_stack.R, which builds a raster predictor stack used in microclimate or ecological modeling.\n\n\n\n2 1. Overall Workflow Diagram\n\n\n\n\n\nflowchart TD\n    LAS[\"LAS Input Data\"]\n    DEM[\"Normalize & Create DEM/DSM/CHM\"]\n    PM[\"Pixel-Level Metrics\"]\n    SEG[\"Tree Segmentation\"]\n\n    TOPO[\"Topographic Variables\"]\n    VOX[\"Voxel Metrics: VCI, LAD, Entropy\"]\n    LAD[\"LAD Profiles\"]\n    CLU[\"Tree Cluster Analysis\"]\n\n    MERGE[\"Merge: Predictor Stack\"]\n    OUT[\"Final Raster Predictor Stack\"]\n\n    LAS --&gt; DEM\n    LAS --&gt; PM\n    LAS --&gt; SEG\n\n    DEM --&gt; TOPO\n    PM --&gt; VOX\n    SEG --&gt; LAD\n    LAD --&gt; CLU\n\n    TOPO --&gt; MERGE\n    VOX --&gt; MERGE\n    CLU --&gt; MERGE\n\n    MERGE --&gt; OUT\n\n\n\n\n\n\nThis diagram shows the data flow:\n\nThe LAS file is used in 3 parallel branches.\nTopographic, voxel, and tree-based metrics are computed independently.\nFinally, all are merged into one raster predictor stack.\n\n\n\n\n3 2. Project Setup\n# Load required packages and environment\nrequire(envimaR)\nrequire(rprojroot)\n\n# Determine root directory of project (requires .Rproj or .here file)\nroot_folder &lt;- find_rstudio_root_file()\n\n# Load envrmt list with all folder paths and EPSG settings\nsource(file.path(root_folder, \"src/000-rspatial-setup.R\"), echo = TRUE)\n\nenvimaR handles dynamic folder structures.\nenvrmt contains paths like path_lidar_raster, path_topo, etc.\nepsg_number, bbox and other global spatial variables are set here.\n\n\n\n\n4 3. Normalizing the LAS Catalog\nctg &lt;- readLAScatalog(las_fileFN)\nctg_base &lt;- normalize_height(ctg, knnidw(k = 6L, p = 2))\n\nA LAS catalog is loaded and normalized.\nGround points are removed to prepare for CHM and DSM creation.\n\n\n\n\n5 4. Terrain Models\ndem &lt;- rasterize_terrain(ctg, res = 1, knnidw(k = 6L, p = 2))\ndsm &lt;- rasterize_canopy(ctg, res = 1, algorithm = pitfree())\nchm &lt;- rasterize_canopy(ctg_base, res = 1, pitfree(c(0,2,5,10,15)))\n\nDEM (Digital Elevation Model) is created from ground returns.\nDSM (Surface Model) and CHM (Canopy Height Model) from canopy points.\n\n\n\n\n6 5. Topographic Derivatives\nslope &lt;- terrain(dem, \"slope\")\naspect &lt;- terrain(dem, \"aspect\")\nTPI &lt;- terrain(dsm, \"TPI\")\n\nDerived terrain parameters used for modeling light, moisture, and temperature.\n\n\n\n\n7 6. Pixel-Level Metrics\npixel_stdmetrics &lt;- pixel_metrics(ctg_base, .stdmetrics, res = 1)\npixel_LAD &lt;- pixel_metrics(ctg_base, ~as.numeric(cv(LAD(Z, dz = 1, k = 0.87)$lad)), res = 1)\npixel_entropy &lt;- pixel_metrics(ctg_base, ~as.numeric(entropy(Z, by = 1.0)), res = 1)\npixel_VCI &lt;- pixel_metrics(ctg_base, ~as.numeric(VCI(Z, zmax = 40, by = 1.0)), res = 1)\nThese voxel-based metrics represent vertical structure:\n\nLAD = Leaf Area Density\nVCI = Vertical Complexity Index\nEntropy = point height diversity\nipground = intensity of ground points (optional)\n\n\n\n\n8 7. Tree Segmentation and Metrics\nctg_seg &lt;- segment_trees(ctg_base, li2012())\nhulls &lt;- catalog_apply(ctg_seg, tree_fn)\nlad_vox &lt;- lad.voxels(ctg_base, grain.size = 1, k = 0.87, maxP = 40)\n\nTrees are segmented using the Li et al. (2012) method.\ntree_fn generates convex hulls or crown shapes.\nLAD profiles are voxelized and linked to hulls.\n\n\n\n\n9 8. Clustering Tree Profiles\nclust_model &lt;- KMeans_arma(data_clust, clusters = 10, n_iter = 500)\ntrees_lad$cluster &lt;- predict_KMeans(data_clust, clust_model)\n\nLAD metrics are dimensionally reduced (PCA or manually).\nClustering assigns structural class per tree.\nResult is written as vector layer and rasterized.\n\n\n\n\n10 9. Predictor Stack Creation\nforest_structure_metrics &lt;- c(rast(topoFN), rast(pmetricsFN), rast(tree_clus_rasFN))\nwriteRaster(forest_structure_metrics, predstack_forest_metricsFN, overwrite = TRUE)\n\nCombines topography, pixel metrics, and clusters into one multiband raster.\n\n\n\n\n11 10. Optional: Solar Irradiance via GRASS\nlinkGRASS7(dem, gisdbase = root_folder, location = \"MOF2\")\nexecGRASS(\"r.sun.hourly\", parameters = list(...))\n\nOptionally runs r.sun.hourly from GRASS to model solar radiation.\nResulting hourly radiation maps can be included in predictor stacks.\n\n\n\n\n12 Output Summary\n\n\n\n\n\n\n\n\nLayer\nType\nDescription\n\n\n\n\ntopo.tif\nRaster\nTerrain-derived variables\n\n\nall_pixel_metrics.tif\nRaster\nStructural voxel statistics\n\n\nlad_hull_raster.tif\nRaster\nLAD metrics aggregated to tree hulls\n\n\ntree_cluster.tif\nRaster\nCluster class per tree segment\n\n\npred_forest_structure.tif\nRaster\nFull predictor stack for modeling\n\n\ntrees_lad_clean.rds\nDataFrame\nTree-level statistics for analysis\n\n\n\n\n\n\n13 Questions or Extensions\n\nAdd modeling scripts (e.g. Random Forest, GLM, XGBoost)\nVisualize clusters with tmap or leaflet\nCombine with microclimate sensors or UAV data"
  },
  {
    "objectID": "doc/tls_v1_2.html#background-and-method",
    "href": "doc/tls_v1_2.html#background-and-method",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Background and Method",
    "text": "Background and Method\nThis section explains the theoretical principles of leaf area density (LAD) and describes how it can be determined using terrestrial laser scanning (TLS). Leaf area density is an important parameter in environmental modeling, for example for radiation balance and microclimate simulations. It indicates the leaf area per volume (m²/m³) and is therefore a decisive factor for microclimate simulations, radiation models, and energy flows in vegetation stands.\n\n\n\n\n\n\n\n\nApproach Type\nName / Description\nNature\n\n\n\n\nPulse-count based\nSimple linear normalization of return counts or voxel hits\nEmpirical, direct\n\n\nLinear normalization\nStraightforward normalization of pulse counts by voxel volume or max LAD\nEmpirical, basic\n\n\nPulse-density normalization\nAdjusts for occlusion and scan geometry\nSemi-empirical\n\n\nGap fraction models\nEstimate LAD/LAI from canopy openness statistics\nSemi-empirical\n\n\nBeer–Lambert conversion conversion\nUses exponential light attenuation to infer LAD\nPhysically-based\n\n\nVoxel-based inverse modeling\nOptimizes 3D LAD to match observed light attenuation or reflectance\nPhysically-based\n\n\nAllometric / geometric reconstruction\nReconstructs crown volume and distributes LAD using QSM or shape fitting\nGeometric, structural\n\n\n\n\nLinear normalization is a practical baseline: simple, fast, and reproducible.\nBeer–Lambert conversion introduces realism via physical light attenuation.\n\nMore advanced models (e.g. voxel inverse or QSM-based) aim for higher biophysical fidelity at the cost of complexity.\nThe present analysis is based on TLS with a medium-range RIEGL scanner (e.g., VZ-400). This captures millions of 3D points of the vegetation structure with high angular resolution. The point cloud is divided into uniform voxels, from which the leaf area density is estimated in two ways.\n\nLinear normalization (straightforwad)\n\\[\n\\text{LAD}_i = \\frac{N_i}{N_{\\max}} \\cdot \\text{LAD}_{\\max}\n\\] - \\(N_i\\): Number of laser points in voxel \\(i\\)\n- \\(N_{\\max}\\): Maximum across all voxels\n- \\(\\text{LAD}_{\\max}\\): Maximum LAD value from the literature (e.g., 5 m²/m³)\n\n\n\nBeer–Lambert conversion\n\\[\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n\\]\n\n\\(k\\): Extinction coefficient (typically 0.3–0.5)\n\\(\\Delta z\\): vertical voxel height\n\n\n\nOverall Workflow\nWhat happens in the script?\n\n\n\n\n\n\n\n\nStep\nDescription\nRelevant Code\n\n\n\n\n1. Read & Filter LAS\nLoad TLS data, optionally crop and clean it\nreadLAS() and las = filter_poi(...)\n\n\n2. Voxel Grid Setup\nSet up 3D grid at defined grain.size\npassed to pixel_metrics(..., res = grain.size)\n\n\n3. Count Pulses\nCount returns in each voxel height bin\npointsByZSlice() function\n\n\n4. Normalise Pulse Counts\nDivide by global max (relative LAD)\nin convert_to_LAD(): lad = (count / max) * LADmax\n\n\n5. Export Raster\nConvert metrics to raster stack\nterra::rast() from voxel_df\n\n\n6. Visualization\nPlot LAD profiles\nsee plotting section\n\n\n7. Export to Plant3D\nExports the LAD to ENVI-met\nsee export section",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#implemetation",
    "href": "doc/tls_v1_2.html#implemetation",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Implemetation",
    "text": "Implemetation\nTo use this ENVI-met tree modeling workflow in R, follow these steps to load and initialize the project correctly:\nProject Setup: Loading the R Project and Environment Download the project from next.hessenbox https://gds.hessen.de/INTERSHOP/web/WFS/HLBG-Geodaten-Site/de_DE/-/EUR/ViewDownloadcenter-Start ##### Download and Unzip the Project Archive\n\n\nUnzip the folder to your desired location.\nThe folder should contain at least:\n\nAn *.Rproj file (e.g. envimet_tree_workflow.Rproj)\nA data/ folder with input files like tree_08.las\nOne or more R/ scripts\n\n\n\nOpen the Project in RStudio\n\nGo to File → Open Project\nSelect the *.Rproj file (e.g. microclimate_TLS.Rproj)\nThis ensures that the project directory is treated as the root for all file paths.\n\n\nThe use of the {here} package depends on having a valid RStudio project. Without this, file paths may not resolve correctly.\n\n\n\nData Input Parameters and Paths\n\n\n\n\n\n\nThe input data set tree_08.las is a cleaned terrestrial laser scan of a single, isolated tree. All surrounding vegetation and ground points have been removed, so the file contains only the tree’s structure—trunk, branches, and foliage. Stored in standard LAS format, it provides high-resolution 3D point data suitable for voxelization, LAD calculation, or input into microclimate and radiative models. This detailed structural data is essential for generating true 3D tree entities in ENVI-met; without it, only simplified vegetation (SimplePlants) can be used.\n\n\n\nSet global parameters for the workflow, such as file paths, voxel resolution, and maximum LAD value for normalization.\n\nlibrary(terra)\nlibrary(lidR)\nlibrary(sf)\nlibrary(here)\nlibrary(data.table)\n\nzmax &lt;- 40  \ngrain.size &lt;- 1  \nproject_root &lt;- here::here()  \n\n# Choose LAD method: \"linear\" or \"beer\"\n# Beer–Lambert conversion Notes:\n# - Avoids log(0) and 1 by clipping near-extreme values\n# - Use when cumulative light absorption or occlusion is relevant\n# - Suitable if extinction coefficient is known or estimated from prior studies\nlad_method &lt;- \"beer\"  # Set to \"linear\" or \"beer\"\n\n# Optional: extinction coefficient (used only for Beer–Lambert conversion)\nk_extinction &lt;- 0.25\n\n\nlas_file &lt;- file.path(project_root, \"data/TLS/tree_08.laz\")  \noutput_voxels &lt;- file.path(project_root, \"data/TLS/LAD_voxDF.rds\")  \noutput_array &lt;- file.path(project_root, \"data/TLS/lad_array_m2m3.rds\")  \noutput_profile_plot &lt;- file.path(project_root, \"data/TLS/lad_vertical_profile.pdf\")  \n\n\n\nVoxelization of TLS data\nVoxelisation turns a 3D TLS point cloud into a grid of cubes (voxels), where each voxel holds structural information. The number of points per voxel is used to estimate Leaf Area Density (LAD), typically normalized relative to the voxel with the most returns.\n\nEach voxel = a 1×1×1 m³ cube\nCount the laser hits per voxel\nNormalize to maximum\nMultiply by a literature-based LAD_max (e.g. 5 m²/m³)\n\nThis gives a spatially distributed LAD profile suitable for further analysis or models like ENVI-met.\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\nlibrary(terra)\n\n las &lt;- lidR::readLAS(las_file)  # Read the LAS/LAZ file (point cloud data)\n\n\n[=======================================&gt;          ] 78% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[=======================================&gt;          ] 79% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 80% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[========================================&gt;         ] 81% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 82% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[=========================================&gt;        ] 83% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 84% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[==========================================&gt;       ] 85% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 86% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[===========================================&gt;      ] 87% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 88% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[============================================&gt;     ] 89% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 90% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[=============================================&gt;    ] 91% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 92% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[==============================================&gt;   ] 93% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 94% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[===============================================&gt;  ] 95% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 96% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[================================================&gt; ] 97% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 98% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n[=================================================&gt;] 99% ETA: 0s     \n                                                                                \n\n  las@data$Z &lt;- las@data$Z - min(las@data$Z, na.rm = TRUE)  \n  maxZ &lt;- min(floor(max(las@data$Z, na.rm = TRUE)), zmax)  \n  las@data$Z[las@data$Z &gt; maxZ] &lt;- maxZ  \npointsByZSlice = function(Z, maxZ){\n  heightSlices = as.integer(Z) # Round down\n  zSlice = data.table::data.table(Z=Z, heightSlices=heightSlices) # Create a data.table (Z, slices))\n  sliceCount = stats::aggregate(list(V1=Z), list(heightSlices=heightSlices), length) # Count number of returns by slice\n  \n  ##############################################\n  # Add columns to equalize number of columns\n  ##############################################\n  colRange = 0:maxZ\n  addToList = setdiff(colRange, sliceCount$heightSlices)\n  n = length(addToList)\n  if (n &gt; 0) {\n    bindDt = data.frame(heightSlices = addToList, V1=integer(n))\n    sliceCount = rbind(sliceCount, bindDt)\n    # Order by height\n    sliceCount = sliceCount[order(sliceCount$heightSlices),]\n  }\n  \n  colNames = as.character(sliceCount$heightSlices)\n  colNames[1] = \"ground_0_1m\"\n  colNames[-1] = paste0(\"pulses_\", colNames[-1], \"_\", sliceCount$heightSlices[-1]+1, \"m\")\n  metrics = list()\n  metrics[colNames] = sliceCount$V1\n  \n  return(metrics)\n  \n} #end function pointsByZSlice\n\n# --- Main function ---\npreprocess_voxels &lt;- function(normlas, grain.size = 1, maxP =zmax, normalize = TRUE, as_raster = TRUE) {  \n  las &lt;- normlas  \n  \n  # Filter height range\n  las &lt;- filter_poi(las, Z &gt;= 0 & Z &lt;= maxP)  \n  if (lidR::is.empty(las)) return(NULL)\n  # Determine Z-slices\n  maxZ &lt;- floor(max(las@data$Z))  \n  maxZ &lt;- min(maxZ, maxP)  \n  \n  \n  # Compute voxel metrics\n  func &lt;- formula(paste0(\"~pointsByZSlice(Z, \", maxZ, \")\"))  \n  voxels &lt;- pixel_metrics(las, func, res = grain.size)  # Calculate metrics in each voxel (3D grid cell)\n  \n  # Optionally normalize values by voxel volume\n  if (normalize) {\n    vvol &lt;- grain.size^3  \n    voxels &lt;- voxels / vvol  \n  }\n  \n  # Return as both terra::SpatRaster and data.frame\n  result &lt;- list()  \n  \n  if (as_raster) {\n    result$raster &lt;- voxels  \n  }\n  \n  # Convert to data.frame\n  xy &lt;- terra::xyFromCell(voxels, seq_len(ncell(voxels)))  \n  vals &lt;- terra::values(voxels)  \n  df &lt;- cbind(xy, vals)  \n  colnames(df)[1:2] &lt;- c(\"X\", \"Y\")  \n  result$df &lt;- df  \n  \n  return(result)\n}\n\n\n\n\nvox_out &lt;- preprocess_voxels(las, grain.size = 1, maxP = zmax)  \n\n\n\n\n\nConversion to LAD (m²/m³)\nThe conversion to LAD (Leaf Area Density, in m²/m³) from TLS-based voxel pulse counts is done using a relative normalization heuristic which is adopted as a practical approximation in voxel-based canopy structure analysis using TLS (Terrestrial Laser Scanning) data.:\nFor each voxel layer (e.g. pulses_2_3m), the LAD is calculated as:\n\\[\n\\text{LAD}_{\\text{voxel}} = \\left( \\frac{\\text{pulse count in voxel}}{\\text{maximum pulse count over all voxels}} \\right) \\times \\text{LAD}_{\\text{max}}\n\\]\nWhere:\n\npulse count in voxel = number of returns in this voxel layer (from TLS)\nmax_pulse = the maximum pulse count found in any voxel (used for normalization)\nLAD_max = a fixed normalization constant (e.g. 5.0 m²/m³) chosen from literature or calibration\n\n\n\n\n\n\n\nTypical LADₘₐₓ Values by Species\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies / Structure Type\nLADₘₐₓ (m²/m³)\nSource / Notes\n\n\n\n\nFagus sylvatica (European beech)\n3.5–5.5\nCalders et al. (2015), Chen et al. (2018)\n\n\nQuercus robur (English oak)\n3.0–6.0\nHosoi & Omasa (2006), field studies with TLS voxelization\n\n\nConiferous trees (e.g. pine)\n4.0–7.0\nWilkes et al. (2017), higher LAD due to needle density\n\n\nMixed broadleaf forest\n3.0–6.0\nFlynn et al. (2023), canopy averaged estimates\n\n\nShrubs / understorey\n1.5–3.0\nChen et al. (2018),lower vertical structure density\n\n\nUrban street trees\n2.0–4.0\nSimon et al. (2020), depending on pruning and species\n\n\n\nLAD values refer to maximum expected per 1 m vertical voxel. Values depend on species, seasonality, and scanning conditions.\n\n\n\nWhat this means conceptually\nYou’re not measuring absolute LAD, but instead:\n\nUsing the number of TLS returns per voxel as a proxy for leaf density\nThen normalization all voxels relatively to the most “leaf-dense” voxel\nThe LAD_max defines what value the “densest” voxel should reach in terms of LAD\n\nThis is fast, simple, and works well when:\n\nYou want relative structure across the canopy\nYou don’t have absolute calibration (e.g. with destructive sampling or hemispheric photos)\n\nCaveats and assumptions\n\nThis approach assumes the TLS beam returns are proportional to leaf area, which is a simplification\nIt’s sensitive to occlusion and TLS positioning\nThe choice of LAD_max is crucial—common values from literature range from 3–7 m²/m³ for dense canopies\n\nThe LAD conversion in the following code is a relative, normalized mapping of TLS pulse counts to LAD values, normalized by the highest voxel return and normalized using a fixed LAD_max. This gives a plausible LAD field usable for analysis, visualization, or simulation input (e.g. for ENVI-met).\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\nlibrary(terra)\nconvert_matrix_to_df &lt;- function(mat) {  \n  df &lt;- as.data.frame(mat)  \n  colnames(df) &lt;- attr(mat, \"dimnames\")[[2]]  \n  return(df)\n}\n\n# --- Preprocess LiDAR data into voxel metrics -------------------------------\nvox_out &lt;- preprocess_voxels(las, grain.size = 1, maxP = zmax)  # Calculate vertical pulse metrics\nvox_df &lt;- convert_matrix_to_df(vox_out$df)                      # Convert voxel array to data.frame\n\n#' Convert TLS voxel pulse data to LAD using Beer–Lambert conversion conversion with post-normalization\n#'\n#' @param df A data.frame with pulse columns (from TLS voxelization)\n#' @param grainsize Numeric, vertical voxel height (e.g., 1 m)\n#' @param k Extinction coefficient (default: 0.3)\n#' @param scale_factor Optional multiplicative scale factor (default: 1.2)\n#' @param lad_max Optional maximum LAD clamp (e.g. 2.5); set to NULL to disable\n#' @param lad_min Optional minimum LAD threshold (e.g. 0.05); set to NULL to disable\n#' @param keep_pulses Logical, whether to retain pulse columns (default: FALSE)\n#'\n#' @return Data.frame with LAD columns added\n#' @export\nconvert_to_LAD_beer &lt;- function(df,\n                                grainsize = 1,\n                                k = 0.3,\n                                scale_factor = 1.2,\n                                lad_max = 2.5,\n                                lad_min = 0.05,\n                                keep_pulses = FALSE) {\n  df_lad &lt;- df\n  pulse_cols &lt;- grep(\"^pulses_\", names(df_lad), value = TRUE)\n  \n  for (col in pulse_cols) {\n    lad_col &lt;- paste0(\"lad_\", sub(\"pulses_\", \"\", col))\n    p_rel &lt;- df_lad[[col]] / max(df_lad[[col]], na.rm = TRUE)\n    \n    # Avoid log(0) and 1\n    p_rel[p_rel &gt;= 1] &lt;- 0.9999\n    p_rel[p_rel &lt;= 0] &lt;- 1e-5\n    \n    # Apply Beer–Lambert conversion\n    lad_vals &lt;- -log(1 - p_rel) / (k * grainsize)\n    \n    # Apply normalization\n    lad_vals &lt;- lad_vals * scale_factor\n    \n    # Clamp LAD values if needed\n    if (!is.null(lad_max)) {\n      lad_vals &lt;- pmin(lad_vals, lad_max)\n    }\n    if (!is.null(lad_min)) {\n      lad_vals &lt;- pmax(lad_vals, lad_min)\n    }\n    \n    df_lad[[lad_col]] &lt;- lad_vals\n    \n    if (!keep_pulses) {\n      df_lad[[col]] &lt;- NULL\n    }\n  }\n  \n  return(df_lad)\n}\n\n\n#' Convert TLS Pulse Counts to Leaf Area Density (LAD)\n#'\n#' Transforms vertically binned pulse counts (from voxelized TLS data) into Leaf Area Density (LAD, m²/m³)\n#' by normalizing pulse values to a specified LAD maximum.\n#'\n#' @param df A `data.frame` containing voxelized TLS pulse data. Must include columns starting with `\"pulses_\"`, \n#'           each representing pulse returns per vertical layer (e.g. `pulses_1_2m`, `pulses_2_3m`, ...).\n#' @param grainsize Numeric. The voxel edge length in meters (assumed cubic). Default is `1`.\n#' @param LADmax Numeric. The maximum LAD value in m²/m³ for relative normalization. Common values: `4.0`–`6.0`. Default is `5.0`.\n#' @param keep_pulses Logical. If `FALSE` (default), the original pulse columns are removed from the output. If `TRUE`, they are retained alongside the LAD columns.\n#'\n#' @return A modified `data.frame` with new LAD columns (`lad_1_2m`, `lad_2_3m`, ...) in m²/m³, normalized relatively to `LADmax`.\n#'\n#' @details\n#' - Each `pulses_*` column is linearly normalized by the overall maximum value across all vertical bins and locations.\n#' - The result is a relative LAD estimate, useful for ecological modeling, input to microclimate simulations (e.g., ENVI-met), or structural analysis.\n#' - Voxel volume is implicitly considered constant due to cubic assumption (via `grainsize`) but is not explicitly used here.\n#'\n#' @examples\n#' \\dontrun{\n#'   df_vox &lt;- readRDS(\"TLS/voxel_metrics.rds\")\n#'   lad_df &lt;- convert_to_LAD(df_vox, grainsize = 1, LADmax = 5)\n#'   head(names(lad_df))  # Should show lad_* columns\n#' }\n#'\n#' @export\nconvert_to_LAD &lt;- function(df, grainsize = 1, LADmax = 5.0, keep_pulses = FALSE) {  \n  # df: Data frame mit voxelisierten TLS-Daten\n# grainsize: Voxelgröße in m (würfelförmig angenommen)\n# LADmax: maximaler LAD-Wert (Literaturbasiert, z. B. 5.0 m²/m³)\n  df_lad &lt;- df  \n  pulse_cols &lt;- grep(\"^pulses_\", names(df_lad), value = TRUE)  \n  \n  # Schichtanzahl = Anzahl Pulse-Spalten\n  n_layers &lt;- length(pulse_cols)  \n  \n  # Optional: originales Maximum zur linearen Skalierung (relativ)\n  max_pulse &lt;- max(df_lad[, pulse_cols], na.rm = TRUE)  \n  \n  # Umwandlung in LAD (m²/m³) – Skaliert auf LADmax oder absolut (siehe Kommentar)\n  for (col in pulse_cols) {\n    lad_col &lt;- paste0(\"lad_\", sub(\"pulses_\", \"\", col))  \n    \n    # Hier wird RELATIV zu max_pulse skaliert → einfache Normalisierung\n    df_lad[[lad_col]] &lt;- (df_lad[[col]] / max_pulse) * LADmax  \n    \n    # Optional: löschen der Pulse-Spalten\n    if (!keep_pulses) {\n      df_lad[[col]] &lt;- NULL  \n    }\n  }\n  \n  return(df_lad)\n}\n\n\n\n# method selection\nif (lad_method == \"beer\") {\n  message(\"✔ Using Beer–Lambert conversion LAD conversion...\")\n  df_lad &lt;- convert_to_LAD_beer(\n    vox_df,\n    grainsize = 1,\n    k = k_extinction,\n    scale_factor = 0.4,\n    lad_max = 2.5,\n    lad_min = 0.0\n  )\n} else if (lad_method == \"linear\") {\n  message(\"Using linear LAD conversion...\")\n  df_lad &lt;- convert_to_LAD(\n    vox_df,\n    grainsize = 1,\n    LADmax = 5.0\n  )\n} else {\n  stop(\"Unknown LAD conversion method: choose 'linear' or 'beer'\")\n}\n\n\n\n\n\nDT::datatable(head(df_lad, 5))\n\n\n\n\n\n\n\nRaster Stack Representation of 3D Vegetation (Voxel-Based)\nWe represent 3D vegetation using a voxel-based raster stack:\n\nSpace is divided into cubic voxels (e.g. 1 × 1 × 1 m).\nEach raster layer represents a height slice (e.g. 0–1 m, 1–2 m, …).\nVoxels store values like pulse counts or Leaf Area Density (LAD).\n\nThis 2D stack structure enables:\n\nVertical profiling of vegetation per XY column.\nLayer-wise analysis (e.g. median, entropy).\nIntegration with raster data like topography or irradiance.\nUse in raster-based ecological and microclimate models.\n\nIt supports both analysis and visualization of vertical structure with standard geospatial tools.\nENVI-met supports custom vegetation input via the SimplePlant method, which requires a vertical LAD profile per grid column. A raster stack derived from TLS data provides exactly this: each layer represents LAD in a specific height slice, and each XY cell corresponds to one vertical profile. This structure can be exported as CSV, ASCII rasters, or custom profile files.\nFor 3D vegetation parameterization in ENVI-met 5.8+, the raster stack enables preprocessing of spatially explicit LAD or LAI profiles, even if some reformatting is needed.\nThe raster stack also supports canopy clustering and prototyping. It allows classification of structural types, simplification of complex vegetation, and the creation of representative profiles for simulation.\n\nlibrary(terra)\n# In SpatRasterStack umwandeln\nxy &lt;- df_lad[, c(\"X\", \"Y\")]  \nlad_vals &lt;- df_lad[, grep(\"^lad_\", names(df_lad), value = TRUE)]  \n\nlad_raster &lt;- rast(cbind(xy, lad_vals), type = \"xyz\")  \nplot(lad_raster)\n\n\n\n\n\n\n\n\nIn a more 3D version it looks like below.\n\n# #| eval: false\n# #| include: false\n# library(terra)\n# library(rgl)\n# \n# # Threshold value for LAD\n# threshold &lt;- 0.1 # change as needed\n# \n# # Step 1: Convert raster to voxel data frame\n# rast_cube &lt;- lad_raster  # your raster stack\n# voxel_df &lt;- as.data.frame(rast_cube, xy = TRUE, na.rm = TRUE)\n# names(voxel_df) &lt;- c(\"x\", \"y\", paste0(\"z\", seq_len(nlyr(rast_cube))))\n# \n# # Step 2: Reshape to long format\n# voxel_long &lt;- reshape(\n#   voxel_df,\n#   direction = \"long\",\n#   varying = paste0(\"z\", seq_len(nlyr(rast_cube))),\n#   v.names = \"val\",\n#   timevar = \"z\",\n#   times = seq_len(nlyr(rast_cube))\n# )\n# \n# # Step 3: Clean up and filter by threshold\n# voxel_long &lt;- voxel_long[!is.na(voxel_long$val) & voxel_long$val &gt; threshold, ]\n# voxel_long$z &lt;- as.numeric(voxel_long$z)\n# \n# # Step 4: Normalize colors\n# colors &lt;- terrain.colors(100)[cut(voxel_long$val, breaks = 100)]\n# \n# # Step 5: Draw voxel cubes\n# open3d(useNULL = TRUE)\n# for (i in seq_len(nrow(voxel_long))) {\n#   shade3d(\n#     translate3d(cube3d(scale = 1), \n#                 voxel_long$x[i], \n#                 voxel_long$y[i], \n#                 voxel_long$z[i]),\n#     color = colors[i],\n#     alpha = 0.8\n#   )\n# }\n# \n# # Step 6: Render in browser\n# # Determine the bounds of your voxel space\n# xlim &lt;- range(voxel_long$x)\n# ylim &lt;- range(voxel_long$y)\n# zlim &lt;- range(voxel_long$z)\n# \n# # Draw bounding box\n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[1], zlim[1]),\n#   c(xlim[2], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[2], zlim[1]),\n#   c(xlim[1], ylim[1], zlim[1])\n# ), col = \"black\", lwd = 2)\n# \n# lines3d(rbind(\n#   c(xlim[1], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[1], zlim[2]),\n#   c(xlim[2], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[2], zlim[2]),\n#   c(xlim[1], ylim[1], zlim[2])\n# ), col = \"black\", lwd = 2)\n# \n# for (i in 1:4) {\n#   lines3d(\n#     rbind(\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[1]),\n#       c(xlim[c(1,2,2,1)][i], ylim[c(1,1,2,2)][i], zlim[2])\n#     ), col = \"black\", lwd = 2\n#   )\n# }\n# \n# # Optional: Add coordinate axes\n# axes3d(edges = c(\"x--\", \"y--\", \"z--\"), col = \"gray40\")\n# title3d(xlab = \"X\", ylab = \"Y\", zlab = \"Z\")\n# widget &lt;- rglwidget()\n# htmlwidgets::saveWidget(widget, \"tree_voxel_viewer.html\", selfcontained = TRUE)\n\n\n\nVisualization\n\nLAD Profile Visualizations from TLS Data\nThe plot_lad_profiles() function visualizes vertical leaf area density (LAD) profiles derived from voxelized TLS (terrestrial laser scanning) data. LAD represents leaf surface area per unit volume (m²/m³). The function provides three main plot styles:\n\n\n1. XY Matrix Plot (plotstyle = \"each_median\")\n\nDisplays a grid of mini-profiles, each representing a 0.5 × 0.5 m (x/y) ground column.\nWithin each cell, a normalized vertical LAD profile is plotted:\n\nY-axis (height) is normalized from 0 to 1 per column.\nX-axis shows LAD values normalized relative to the global LAD maximum.\n\nUseful for comparing structural patterns across space.\n\n\n\n2. Overall Median Profile (plotstyle = \"all_median\")\n\nAggregates LAD values across all (x/y) locations by height bin.\nProduces a typical vertical profile using the median and smoothed with a moving average.\nHeight is shown in absolute units (e.g. meters).\nCaptures the dominant vertical canopy structure.\n\n\n\n3. Single Profile (plotstyle = \"single_profile\")\n\nExtracts and plots the LAD profile at a specific (x, y) coordinate.\nBoth LAD and height are shown in absolute units.\nPlots the true vertical structure at one location.\n\nThe matrix plot shows multiple vertical LAD profiles arranged in a grid, with each small plot corresponding to a specific spatial location. This allows the vertical vegetation structure to be viewed in relation to its position on the ground. To make the individual profiles comparable, both height and LAD values are normalized within the plot. A reference profile on the side shows the overall median LAD distribution by height, which helps interpret the scale and shape of the individual profiles.\n\n\n\n\n\n\nView Code\n\n\n\n\n\n\n# --- Reshape LAD data to long format ----------------------------------------\n\nlad_df &lt;- as.data.frame(lad_raster, xy = TRUE, na.rm = TRUE)     # Convert raster to data.frame\n\n# 1. Extract LAD columns and XY coordinates\npulse_cols &lt;- grep(\"^lad_\", names(lad_df), value = TRUE)\nxy_cols &lt;- c(\"x\", \"y\")  # Adjust to \"X\", \"Y\" if needed\n\n# 2. Reshape to long format (one row per LAD layer)\nlad_df &lt;- reshape(\n  data = lad_df[, c(xy_cols, pulse_cols)],\n  varying = pulse_cols,\n  v.names = \"LAD\",\n  timevar = \"layer\",\n  times = pulse_cols,\n  direction = \"long\"\n)\n\n# 3. Extract z-layer information from column names\nlad_df$z_low  &lt;- as.numeric(sub(\"lad_(\\\\d+)_.*\", \"\\\\1\", lad_df$layer))  \nlad_df$z_high &lt;- as.numeric(sub(\"lad_\\\\d+_(\\\\d+)m\", \"\\\\1\", lad_df$layer))  \n\n# 4. Compute mid-point height of each voxel layer\nlad_df$Height &lt;- (lad_df$z_low + lad_df$z_high) / 2  \n\n# 5. Round to whole meters to create height classes\nlad_df$Height_bin &lt;- round(lad_df$Height)  \n\n# --- Aggregate median LAD per 0.5 × 0.5 m column ----------------------------\nsetDT(lad_df)  # Use data.table for efficient aggregation\n\nlad_by_column &lt;- lad_df[  \n  , .(LAD_median = median(LAD, na.rm = TRUE)), \n  by = .(x, y, Height_bin)\n]\n\n# Convert back to regular data.frame\nlad_df &lt;- as.data.frame(lad_by_column)\n\nplot_lad_profiles &lt;- function(lad_df, plotstyle = c(\"each_median\", \"all_median\", \"single_profile\"),  \n                              single_coords = c(NA, NA)) {\n  plotstyle &lt;- match.arg(plotstyle)  \n  \n  # Combine x and y coordinates into a unique column ID\n  lad_df$col_id &lt;- paste(lad_df$x, lad_df$y, sep = \"_\")  \n  x_levels &lt;- sort(unique(lad_df$x))  \n  y_levels &lt;- sort(unique(lad_df$y))  \n  # Convert x/y coordinates to factor variables for matrix layout\n  lad_df$x_f &lt;- factor(lad_df$x, levels = x_levels)  \n  lad_df$y_f &lt;- factor(lad_df$y, levels = y_levels)  \n  n_x &lt;- length(x_levels)  \n  n_y &lt;- length(y_levels)  \n  \n  # Determine the maximum LAD value for relative normalization\n  lad_max &lt;- max(lad_df$LAD_median, na.rm = TRUE)  \n  height_range &lt;- range(lad_df$Height_bin, na.rm = TRUE)  \n  dx &lt;- 0.8  \n  dy &lt;- 0.8  \n  \n  par(mar = c(5, 5, 4, 5), xpd = TRUE)\n  \n \n\n  \n  # Differentiate by plot type: all profiles, overall profile, or single profile\n  if (plotstyle == \"each_median\") {\n # Load PNG legend\nlegend_img &lt;- png::readPNG(\"output.png\")\n\n# Define aspect-preserving image placement\nimg_height_units &lt;- 20\nimg_width_units &lt;- img_height_units * dim(legend_img)[2] / dim(legend_img)[1]  # preserve ratio\n\n# Define position\nimg_x_left &lt;- n_x + 1.5\nimg_x_right &lt;- img_x_left + img_width_units\nimg_y_bottom &lt;- 0\nimg_y_top &lt;- img_y_bottom + img_height_units\n\n# Begin plot\nplot(NA, xlim = c(1, n_x + img_width_units + 4), ylim = c(1, n_y),\n     type = \"n\", axes = FALSE, xlab = \"\", ylab = \"\",\n     main = \"Vertical LAD Profiles in XY Matrix\", asp = 1.2)\n\n\n# Draw all LAD profiles\nfor (i in seq_along(x_levels)) {\n  for (j in seq_along(y_levels)) {\n    profile &lt;- subset(lad_df, x == x_levels[i] & y == y_levels[j])\n    if (nrow(profile) == 0) next\n    lad_scaled &lt;- profile$LAD_median / lad_max\n    height_scaled &lt;- (profile$Height_bin - min(height_range)) / diff(height_range)\n    lines(x = lad_scaled * dx + i,\n          y = height_scaled * dy + j,\n          col = \"darkgreen\", lwd = 1)\n  }\n}\n\n# Axis labels for ground position\naxis(1, at = 1:n_x, labels = round(x_levels, 1), las = 2)\naxis(2, at = 1:n_y, labels = round(y_levels, 1), las = 2)\n\n# Add the image\nrasterImage(legend_img,\n            xleft = img_x_left,\n            xright = img_x_right,\n            ybottom = img_y_bottom,\n            ytop = img_y_top)\n\n    \n  } else if (plotstyle == \"all_median\") {\n    unique_heights &lt;- sort(unique(lad_df$Height_bin))  \n    lad_median &lt;- numeric(length(unique_heights))  \n    for (i in seq_along(unique_heights)) {\n      h &lt;- unique_heights[i]  \n      lad_median[i] &lt;- median(lad_df$LAD[lad_df$Height_bin == h], na.rm = TRUE)  \n    }\n    lad_smooth &lt;- stats::filter(lad_median, rep(1/3, 3), sides = 2)  \n    \n    plot(\n      lad_smooth, unique_heights,\n      type = \"l\",\n      col = \"darkgreen\",\n      lwd = 2,\n      xlab = \"Leaf Area Density (m²/m³)\",\n      ylab = \"Height (m)\",\n      main = \"Vertical LAD Profile (smoothed)\",\n      xlim = c(0, max(lad_smooth, na.rm = TRUE)),\n      ylim = range(unique_heights)\n    )\n    \n    text(\n      x = as.numeric(lad_smooth),\n      y = unique_heights,\n      labels = round(as.numeric(lad_smooth), 1),\n      pos = 4,\n      cex = 0.7,\n      col = \"black\"\n    )\n    grid()\n    \n    \n  } else if (plotstyle == \"single_profile\") {\n    x_target &lt;- single_coords[1]  \n    y_target &lt;- single_coords[2]  \n    tol &lt;- 1e-6  \n    \n    profile &lt;- subset(lad_df, abs(x - x_target) &lt; tol & abs(y - y_target) &lt; tol)  \n    \n    if (nrow(profile) == 0) {\n      # Show warning if no profile exists for selected coordinates\n      warning(\"No data for the selected coordinates.\")\n      plot.new()\n      title(main = paste(\"No profile at\", x_target, \"/\", y_target))\n      return(invisible(NULL))\n    }\n    \n    # Normalize height and LAD\n    height_range &lt;- range(profile$Height_bin, na.rm = TRUE)  \n    # Determine the maximum LAD value for relative normalization\n    lad_max &lt;- max(profile$LAD_median, na.rm = TRUE)  \n    \n    height_scaled &lt;- (profile$Height_bin - min(height_range)) / diff(height_range)  \n    height_unscaled &lt;- profile$Height_bin\n    # Determine the maximum LAD value for relative normalization\n    lad_scaled &lt;- profile$LAD_median / lad_max  \n    \n    plot(\n      x = lad_scaled,\n      y = height_unscaled, #height_scaled,\n      type = \"l\",\n      lwd = 2,\n      col = \"darkgreen\",\n      xlab = \"LAD (normalized)\",\n      ylab = \"Height (m)\",\n      main = paste(\"Profile at\", x_target, \"/\", y_target)\n    )\n  }\n}\n# --- Visualize LAD profiles -------------------------------------------------\n\n\n\n\n\n# Option 1: Profile in each column\nplot_lad_profiles(lad_df, plotstyle = \"each_median\")\n\n\n\n\n\n\n\n# Option 2: Overall vertical LAD profile (median of all)\nplot_lad_profiles(lad_df, plotstyle = \"all_median\")\n\n\n\n\n\n\n\n# Option 3: Single profile at specified coordinates\nplot_lad_profiles(lad_df, plotstyle = \"single_profile\", single_coords = c(57.5, -94.5))",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#envi-met-3d-tree-export",
    "href": "doc/tls_v1_2.html#envi-met-3d-tree-export",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "ENVI-met 3D Tree Export",
    "text": "ENVI-met 3D Tree Export\nThe next section describes more detailed how the key input values in the R function export_lad_to_envimet3d() are computed, derived or selected, and provides the rationale for each. The function converts a voxel-based Leaf Area Density (LAD) profile, typically obtained from Terrestrial Laser Scanning (TLS) data, into a structured XML file compatible with ENVI-met’s 3D tree model (.pld or PLANT3D).\nGiven the sensitivity of ENVI-met simulations to tree morphology and LAD distribution, the function ensures that the spatial dimensions, vertical layering and LAD intensity values are all correctly represented. Some parameters are optional, but can be derived from the data if not explicitly set.\nThe table below details each argument of the function, including its purpose, how it is determined and its necessity.\n\n\n\n\n\n\n\n\nCode Line\nMeaning\nReason\n\n\n\n\nlad_df &lt;-lad_df[!is.na(lad_df$LAD_median), ]\nRemoves entries with missing LAD values\nEnsures only valid data is used in the LAD calculation and XML export\n\n\nlad_df$i &lt;-as.integer(factor(lad_df$x))\nConverts x-coordinates to integer voxel column indices (i)\nRequired for ENVI-met LAD matrix indexing\n\n\nlad_df$j &lt;-as.integer(factor(lad_df$y))\nConverts y-coordinates to integer voxel row indices (j)\nSame as above, for the y-direction\n\n\nz_map &lt;-setNames( ...)\nMaps unique height bins to sequential vertical indices (k)\nTranslates height levels into voxel layers compatible with ENVI-met\n\n\nlad_df$k &lt;-z_map[as.character(lad_df$Height_bin)]\nApplies the vertical index to the LAD data\nAligns LAD values with ENVI-met vertical layer system\n\n\nlad_df$lad_value &lt;-round(lad_df$LAD_median * scale_factor, 5)\nScales LAD values and rounds to 5 digits\nBrings LAD values to a usable range for ENVI-met and ensures precision\n\n\ndataI &lt;-max(lad_df$i)\nGets the number of horizontal grid cells in i-direction (width)\nRequired as matrix size input for ENVI-met\n\n\ndataJ &lt;-max(lad_df$j)\nGets the number of horizontal grid cells in j-direction (depth)\nRequired as matrix size input for ENVI-met\n\n\nzlayers &lt;-max(lad_df$k)\nGets the number of vertical layers\nSets the height resolution of the LAD matrix",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#automatic-grid-dimensions-transformation",
    "href": "doc/tls_v1_2.html#automatic-grid-dimensions-transformation",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Automatic Grid Dimensions transformation",
    "text": "Automatic Grid Dimensions transformation\nCalculates the voxel grid dimensions in X, Y, and Z from the TLS-derived LAD profile.\nThe table below outlines how the core spatial and structural parameters of the tree model are computed from the input LAD_DF data frame. These derived values define the three-dimensional structure of the tree in terms of its horizontal extent, vertical layering and canopy dimensions.\nData I and data J represent the size of the voxel grid in the i and j dimensions, respectively, based on unique horizontal (x and y) and vertical (height bin) bins in the LAD profile.\n‘Width’ and ‘Depth’ describe the physical spread of the tree crown, inferred from the voxel grid extent if not manually set.\nHeight is computed by multiplying the number of vertical layers (zlayers) by the voxel resolution (cellSize), providing the total modelled height of the canopy.\nThese computed values are essential for correctly normalization and locating the 3D LAD matrix within the ENVI-met simulation domain to ensure visual and physiological realism.\n\n\n\n\n\n\n\n\nCode Line\nMeaning\nReason\n\n\n\n\nWidth  &lt;- if (is.null(Width)) dataI else Width\nUses the number of i-cells if Width is not provided\nAutomatically estimates tree width from voxel spread in x-direction\n\n\nDepth  &lt;- if (is.null(Depth)) dataJ else Depth\nUses the number of j-cells if Depth is not provided\nAutomatically estimates tree depth from voxel spread in y-direction\n\n\nHeight &lt;- zlayers * cellsize\nConverts number of vertical layers to metric height using cellsize\nComputes physical tree height in meters for ENVI-met\n\n\n\n# 1. Remove NA values from the LAD column\nlad_df &lt;- lad_df[!is.na(lad_df$LAD_median), ]\n\n# 2. Create discrete i and j indices for the horizontal position\n# (converts x and y coordinates into consecutive index values)\nlad_df$i &lt;- as.integer(factor(lad_df$x))\nlad_df$j &lt;- as.integer(factor(lad_df$y))\n\n# 3. Assign each Height_bin (z direction) a consecutive layer ID k\n# (z_map assigns an index layer to each unique height)\nz_map &lt;- setNames(seq_along(sort(unique(lad_df$Height_bin))), sort(unique(lad_df$Height_bin)))\nlad_df$k &lt;- z_map[as.character(lad_df$Height_bin)]\n\n# 4. Scale LAD values, e.g. to get from 0.02 to more realistic values such as 0.5–1.5\nlad_df$lad_value &lt;- round(lad_df$LAD_median * scale_factor, 5)\n\n# 5. Calculate the maximum dimensions of the grid (for XML specifications)\ndataI &lt;- max(lad_df$i) # Width in cells (x-direction)\ndataJ &lt;- max(lad_df$j) # Depth in cells (y-direction)\nzlayers &lt;- max(lad_df$k) # Number of vertical layers (z-direction)",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#transmittance-and-albedo",
    "href": "doc/tls_v1_2.html#transmittance-and-albedo",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Transmittance and Albedo",
    "text": "Transmittance and Albedo\nAlbedo = 0.18\nTransmittance = 0.3\nAlbedo = 0.18: Albedo is the fraction of incoming solar radiation reflected by the canopy surface. For deciduous trees, values usually range between 0.15 and 0.20. 0.18 is a commonly used default for broadleaved species like Fagus sylvatica or Quercus robur in many ecological models (e.g., ENVI-met, MAESPA). It affects surface energy balance and radiation reflection in ENVI-met simulations.\nTransmittance = 0.3: Transmittance represents the proportion of shortwave radiation that passes through the canopy without being absorbed or reflected. Deciduous trees in full leaf have transmittance values between 0.1 and 0.4 depending on species and LAI. 0.3 reflects moderate canopy density, consistent with empirical observations for mid-summer crowns. It controls how much light reaches the ground and sub-canopy vegetation; affects microclimate and shading.\nBoth values can be adjusted to match field measurements or literature for specific species or leaf phenology. However you can use them as robust fallback defaults when exact species traits are unavailable.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#season-profile",
    "href": "doc/tls_v1_2.html#season-profile",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Season-Profile",
    "text": "Season-Profile\nDefines monthly LAD normalization.\nSeasonProfile = c(0.2, 0.2, 0.4, 0.7, 1.0, 1.0, 1.0, 0.8, 0.6, 0.3, 0.2, 0.2)\nThe SeasonProfile is a vector of 12 numeric values (one per month) weighting the relative Leaf Area Density (LAD) throughout the year. It models seasonal leaf development and senescence, controlling how much foliage is present in each month:\n\nValues range from 0.0 (no foliage) to 1.0 (full foliage).\nFor deciduous trees like Fagus sylvatica or Quercus robur, foliage develops in spring (April–May), peaks in summer (June–August), and declines in autumn (September–October).\n\nProfile Breakdown:\n\n\n\nMonths\nValue\nInterpretation\n\n\n\n\nJan–Feb, Nov–Dec\n0.2\nDormant / leafless\n\n\nMarch\n0.4\nBudburst begins\n\n\nApril\n0.7\nLeaf expansion\n\n\nMay–July\n1.0\nFull canopy\n\n\nAugust\n0.8\nLeaf maturity decline\n\n\nSeptember\n0.6\nSenescence onset\n\n\nOctober\n0.3\nStrong senescence\n\n\n\nThe SeasonProfile directly influences LAD in ENVI-met’s dynamic vegetation simulation — affecting transpiration, shading, and energy balance across the simulation year. Adjusting this vector allows tailoring of phenology to site-specific or species-specific data.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#l-systembased-trees-in-envi-met-experimetal",
    "href": "doc/tls_v1_2.html#l-systembased-trees-in-envi-met-experimetal",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "L-SystemBased trees in ENVI-met (Experimetal)",
    "text": "L-SystemBased trees in ENVI-met (Experimetal)\nENVI-met optionally allows procedural generation of tree architecture using Lindenmayer Systems (L-Systems) — a formal grammar originally used to simulate plant growth patterns. When L-SystemBased = 1, the geometry of the tree is not derived from a static LAD matrix alone, but supplemented or replaced by rule-based 3D branching structures which supplement or replace the matrix. This is independent of the LAD profile but may affect shading and visualisation in the Albero interface of ENVI-met.\nL-SystemBased = 1\nAxiom = \"F(2)V\\V\\\\V/////B\"\nIterationDepth = 3\n\nExplanation of Key Parameters\n\n\n\n\n\n\n\nParameter\nMeaning\n\n\n\n\nL-SystemBased\nIf 1, enables L-system generation (uses rules to grow plant structure)\n\n\nAxiom\nStarting string (“seed”) for the L-system; defines base growth\n\n\nIterationDepth\nHow many times to apply production rules; higher means more detail\n\n\nTermLString\nOptional: Final symbol to be drawn/rendered (e.g. “L”)\n\n\nApplyTermLString\nIf 1, interprets the TermLString; otherwise, renders entire string\n\n\n\n\n\nDefault Settings\n\n\n\nL-System Branching as implemented by default\n\n\n&lt;L-SystemBased&gt;1&lt;/L-SystemBased&gt;\n&lt;Axiom&gt;F(2)V\\V\\\\V/////B&lt;/Axiom&gt;\n&lt;IterationDepth&gt;3&lt;/IterationDepth&gt;\n&lt;TermLString&gt;L&lt;/TermLString&gt;\n&lt;ApplyTermLString&gt;1&lt;/ApplyTermLString&gt;\n\nF(2): Move forward with length 2 (main trunk)\nV\\\\V/////B: Branching pattern with rotations (backslashes and slashes encode rotation commands); B may denote a terminal leaf or bud\nIterationDepth = 3: The production rules (if defined) will be applied 3 times to this axiom, generating a fractal-like tree structure.\n\n\nNote: In ENVI-met, the actual grammar rules are hard-coded and not customizable in .pld — only the axiom and iteration depth are user-defined. It is highly experimental and poorly documented\n\nUse L-SystemBased = 1 if:\n\nYou want visual structure added to otherwise sparse or low-resolution LAD matrices\nThe tree lacks realistic shape (for Albero visualization)\nUse L-SystemBased = 0 (default) if:\n\nYou already provide a dense voxel-based LAD (from TLS or similar)\nYou want strict control over the 3D structure via LAD profile only\n\n\n\n\nImport TLS-based .pld into ENVI-met via Albero Clipboard\nRequirements\n- ENVI-met 5.8+\n- .pld file (e.g. oak_tls_envimet.pld)\n- Albero editor (via Leonardo)\nSteps\n1. Open Albero\n→ Leonardo → Database → Plant Database\n2. Open Clipboard\n→ Click Clipboard (top-right)\n3. Import .pld\n→ Clipboard → Import → Load file\n4. Edit (optional)\n→ Adjust LAD, albedo, transmittance, name, etc.\n5. Send to Library\n→ Click “Send to Library”\n6. Use in ENVI-met\n→ In Leonardo/Spaces assign plant to your 3D model\nNotes\n- .pld contains LAD(z) values (m²/m³)\n- Use Advanced Settings to fine-tune visualization\n- Custom plants stored in your personal Albero library",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#key-benefits",
    "href": "doc/tls_v1_2.html#key-benefits",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Key Benefits",
    "text": "Key Benefits\n\nEfficient and scalable: The method avoids destructive sampling by using TLS return counts as proxies for leaf density. This makes it suitable for large-scale or repeated surveys without the need for time-consuming ground calibration.\nCaptures structural patterns: Normalizing the LAD values retains the vertical and spatial structure of vegetation, enabling meaningful comparison of crown shape, canopy layering, and vegetation density across space or time.\nDirectly usable in ENVI-met: The output is structured as a raster stack with height-specific layers, aligning with the input requirements of ENVI-met’s SimplePlant or 3D vegetation modules. This enables seamless integration into microclimate simulations.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#limitations",
    "href": "doc/tls_v1_2.html#limitations",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Limitations",
    "text": "Limitations\n\nSimplified assumptions: The linear mapping of TLS returns to LAD assumes a proportional relationship, which simplifies the complex interaction between laser pulses and vegetation surfaces.\nScan geometry dependency: Occlusion, scan angle, and varying point densities can distort the return distribution, especially in dense or multi-layered vegetation.\nGeneric LAD normalization: The maximum LAD value used for normalization is taken from literature-based estimates rather than site-specific measurements, which can introduce bias in absolute LAD magnitudes.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#conclusion",
    "href": "doc/tls_v1_2.html#conclusion",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Conclusion",
    "text": "Conclusion\nThis workflow offers a robust and accessible approach for analyzing vegetation structure and generating model-ready LAD profiles from TLS data. It is especially useful for relative comparisons and ecological modeling, but is not intended for absolute LAD quantification without additional calibration.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#why-als-requires-a-specific-lad-approach",
    "href": "doc/tls_v1_2.html#why-als-requires-a-specific-lad-approach",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Why ALS Requires a Specific LAD Approach",
    "text": "Why ALS Requires a Specific LAD Approach\nUnlike TLS (Terrestrial Laser Scanning), which scans from the bottom-up and suffers from occlusion in upper layers, ALS samples vegetation top-down. This means:\n\nALS oversamples upper canopy layers\nALS undersamples lower canopy due to occlusion\n\nTo correct for this sampling bias, we estimate LAD using a modified form of Beer’s Law, based on the normalized proportion of hits per voxel layer. The key difference lies in the way “gap probability” is estimated: rather than tracking cumulative occlusion, ALS uses the maximum return count per column as a proxy for full canopy closure.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#lad-estimation-using-beers-law",
    "href": "doc/tls_v1_2.html#lad-estimation-using-beers-law",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "LAD Estimation Using Beer’s Law",
    "text": "LAD Estimation Using Beer’s Law\nWe model LAD using:\n\\[\nLAD = -\\frac{\\ln(1 - p)}{k \\cdot dz}\n\\]\nWhere: - ( p ) is the normalized proportion of hits per voxel column (( 0 &lt; p &lt; 1 )) - ( k ) is the light extinction coefficient - ( dz ) is the vertical resolution (voxel height)\nIn our script, we set: - ( k = 0.3 ) (typical value) - LAD values are scaled using a multiplicative factor (default 1.2)\n\nTLS Variant of LAD\nIn TLS-based LAD estimation, we assume that the LiDAR sensor is located near ground level and that returns are accumulated from bottom to top. In this setup, each voxel’s return count ( N_i ) is interpreted as contributing to the cumulative transmittance through the canopy.\nThe Beer–Lambert law is applied as:\n\\[\n\\text{LAD}_i = -\\frac{\\ln\\left(1 - \\frac{N_i}{N_{\\max}}\\right)}{k \\cdot \\Delta z}\n\\]\nHere: - ( N_i ): number of returns in voxel layer ( i ) - ( N_{} ): maximum number of returns in any voxel in the column (used to normalize return density) - ( z ): voxel height - ( k ): extinction coefficient\n\nPhysical Interpretation\nThe ratio ( ) estimates the fraction of light intercepted at layer ( i ), assuming the densest layer represents near-total occlusion. Thus, the term ( 1 - ) represents the gap fraction — i.e., the probability that a beam of light traveling from the ground upward has not yet been occluded by vegetation up to that layer.\nThis interpretation fits the TLS scanning geometry, where lower layers are sampled first and occlusion increases with height.\n\n\n\nALS Variant Used Here\nWe assume that the highest return count in the column corresponds to full canopy closure (i.e., near-zero gap fraction). This allows us to use the maximum as a local normalization factor:\n\n( p_i = )\n( LAD_i = -(1 - p_i) / (k dz) )\n\nThis does not model occlusion directly, but gives a consistent LAD profile for column-wise clustering.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#full-workflow-voxelization-to-envi-met-3d-trees",
    "href": "doc/tls_v1_2.html#full-workflow-voxelization-to-envi-met-3d-trees",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Full Workflow: Voxelization to ENVI-met 3D Trees",
    "text": "Full Workflow: Voxelization to ENVI-met 3D Trees\n\nNormalize ALS Height and Filter Ground\nlas &lt;- readLAS(las_file)\nlas &lt;- normalize_height(las, knnidw(k = 6, p = 2))\nlas &lt;- filter_poi(las, Z &gt; 0)\n\n\nVoxelize ALS Point Cloud\nvoxels &lt;- voxel_metrics(las, ~length(Z), res = res_xy, dz = res_z)\n\n\nConvert Voxel Counts to LAD using ALS-based Beer’s Law\nlad_df &lt;- convert_voxel_lad_long(voxels, res_z = res_z, k = k, scale_factor = scale_factor)\n\n\nCluster Similar LAD Profiles\nWe reduce the number of ENVI-met profiles by grouping similar LAD profiles using k-means clustering. LAD profiles are pivoted to a wide matrix (z-layers as columns):\nlad_df$xy_key &lt;- paste(lad_df$x, lad_df$y)\nlad_matrix &lt;- lad_df %&gt;% \n  tidyr::pivot_wider(names_from = z, values_from = lad, values_fill = 0) %&gt;%\n  column_to_rownames(\"xy_key\") %&gt;%\n  as.matrix()\nclustering &lt;- kmeans(lad_matrix, centers = n_clusters, nstart = 10)\nlad_df$cluster &lt;- clustering$cluster[match(lad_df$xy_key, rownames(lad_matrix))]\n\n\nAssign 6-Character ENVIMET_IDs\nEach LAD cluster is assigned a unique identifier that begins with “S” and uses base36 encoding (0–9, A–Z):\nint_to_base36 &lt;- function(n, width = 5) {\n  chars &lt;- c(0:9, LETTERS)\n  base &lt;- length(chars)\n  result &lt;- character()\n  while (n &gt; 0) {\n    result &lt;- c(chars[(n %% base) + 1], result)\n    n &lt;- n %/% base\n  }\n  result &lt;- paste(result, collapse = \"\")\n  padded &lt;- sprintf(paste0(\"%0\", width, \"s\"), result)\n  paste0(\"S\", substr(gsub(\" \", \"0\", padded), 1, width))\n}\n\n\nExport Point Locations as GIS Layer\nEach unique LAD column becomes a point in a GeoPackage, tagged with its ENVIMET_ID.\nsf_points &lt;- st_as_sf(point_df, coords = c(\"x\", \"y\"), crs = crs_code)\nst_write(sf_points, output_gpkg, delete_layer = TRUE)\n\n\nExport Clustered LAD Profiles as ENVI-met 3DPLANT XML\nThe LAD profile per cluster is exported to a .pld file using XML.\nexport_lad_to_envimet3d(lad_df, file_out = xml_output_file)",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#concept-of-pseudo-3d-tree-columns",
    "href": "doc/tls_v1_2.html#concept-of-pseudo-3d-tree-columns",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Concept of Pseudo-3D Tree Columns",
    "text": "Concept of Pseudo-3D Tree Columns\nEach clustered LAD profile is interpreted as a pseudo-3D vegetation column. These are not derived from segmented individual trees but represent aggregated vertical structure typical for a 2 × 2 m area.\nThis approach provides a balance between realism and simplicity:\n\nIt allows realistic vertical vegetation profiles from ALS\nReduces complexity through clustering\nProvides efficient integration into ENVI-met via both:\n\nGIS point layers with ENVIMET_ID\nXML-based 3DPLANT definitions\n\n\nPseudo-3D trees enable realistic microclimate domains with vegetation heterogeneity without requiring full 3D reconstruction.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#tls-vs-als-lad-computation-summary",
    "href": "doc/tls_v1_2.html#tls-vs-als-lad-computation-summary",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "TLS vs ALS LAD Computation Summary",
    "text": "TLS vs ALS LAD Computation Summary\n\n\n\n\n\n\n\n\nAspect\nTLS\nALS\n\n\n\n\nView Direction\nBottom-up\nTop-down\n\n\nOcclusion Bias\nUndersamples upper canopy\nUndersamples lower canopy\n\n\nLAD Estimation\nCumulative bottom-up (Beer)\nNormalized per column (max count)\n\n\nTypical Use Case\nDetailed single tree analysis\nLarge-area structure sampling",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#conclusion-and-limitations",
    "href": "doc/tls_v1_2.html#conclusion-and-limitations",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Conclusion and Limitations",
    "text": "Conclusion and Limitations\nThis pipeline offers an efficient method to integrate voxelized ALS data into ENVI-met’s 3DPLANT framework by:\n\nEstimating LAD profiles via a Beer–Lambert-based approximation\nClustering voxel columns into representative pseudo-3D vegetation types\nExporting both point geometries and XML-based plant profiles\n\nAdvantages: - Scalable to large ALS datasets - Preserves key structural heterogeneity - Compatible with ENVI-met simulation domains\nLimitations: - Assumes that the maximum voxel return represents full canopy cover, which may not hold in sparse stands - LAD estimation is empirical; it does not model true light attenuation or occlusion - The pseudo-3D approach does not represent individual trees or crown geometry - Clustering may smooth out fine-scale vertical variability\nFuture improvements could include stratified LAD normalization, occlusion-aware corrections, or hybrid ALS-TLS fusion for enhanced realism.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#references",
    "href": "doc/tls_v1_2.html#references",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "References",
    "text": "References\n\nBéland, M., et al. (2014). Remote Sensing of Environment\nCalders, K., et al. (2015). Methods in Ecology and Evolution\nJupp, D. L. B., et al. (2009). Remote Sensing of Environment",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#script-reference",
    "href": "doc/tls_v1_2.html#script-reference",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "Script Reference",
    "text": "Script Reference\nsource(\"src/microclimate_ALS.R\")\nThis source contains the complete processing workflow from voxel metrics to XML generation.",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "doc/tls_v1_2.html#references-1",
    "href": "doc/tls_v1_2.html#references-1",
    "title": "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants",
    "section": "References",
    "text": "References\n\nCalders et al. (2015). Nondestructive biomass estimation via TLS. Methods Ecol Evol, 6:198–208.https://doi.org/10.1111/2041-210X.12301\nChen et al. (2018): Estimation of LAI in open-canopy forests using TLS and path length models. Agric. For. Meteorol. 263, 323–333. https://doi.org/10.1016/j.agrformet.2018.09.006\nENVI-met PLANT3D specification: https://www.envi-met.net/documents/papers/overview30.pdf\nENVI-met Albero overview: https://envi-met.com/tutorials/albero-overview\nENVI-met KB – Obtaining Leaf Area Density: https://envi-met.info/doku.php?id=kb:lad#obtaining_leaf_area_density_data\nENVI-met dbmanager documentation: https://envi-met.info/doku.php?id=apps:dbmanager:start\nENVI-met Vegetation Tutorial (YouTube): https://www.youtube.com/watch?v=KGRLnXAXZds\nFlynn et al. (2023) – TLS-based vegetation index estimation; compares methods and highlights complexities in Mediterranean forest. Biogeosciences, 20(13), 2769–2784. doi:10.5194/bg-20-2769-2023\nHosoi & Omasa (2006). Voxel-based 3D tree modeling. IEEE TGRS, 44(12), 3610–3618. https://doi.org/10.1109/TGRS.2006.881743\nPrusinkiewicz & Lindenmayer (1990). The Algorithmic Beauty of Plants. Springer. https://doi.org/10.1007/978-1-4613-8476-2\nOshio & Asawa (2016). Solar transmittance of urban trees. IEEE TGRS, 54(9), 5483–5492. https://doi.org/10.1109/TGRS.2016.2565699\nSimon, Sinsel & Bruse (2020). Fractal trees in ENVI-met. Forests, 11(8), 869. https://doi.org/10.3390/f11080869\nWilkes et al. (2017). TLS acquisition strategies. Remote Sens Environ, 196, 140–153. https://doi.org/10.1016/j.rse.2017.04.030\nChen et al. (2018). LAI from TLS. Agr Forest Meteorol, 263, 323–333. https://doi.org/10.1016/j.agrformet.2018.09.006\nYin et al. (2019). Shading and thermal comfort. Sustainability, 11(5), 1355. https://doi.org/10.3390/su11051355\nZhang (2024). Green layouts in ENVI-met. Informatica, 48(23). https://doi.org/10.31449/inf.v48i23.6881 Certainly. Here’s the reference adapted to match your current compact style:",
    "crumbs": [
      "Using leaf area density (LAD) from TLS data in ENVI-met for 3D plants"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Envi_Met TLS-tree-climate",
    "section": "",
    "text": "This course teaches how to use terrestrial laser scanning (TLS) to model individual trees and their effects on microclimate. You’ll learn how to turn detailed 3D scans into leaf area density (LAD) profiles and use them in ENVI-met for realistic tree simulations.\nWhat you’ll learn: What LAD means and why it matters for tree–climate interaction\nThis course is hands-on, focused, and designed for clear outcomes: understanding tree structure, visualizing it, and using it in a climate model."
  },
  {
    "objectID": "base/faq.html",
    "href": "base/faq.html",
    "title": "Frequently asked Questions",
    "section": "",
    "text": "This is a senseless question to meet a meaningfull answer\n\n\n\n\n\n\n\n\n\nThis is a meaningful answer to a senseless question\n\n\n\n\n\n\n\n\n\nLearn More…\n\n\n\n\n\nThis is a even more meaningful answer to a senseless question"
  },
  {
    "objectID": "base/faq.html#make-sense-topic",
    "href": "base/faq.html#make-sense-topic",
    "title": "Frequently asked Questions",
    "section": "",
    "text": "This is a senseless question to meet a meaningfull answer\n\n\n\n\n\n\n\n\n\nThis is a meaningful answer to a senseless question\n\n\n\n\n\n\n\n\n\nLearn More…\n\n\n\n\n\nThis is a even more meaningful answer to a senseless question"
  },
  {
    "objectID": "index.html#commenting-on-the-course-pages",
    "href": "index.html#commenting-on-the-course-pages",
    "title": "Envi_Met TLS-tree-climate",
    "section": "Commenting on the course pages",
    "text": "Commenting on the course pages\nThis site uses utterances for comments via GitHub. To leave a comment, simply sign in with your GitHub account. If you don’t have one, you can create a free account here.\nYour comment will be publicly stored and appear directly below. No trackers or third-party cookies are used.\nNeed help? What is utterances and how does it work?"
  }
]